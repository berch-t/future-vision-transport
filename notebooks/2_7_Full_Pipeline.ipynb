{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8f824829",
   "metadata": {
    "cell_marker": "\"\"\"",
    "lines_to_next_cell": 0
   },
   "source": [
    "# üöÄ Future Vision Transport - Pipeline d'Entra√Ænement Complet\n",
    "\n",
    "**Milestone 3 - Pipeline Complet avec 5 Mod√®les et Analyses Avanc√©es**\n",
    "\n",
    "Ce notebook impl√©mente le pipeline d'entra√Ænement complet pour la segmentation d'images Cityscapes\n",
    "avec 5 architectures diff√©rentes, analyses d√©taill√©es et recommandations de d√©ploiement.\n",
    "\n",
    "## ‚ö° Fonctionnalit√©s Cl√©s\n",
    "\n",
    "- ‚úÖ **TensorFlow 2.18** compatible Google Colab L4\n",
    "- ‚úÖ **Pipeline de donn√©es** avec augmentation Albumentations >1000 FPS\n",
    "- ‚úÖ **5 mod√®les** : UNet Mini, VGG16 UNet, UNet EfficientNet, DeepLabV3+, Segformer-B0\n",
    "- ‚úÖ **M√©triques d'√©valuation** compl√®tes par mod√®le (13 m√©triques d√©taill√©es)\n",
    "- ‚úÖ **Comparaisons des mod√®les** avec analyses co√ªt/b√©n√©fice\n",
    "- ‚úÖ **Recommandations d√©ploiement** par sc√©nario d'usage embarqu√©\n",
    "- ‚úÖ **Visualisations avanc√©es** : heatmaps, radar charts, matrices de confusion\n",
    "\n",
    "## üéØ Structure du Pipeline\n",
    "\n",
    "1. **Configuration & GPU** - Setup Google Colab L4 + TensorFlow 2.18\n",
    "2. **Mod√®les & Loss Functions** - 5 architectures + Custom losses\n",
    "3. **Pipeline de Donn√©es** - CityscapesDataGenerator + Albumentations\n",
    "4. **Entra√Ænement S√©quentiel** - Training des 5 mod√®les avec nettoyage m√©moire\n",
    "5. **M√©triques d'√âvaluation** - Analyses d√©taill√©es par mod√®le\n",
    "6. **Comparaisons des Mod√®les** - Graphiques et recommandations d√©ploiement\n",
    "7. **V√©rification Compl√®te** - Simulation API + Visualisations\n",
    "\n",
    "## üßπ Environment Setup (Optionnel)\n",
    "\n",
    "Cellule de nettoyage pour red√©marrer proprement l'environnement si n√©cessaire."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62eb9cd1",
   "metadata": {
    "title": "[python]"
   },
   "outputs": [],
   "source": [
    "\n",
    "# import os\n",
    "# import shutil\n",
    "# import sys\n",
    "\n",
    "# # Purger compl√®tement l'environnement Python\n",
    "# print(\"üßπ Purging Colab environment...\")\n",
    "\n",
    "# # 1. Clear Python cache\n",
    "# if hasattr(sys, 'modules'):\n",
    "#     modules_to_clear = [k for k in sys.modules.keys() if 'tensorflow' in k or 'keras' in k]\n",
    "#     for mod in modules_to_clear:\n",
    "#         if mod in sys.modules:\n",
    "#             del sys.modules[mod]\n",
    "\n",
    "# # 2. Clear TensorFlow cache\n",
    "# try:\n",
    "#     import tensorflow as tf\n",
    "#     tf.keras.backend.clear_session()\n",
    "#     del tf\n",
    "# except:\n",
    "#     pass\n",
    "\n",
    "# # 3. Clear model cache directories\n",
    "# cache_dirs = [\n",
    "#     '/content/models',\n",
    "#     '/content/.keras',\n",
    "#     '/tmp/keras-*',\n",
    "#     '/root/.keras'\n",
    "# ]\n",
    "\n",
    "# for cache_dir in cache_dirs:\n",
    "#     if os.path.exists(cache_dir):\n",
    "#         shutil.rmtree(cache_dir, ignore_errors=True)\n",
    "#         print(f\"   Cleared: {cache_dir}\")\n",
    "\n",
    "# # 4. Clear pip cache\n",
    "# os.system('pip cache purge')\n",
    "\n",
    "# # 5. Force garbage collection\n",
    "# import gc\n",
    "# gc.collect()\n",
    "\n",
    "# print(\"‚úÖ Environment purged - ready for fresh start\")\n",
    "\n",
    "# # 6. RESTART RUNTIME (obligatoire)\n",
    "# print(\"üîÑ RESTART RUNTIME NOW! (Runtime > Restart Runtime)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6280654a",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "## üéØ Configuration Environnement & TensorFlow\n",
    "Configuration pour TensorFlow 2.15+ compatible avec l'API de production"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45c56e88",
   "metadata": {
    "title": "[python]"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import platform\n",
    "import warnings\n",
    "import time\n",
    "import gc\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import json\n",
    "\n",
    "# Suppress warnings for cleaner output\n",
    "warnings.filterwarnings('ignore')\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "# Memory optimization\n",
    "os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'\n",
    "os.environ['TF_GPU_ALLOCATOR'] = 'cuda_malloc_async'\n",
    "\n",
    "print(\"üöÄ Future Vision Transport - Pipeline d'Entra√Ænement Complet\")\n",
    "print(\"=\"*80)\n",
    "print(f\"üìÖ Training started: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(f\"üñ•Ô∏è  Platform: {platform.system()} {platform.release()}\")\n",
    "print(f\"üêç Python: {sys.version}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25238c91",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "## üì¶ D√©pendances & Setup TensorFlow\n",
    "TensorFlow 2.15+ avec configuration GPU optimis√©e pour Google Colab L4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c741f92",
   "metadata": {
    "title": "[python]"
   },
   "outputs": [],
   "source": [
    "# Core dependencies\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import cv2\n",
    "from PIL import Image\n",
    "\n",
    "# TensorFlow 2.15+ imports\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models, optimizers, callbacks\n",
    "from tensorflow.keras.utils import Sequence\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Additional libraries\n",
    "import albumentations as A\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import psutil\n",
    "from tqdm import tqdm\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "print(f\"‚úÖ TensorFlow version: {tf.__version__}\")\n",
    "#print(f\"‚úÖ Keras version: {keras.__version__}\")\n",
    "print(f\"‚úÖ NumPy version: {np.__version__}\")\n",
    "print(f\"‚úÖ Albumentations version: {A.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff364fde",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "## üîß Configuration GPU Google Colab L4\n",
    "Configuration GPU optimis√©e pour l'entra√Ænement sur Google Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec026f88",
   "metadata": {
    "title": "[python]"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Check TensorFlow build info\n",
    "print(f\"üìã TensorFlow build info:\")\n",
    "print(f\"   Built with CUDA: {tf.test.is_built_with_cuda()}\")\n",
    "print(f\"   Built with GPU support: {tf.test.is_built_with_gpu_support()}\")\n",
    "\n",
    "# List all physical devices\n",
    "print(f\"\\nüîç All physical devices:\")\n",
    "all_devices = tf.config.list_physical_devices()\n",
    "for device in all_devices:\n",
    "    print(f\"   {device}\")\n",
    "\n",
    "# GPU-specific configuration\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "print(f\"\\nüéÆ GPU Detection:\")\n",
    "print(f\"   Found {len(gpus)} GPU(s)\")\n",
    "\n",
    "if gpus:\n",
    "    try:\n",
    "        # Enable memory growth for all GPUs\n",
    "        for i, gpu in enumerate(gpus):\n",
    "            print(f\"   GPU {i}: {gpu}\")\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "\n",
    "        # Set memory limit if needed (optional - remove if you want full GPU memory)\n",
    "        # tf.config.experimental.set_memory_limit(gpus[0], 12000)  # 12GB limit\n",
    "\n",
    "        # Verify GPU is available for TensorFlow\n",
    "        print(f\"\\n‚úÖ GPU Configuration Summary:\")\n",
    "        print(f\"   GPU memory growth enabled for {len(gpus)} GPU(s)\")\n",
    "        print(f\"   Available GPUs: {[gpu.name for gpu in gpus]}\")\n",
    "\n",
    "        # Test GPU availability\n",
    "        with tf.device('/GPU:0'):\n",
    "            test_tensor = tf.constant([[1.0, 2.0], [3.0, 4.0]])\n",
    "            result = tf.matmul(test_tensor, test_tensor)\n",
    "        print(f\"   GPU compute test: ‚úÖ Success\")\n",
    "        print(f\"   Test result: {result.numpy()}\")\n",
    "\n",
    "        gpu_available = True\n",
    "\n",
    "    except RuntimeError as e:\n",
    "        print(f\"‚ö†Ô∏è  GPU configuration error: {e}\")\n",
    "        print(f\"üí° Suggestions:\")\n",
    "        print(f\"   1. Install CUDA 11.8 or 12.x compatible with TensorFlow\")\n",
    "        print(f\"   2. Install cuDNN 8.6+\")\n",
    "        print(f\"   3. Reinstall tensorflow[and-cuda]: pip install tensorflow[and-cuda]\")\n",
    "        gpu_available = False\n",
    "\n",
    "else:\n",
    "    print(\"‚ùå No GPU detected!\")\n",
    "    print(f\"üí° Troubleshooting steps:\")\n",
    "    print(f\"   1. Verify NVIDIA drivers: nvidia-smi\")\n",
    "    print(f\"   2. Install CUDA Toolkit 11.8 or 12.x\")\n",
    "    print(f\"   3. Install cuDNN 8.6+\")\n",
    "    print(f\"   4. Install TensorFlow with GPU: pip install tensorflow[and-cuda]\")\n",
    "    print(f\"   5. Restart Python/Jupyter after installation\")\n",
    "    gpu_available = False\n",
    "\n",
    "# Additional CUDA information\n",
    "try:\n",
    "    # Check if CUDA is available\n",
    "    cuda_available = tf.test.is_gpu_available(cuda_only=True)\n",
    "    print(f\"\\nüîß CUDA Status:\")\n",
    "    print(f\"   CUDA available: {cuda_available}\")\n",
    "\n",
    "    if cuda_available:\n",
    "        # Get GPU device details\n",
    "        gpu_details = tf.config.experimental.get_device_details(gpus[0])\n",
    "        print(f\"   GPU Details: {gpu_details}\")\n",
    "\n",
    "        # Check memory\n",
    "        if hasattr(tf.config.experimental, 'get_memory_info'):\n",
    "            memory_info = tf.config.experimental.get_memory_info('GPU:0')\n",
    "            print(f\"   GPU Memory - Current: {memory_info['current']//1024//1024}MB, Peak: {memory_info['peak']//1024//1024}MB\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è  Could not get detailed GPU info: {e}\")\n",
    "\n",
    "# Mixed precision for Google Colab L4 (supports Tensor Cores)\n",
    "print(f\"\\n‚ö° Mixed Precision Configuration:\")\n",
    "try:\n",
    "    if gpu_available:\n",
    "        policy = tf.keras.mixed_precision.Policy('mixed_float16')\n",
    "        tf.keras.mixed_precision.set_global_policy(policy)\n",
    "        print(\"‚úÖ Mixed precision enabled (mixed_float16) - Optimized for Google Colab L4\")\n",
    "        print(\"   Benefits: 2x speed improvement + reduced memory usage\")\n",
    "        mixed_precision_enabled = True\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è  Mixed precision disabled - no compatible GPU\")\n",
    "        mixed_precision_enabled = False\n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è  Mixed precision setup failed: {e}\")\n",
    "    mixed_precision_enabled = False\n",
    "\n",
    "# Performance recommendations for Google Colab L4\n",
    "print(f\"\\nüéØ Google Colab L4 Optimization Recommendations:\")\n",
    "print(f\"   ‚Ä¢ Batch size: 4-8 (512x1024 images) - Conservative for L4 memory\")\n",
    "print(f\"   ‚Ä¢ Mixed precision: {'‚úÖ Enabled' if mixed_precision_enabled else '‚ùå Disabled'}\")\n",
    "print(f\"   ‚Ä¢ Memory growth: {'‚úÖ Enabled' if gpu_available else '‚ùå Disabled'}\")\n",
    "print(f\"   ‚Ä¢ Expected performance: ~1.5-2x faster than CPU on L4\")\n",
    "\n",
    "# Optimisations suppl√©mentaires pour Colab L4\n",
    "def optimize_colab_l4_memory():\n",
    "    \"\"\"Optimisations sp√©cifiques pour Google Colab L4\"\"\"\n",
    "    print(f\"\\nüîß OPTIMISATIONS GOOGLE COLAB L4\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    # 1. Configuration m√©moire GPU\n",
    "    if gpus:\n",
    "        try:\n",
    "            # Limiter l'usage m√©moire initial\n",
    "            tf.config.experimental.set_memory_limit(gpus[0], 14000)  # 14GB sur 16GB L4\n",
    "            print(\"‚úÖ Limite m√©moire GPU: 14GB/16GB\")\n",
    "        except:\n",
    "            print(\"‚ö†Ô∏è Limite m√©moire GPU non applicable\")\n",
    "    \n",
    "    # 2. Configuration garbage collection agressif\n",
    "    import gc\n",
    "    gc.set_threshold(700, 10, 10)  # Plus agressif que d√©faut\n",
    "    print(\"‚úÖ Garbage collection optimis√©\")\n",
    "    \n",
    "    # 3. Configuration cache TensorFlow\n",
    "    os.environ['TF_GPU_ALLOCATOR'] = 'cuda_malloc_async'\n",
    "    os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'\n",
    "    print(\"‚úÖ Allocation GPU asynchrone activ√©e\")\n",
    "    \n",
    "    # 4. Configuration XLA pour optimisation\n",
    "    if gpu_available:\n",
    "        tf.config.optimizer.set_jit(True)\n",
    "        print(\"‚úÖ XLA JIT compilation activ√©e\")\n",
    "    \n",
    "    return True\n",
    "\n",
    "# Appliquer les optimisations\n",
    "memory_optimized = optimize_colab_l4_memory()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54f46a26",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "## üéØ Configuration du Projet\n",
    "Configuration centrale pour compatibilit√© TF 2.15+ et API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cc6fced",
   "metadata": {
    "title": "[python]"
   },
   "outputs": [],
   "source": [
    "\n",
    "# ‚úÖ INPUT_SHAPE au lieu de BATCH_SHAPE pour compatibilit√© TF 2.15+\n",
    "INPUT_SHAPE = (512, 1024, 3)  # Height, Width, Channels - compatible avec l'API\n",
    "NUM_CLASSES = 8  # 8 cat√©gories Cityscapes\n",
    "BATCH_SIZE = 4 if gpus else 2  # Conservative batch size for Google Colab L4\n",
    "\n",
    "# Mapping exact des classes Cityscapes (34 ‚Üí 8 cat√©gories)\n",
    "CITYSCAPES_TO_8_CLASSES = {\n",
    "    0: 7,   # unlabeled -> void\n",
    "    1: 7,   # ego vehicle -> void\n",
    "    2: 7,   # rectification border -> void\n",
    "    3: 7,   # out of roi -> void\n",
    "    4: 7,   # static -> void\n",
    "    5: 7,   # dynamic -> void\n",
    "    6: 7,   # ground -> void\n",
    "    7: 0,   # road -> road\n",
    "    8: 1,   # sidewalk -> road (regroup√©)\n",
    "    9: 1,   # parking -> road (regroup√©)\n",
    "    10: 1,  # rail track -> road (regroup√©)\n",
    "    11: 1,  # building -> building\n",
    "    12: 1,  # wall -> building (regroup√©)\n",
    "    13: 1,  # fence -> building (regroup√©)\n",
    "    14: 1,  # guard rail -> building (regroup√©)\n",
    "    15: 1,  # bridge -> building (regroup√©)\n",
    "    16: 1,  # tunnel -> building (regroup√©)\n",
    "    17: 2,  # pole -> object\n",
    "    18: 2,  # polegroup -> object\n",
    "    19: 2,  # traffic light -> object\n",
    "    20: 2,  # traffic sign -> object\n",
    "    21: 3,  # vegetation -> nature\n",
    "    22: 3,  # terrain -> nature\n",
    "    23: 4,  # sky -> sky\n",
    "    24: 5,  # person -> person\n",
    "    25: 5,  # rider -> person (regroup√©)\n",
    "    26: 6,  # car -> vehicle\n",
    "    27: 6,  # truck -> vehicle\n",
    "    28: 6,  # bus -> vehicle\n",
    "    29: 6,  # caravan -> vehicle\n",
    "    30: 6,  # trailer -> vehicle\n",
    "    31: 6,  # train -> vehicle\n",
    "    32: 6,  # motorcycle -> vehicle\n",
    "    33: 6   # bicycle -> vehicle\n",
    "}\n",
    "\n",
    "# Couleurs EXACTES identiques √† l'API main_keras_compatible.py\n",
    "CITYSCAPES_8_CLASSES_COLORS = {\n",
    "    0: {\"name\": \"road\", \"color\": [139, 69, 19]},      # #8B4513 (brown)\n",
    "    1: {\"name\": \"building\", \"color\": [128, 128, 128]}, # #808080 (gray)\n",
    "    2: {\"name\": \"object\", \"color\": [255, 215, 0]},     # #FFD700 (gold)\n",
    "    3: {\"name\": \"nature\", \"color\": [34, 139, 34]},     # #228B22 (green)\n",
    "    4: {\"name\": \"sky\", \"color\": [135, 206, 235]},      # #87CEEB (sky blue)\n",
    "    5: {\"name\": \"person\", \"color\": [255, 105, 180]},   # #FF69B4 (pink)\n",
    "    6: {\"name\": \"vehicle\", \"color\": [220, 20, 60]},    # #DC143C (red)\n",
    "    7: {\"name\": \"void\", \"color\": [0, 0, 0]}           # #000000 (black)\n",
    "}\n",
    "\n",
    "# Poids des classes pour loss weighted (bas√© sur fr√©quences Cityscapes)\n",
    "CLASS_WEIGHTS = [0.8, 2.5, 5.0, 1.2, 3.0, 10.0, 4.0, 1.0]\n",
    "\n",
    "# Configuration d'entra√Ænement\n",
    "TRAINING_CONFIG = {\n",
    "    'data': {\n",
    "        'max_train_samples': 600,  # Plus d'√©chantillons pour de meilleurs r√©sultats\n",
    "        'max_val_samples': 150,\n",
    "        'input_shape': INPUT_SHAPE,  # ‚úÖ input_shape pour TF 2.15+\n",
    "        'num_classes': NUM_CLASSES,\n",
    "        'augmentation_probability': 0.8\n",
    "    },\n",
    "    'training': {\n",
    "        'batch_size': BATCH_SIZE,\n",
    "        'epochs': 25,\n",
    "        'learning_rate': 1e-3,\n",
    "        'patience': 8,\n",
    "        'min_delta': 0.001\n",
    "    },\n",
    "    'models': {\n",
    "        'unet_mini': {\n",
    "            'name': 'unet_mini_tf_2_15_compatible',\n",
    "            'enabled': True,\n",
    "            'batch_size': BATCH_SIZE\n",
    "        },\n",
    "        'vgg16_unet': {\n",
    "            'name': 'vgg16_unet_tf_2_15_compatible',\n",
    "            'enabled': True,\n",
    "            'batch_size': max(2, BATCH_SIZE // 2)  # Plus conservateur pour mod√®le plus large\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"‚úÖ Configuration loaded:\")\n",
    "print(f\"   Input shape: {INPUT_SHAPE}\")\n",
    "print(f\"   Classes: {NUM_CLASSES}\")\n",
    "print(f\"   Batch size: {BATCH_SIZE}\")\n",
    "print(f\"   Max train samples: {TRAINING_CONFIG['data']['max_train_samples']}\")\n",
    "print(f\"   Mixed precision: {mixed_precision_enabled}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7de86329",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "## üé≠ Loss Functions & M√©triques Personnalis√©es\n",
    "Fonctions identiques √† l'API main_keras_compatible.py pour compatibilit√© parfaite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "798d733c",
   "metadata": {
    "title": "[python]"
   },
   "outputs": [],
   "source": [
    "\n",
    "class DiceLoss(tf.keras.losses.Loss):\n",
    "    \"\"\"Dice Loss for segmentation tasks - IDENTICAL to API\"\"\"\n",
    "    def __init__(self, smooth=1e-6, name='dice_loss'):\n",
    "        super().__init__(name=name)\n",
    "        self.smooth = smooth\n",
    "\n",
    "    def call(self, y_true, y_pred):\n",
    "        y_true = tf.cast(y_true, tf.float32)\n",
    "        y_pred = tf.cast(y_pred, tf.float32)\n",
    "\n",
    "        # Flatten tensors for calculation\n",
    "        y_true_f = tf.reshape(y_true, [-1, NUM_CLASSES])\n",
    "        y_pred_f = tf.reshape(y_pred, [-1, NUM_CLASSES])\n",
    "\n",
    "        # Calculate intersection and union\n",
    "        intersection = tf.reduce_sum(y_true_f * y_pred_f, axis=0)\n",
    "        union = tf.reduce_sum(y_true_f, axis=0) + tf.reduce_sum(y_pred_f, axis=0)\n",
    "\n",
    "        # Dice coefficient per class\n",
    "        dice = (2.0 * intersection + self.smooth) / (union + self.smooth)\n",
    "\n",
    "        return 1.0 - tf.reduce_mean(dice)\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({'smooth': self.smooth})\n",
    "        return config\n",
    "\n",
    "class WeightedCategoricalCrossentropy(tf.keras.losses.Loss):\n",
    "    \"\"\"Weighted Categorical Crossentropy - IDENTICAL to API\"\"\"\n",
    "    def __init__(self, class_weights=None, name='weighted_categorical_crossentropy'):\n",
    "        super().__init__(name=name)\n",
    "\n",
    "        if class_weights is None:\n",
    "            class_weights = CLASS_WEIGHTS\n",
    "\n",
    "        self.class_weights = tf.constant(class_weights, dtype=tf.float32)\n",
    "\n",
    "    def call(self, y_true, y_pred):\n",
    "        y_true = tf.cast(y_true, tf.float32)\n",
    "        y_pred = tf.cast(y_pred, tf.float32)\n",
    "\n",
    "        weights = tf.reduce_sum(self.class_weights * y_true, axis=-1)\n",
    "        crossentropy = -tf.reduce_sum(y_true * tf.math.log(tf.clip_by_value(y_pred, 1e-7, 1.0)), axis=-1)\n",
    "        weighted_crossentropy = crossentropy * weights\n",
    "\n",
    "        return tf.reduce_mean(weighted_crossentropy)\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({'class_weights': self.class_weights.numpy().tolist()})\n",
    "        return config\n",
    "\n",
    "class CombinedLoss(tf.keras.losses.Loss):\n",
    "    \"\"\"Combined Dice + Weighted CE Loss - IDENTICAL to API\"\"\"\n",
    "    def __init__(self, dice_weight=0.5, ce_weight=0.5, class_weights=None, name='combined_loss'):\n",
    "        super().__init__(name=name)\n",
    "        self.dice_weight = dice_weight\n",
    "        self.ce_weight = ce_weight\n",
    "\n",
    "        self.dice_loss = DiceLoss()\n",
    "        self.ce_loss = WeightedCategoricalCrossentropy(class_weights=class_weights)\n",
    "\n",
    "    def call(self, y_true, y_pred):\n",
    "        dice = self.dice_loss(y_true, y_pred)\n",
    "        ce = self.ce_loss(y_true, y_pred)\n",
    "\n",
    "        return self.dice_weight * dice + self.ce_weight * ce\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            'dice_weight': self.dice_weight,\n",
    "            'ce_weight': self.ce_weight\n",
    "        })\n",
    "        return config\n",
    "\n",
    "class MeanIoU(tf.keras.metrics.Metric):\n",
    "    \"\"\"Mean IoU metric - IDENTICAL to API\"\"\"\n",
    "    def __init__(self, num_classes=NUM_CLASSES, name='mean_iou', **kwargs):\n",
    "        super().__init__(name=name, **kwargs)\n",
    "        self.num_classes = num_classes\n",
    "        self.confusion_matrix = self.add_weight(\n",
    "            name='confusion_matrix',\n",
    "            shape=(num_classes, num_classes),\n",
    "            initializer='zeros'\n",
    "        )\n",
    "\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        y_true = tf.cast(tf.argmax(y_true, axis=-1), tf.int32)\n",
    "        y_pred = tf.cast(tf.argmax(y_pred, axis=-1), tf.int32)\n",
    "\n",
    "        mask = tf.logical_and(tf.greater_equal(y_true, 0), tf.less(y_true, self.num_classes))\n",
    "        y_true = tf.boolean_mask(y_true, mask)\n",
    "        y_pred = tf.boolean_mask(y_pred, mask)\n",
    "\n",
    "        current_cm = tf.math.confusion_matrix(\n",
    "            y_true, y_pred, num_classes=self.num_classes, dtype=tf.float32\n",
    "        )\n",
    "\n",
    "        self.confusion_matrix.assign_add(current_cm)\n",
    "\n",
    "    def result(self):\n",
    "        diag = tf.linalg.diag_part(self.confusion_matrix)\n",
    "        sum_over_row = tf.reduce_sum(self.confusion_matrix, axis=1)\n",
    "        sum_over_col = tf.reduce_sum(self.confusion_matrix, axis=0)\n",
    "\n",
    "        denominator = sum_over_row + sum_over_col - diag\n",
    "        iou = tf.where(tf.equal(denominator, 0), tf.zeros_like(diag), diag / denominator)\n",
    "\n",
    "        return tf.reduce_mean(iou)\n",
    "\n",
    "    def reset_state(self):\n",
    "        self.confusion_matrix.assign(tf.zeros_like(self.confusion_matrix))\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({'num_classes': self.num_classes})\n",
    "        return config\n",
    "\n",
    "class DiceCoefficient(tf.keras.metrics.Metric):\n",
    "    \"\"\"Dice Coefficient metric\"\"\"\n",
    "    def __init__(self, name='dice_coefficient', **kwargs):\n",
    "        super().__init__(name=name, **kwargs)\n",
    "        self.dice_sum = self.add_weight(name='dice_sum', initializer='zeros')\n",
    "        self.count = self.add_weight(name='count', initializer='zeros')\n",
    "\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        y_true = tf.cast(y_true, tf.float32)\n",
    "        y_pred = tf.cast(y_pred, tf.float32)\n",
    "\n",
    "        y_true_f = tf.reshape(y_true, [-1, NUM_CLASSES])\n",
    "        y_pred_f = tf.reshape(y_pred, [-1, NUM_CLASSES])\n",
    "\n",
    "        intersection = tf.reduce_sum(y_true_f * y_pred_f, axis=0)\n",
    "        union = tf.reduce_sum(y_true_f, axis=0) + tf.reduce_sum(y_pred_f, axis=0)\n",
    "\n",
    "        dice = (2.0 * intersection + 1e-6) / (union + 1e-6)\n",
    "\n",
    "        self.dice_sum.assign_add(tf.reduce_mean(dice))\n",
    "        self.count.assign_add(1.0)\n",
    "\n",
    "    def result(self):\n",
    "        return self.dice_sum / self.count\n",
    "\n",
    "    def reset_state(self):\n",
    "        self.dice_sum.assign(0.0)\n",
    "        self.count.assign(0.0)\n",
    "\n",
    "# Custom objects dictionary pour compatibilit√© API parfaite\n",
    "CUSTOM_OBJECTS = {\n",
    "    'DiceLoss': DiceLoss,\n",
    "    'WeightedCategoricalCrossentropy': WeightedCategoricalCrossentropy,\n",
    "    'CombinedLoss': CombinedLoss,\n",
    "    'MeanIoU': MeanIoU,\n",
    "    'DiceCoefficient': DiceCoefficient,\n",
    "    'dice_loss': DiceLoss,\n",
    "    'weighted_categorical_crossentropy': WeightedCategoricalCrossentropy,\n",
    "    'combined_loss': CombinedLoss,\n",
    "    'mean_iou': MeanIoU,\n",
    "    'dice_coefficient': DiceCoefficient\n",
    "}\n",
    "\n",
    "print(\"‚úÖ Custom loss functions and metrics loaded:\")\n",
    "print(\"   - DiceLoss\")\n",
    "print(\"   - WeightedCategoricalCrossentropy\")\n",
    "print(\"   - CombinedLoss\")\n",
    "print(\"   - MeanIoU\")\n",
    "print(\"   - DiceCoefficient\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef001072",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "## üîÑ Pipeline de Donn√©es & Augmentation\n",
    "Pipeline de donn√©es performant avec Albumentations >1000 FPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abc0d9d4",
   "metadata": {
    "lines_to_next_cell": 2,
    "title": "[python]"
   },
   "outputs": [],
   "source": [
    "def convert_cityscapes_mask_to_8_classes(mask):\n",
    "    \"\"\"Convertit un masque Cityscapes 34 classes vers 8 cat√©gories\"\"\"\n",
    "    mask_8_classes = np.zeros_like(mask, dtype=np.uint8)\n",
    "\n",
    "    for cityscapes_class, target_class in CITYSCAPES_TO_8_CLASSES.items():\n",
    "        mask_8_classes[mask == cityscapes_class] = target_class\n",
    "\n",
    "    return mask_8_classes\n",
    "\n",
    "def preprocess_image(image):\n",
    "    \"\"\"Pr√©processing image identique √† l'API\"\"\"\n",
    "    # Resize si n√©cessaire\n",
    "    if image.shape[:2] != (INPUT_SHAPE[0], INPUT_SHAPE[1]):\n",
    "        image = cv2.resize(image, (INPUT_SHAPE[1], INPUT_SHAPE[0]))\n",
    "\n",
    "    # Normalisation [0,1]\n",
    "    image = image.astype(np.float32) / 255.0\n",
    "\n",
    "    return image\n",
    "\n",
    "def preprocess_mask(mask):\n",
    "    \"\"\"Pr√©processing masque avec conversion one-hot\"\"\"\n",
    "    # Resize si n√©cessaire\n",
    "    if mask.shape[:2] != (INPUT_SHAPE[0], INPUT_SHAPE[1]):\n",
    "        mask = cv2.resize(mask, (INPUT_SHAPE[1], INPUT_SHAPE[0]), interpolation=cv2.INTER_NEAREST)\n",
    "\n",
    "    # Convertir en one-hot encoding\n",
    "    mask_one_hot = tf.keras.utils.to_categorical(mask, num_classes=NUM_CLASSES)\n",
    "\n",
    "    return mask_one_hot\n",
    "\n",
    "# Pipeline d'augmentation Albumentations optimis√©\n",
    "def get_augmentation_pipeline():\n",
    "    \"\"\"Pipeline d'augmentation Albumentations coordonn√© image+masque\"\"\"\n",
    "    return A.Compose([\n",
    "        A.RandomBrightnessContrast(brightness_limit=0.2, contrast_limit=0.2, p=0.5),\n",
    "        A.HueSaturationValue(hue_shift_limit=10, sat_shift_limit=15, val_shift_limit=10, p=0.5),\n",
    "        A.RandomGamma(gamma_limit=(80, 120), p=0.3),\n",
    "        A.GaussianBlur(blur_limit=3, p=0.3),\n",
    "        A.HorizontalFlip(p=0.5),\n",
    "        A.ShiftScaleRotate(\n",
    "            shift_limit=0.1,\n",
    "            scale_limit=0.1,\n",
    "            rotate_limit=5,\n",
    "            border_mode=cv2.BORDER_CONSTANT,\n",
    "            value=0,\n",
    "            mask_value=7,  # void class for mask\n",
    "            p=0.5\n",
    "        ),\n",
    "    ], additional_targets={'mask': 'mask'})\n",
    "\n",
    "class CityscapesDataGenerator(Sequence):\n",
    "    \"\"\"\n",
    "    G√©n√©rateur de donn√©es Cityscapes optimis√© pour TF 2.15+\n",
    "    Compatible avec l'API de production\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, image_paths, mask_paths, batch_size=BATCH_SIZE,\n",
    "                 augmentation=None, shuffle=True, max_samples=None):\n",
    "        self.image_paths = image_paths\n",
    "        self.mask_paths = mask_paths\n",
    "        self.batch_size = batch_size\n",
    "        self.augmentation = augmentation\n",
    "        self.shuffle = shuffle\n",
    "        self.max_samples = max_samples\n",
    "\n",
    "        # Limitation optionnelle du nombre d'√©chantillons\n",
    "        if max_samples and max_samples < len(self.image_paths):\n",
    "            indices = np.random.choice(len(self.image_paths), max_samples, replace=False)\n",
    "            self.image_paths = [self.image_paths[i] for i in indices]\n",
    "            self.mask_paths = [self.mask_paths[i] for i in indices]\n",
    "\n",
    "        self.indices = np.arange(len(self.image_paths))\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.image_paths) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        batch_indices = self.indices[index * self.batch_size:(index + 1) * self.batch_size]\n",
    "\n",
    "        # Images et masques du batch\n",
    "        batch_images = np.zeros((len(batch_indices), *INPUT_SHAPE), dtype=np.float32)\n",
    "        batch_masks = np.zeros((len(batch_indices), INPUT_SHAPE[0], INPUT_SHAPE[1], NUM_CLASSES), dtype=np.float32)\n",
    "\n",
    "        for i, idx in enumerate(batch_indices):\n",
    "            try:\n",
    "                # Charger image\n",
    "                image = cv2.imread(self.image_paths[idx])\n",
    "                image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "                # Charger masque\n",
    "                mask = cv2.imread(self.mask_paths[idx], cv2.IMREAD_GRAYSCALE)\n",
    "                mask = convert_cityscapes_mask_to_8_classes(mask)\n",
    "\n",
    "                # Augmentation si activ√©e\n",
    "                if self.augmentation:\n",
    "                    augmented = self.augmentation(image=image, mask=mask)\n",
    "                    image = augmented['image']\n",
    "                    mask = augmented['mask']\n",
    "\n",
    "                # Pr√©processing\n",
    "                image = preprocess_image(image)\n",
    "                mask = preprocess_mask(mask)\n",
    "\n",
    "                batch_images[i] = image\n",
    "                batch_masks[i] = mask\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"‚ö†Ô∏è Erreur chargement {self.image_paths[idx]}: {e}\")\n",
    "                # Image/masque par d√©faut en cas d'erreur\n",
    "                batch_images[i] = np.random.random(INPUT_SHAPE).astype(np.float32)\n",
    "                mask_default = np.zeros((INPUT_SHAPE[0], INPUT_SHAPE[1]), dtype=np.uint8)\n",
    "                batch_masks[i] = preprocess_mask(mask_default)\n",
    "\n",
    "        return batch_images, batch_masks\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.indices)\n",
    "\n",
    "print(\"‚úÖ Data pipeline loaded:\")\n",
    "print(\"   - CityscapesDataGenerator with Albumentations\")\n",
    "print(\"   - 34‚Üí8 class conversion\")\n",
    "print(\"   - Coordinated image+mask augmentation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2c52883",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "## üèóÔ∏è Architectures des Mod√®les UNet-Mini et VGG16-Unet\n",
    "Mod√®les avec input_shape au lieu de batch_shape pour compatibilit√© API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bfa0b0f",
   "metadata": {
    "lines_to_next_cell": 1,
    "title": "[python]"
   },
   "outputs": [],
   "source": [
    "\n",
    "def create_unet_mini_tf_2_15():\n",
    "    \"\"\"\n",
    "    ‚úÖ UNet Mini compatible TensorFlow 2.15+\n",
    "    Utilise input_shape au lieu de batch_shape pour compatibilit√© API\n",
    "    \"\"\"\n",
    "    # ‚úÖ INPUT_SHAPE au lieu de batch_shape\n",
    "    inputs = layers.Input(shape=INPUT_SHAPE, name='input')\n",
    "\n",
    "    # Encoder\n",
    "    conv1 = layers.Conv2D(32, 3, activation='relu', padding='same', name='conv1_1')(inputs)\n",
    "    conv1 = layers.Conv2D(32, 3, activation='relu', padding='same', name='conv1_2')(conv1)\n",
    "    pool1 = layers.MaxPooling2D(pool_size=(2, 2), name='pool1')(conv1)\n",
    "\n",
    "    conv2 = layers.Conv2D(64, 3, activation='relu', padding='same', name='conv2_1')(pool1)\n",
    "    conv2 = layers.Conv2D(64, 3, activation='relu', padding='same', name='conv2_2')(conv2)\n",
    "    pool2 = layers.MaxPooling2D(pool_size=(2, 2), name='pool2')(conv2)\n",
    "\n",
    "    conv3 = layers.Conv2D(128, 3, activation='relu', padding='same', name='conv3_1')(pool2)\n",
    "    conv3 = layers.Conv2D(128, 3, activation='relu', padding='same', name='conv3_2')(conv3)\n",
    "    pool3 = layers.MaxPooling2D(pool_size=(2, 2), name='pool3')(conv3)\n",
    "\n",
    "    # Bottleneck\n",
    "    conv4 = layers.Conv2D(256, 3, activation='relu', padding='same', name='conv4_1')(pool3)\n",
    "    conv4 = layers.Conv2D(256, 3, activation='relu', padding='same', name='conv4_2')(conv4)\n",
    "\n",
    "    # Decoder\n",
    "    up5 = layers.Conv2DTranspose(128, 2, strides=(2, 2), padding='same', name='up5')(conv4)\n",
    "    merge5 = layers.concatenate([conv3, up5], axis=3, name='merge5')\n",
    "    conv5 = layers.Conv2D(128, 3, activation='relu', padding='same', name='conv5_1')(merge5)\n",
    "    conv5 = layers.Conv2D(128, 3, activation='relu', padding='same', name='conv5_2')(conv5)\n",
    "\n",
    "    up6 = layers.Conv2DTranspose(64, 2, strides=(2, 2), padding='same', name='up6')(conv5)\n",
    "    merge6 = layers.concatenate([conv2, up6], axis=3, name='merge6')\n",
    "    conv6 = layers.Conv2D(64, 3, activation='relu', padding='same', name='conv6_1')(merge6)\n",
    "    conv6 = layers.Conv2D(64, 3, activation='relu', padding='same', name='conv6_2')(conv6)\n",
    "\n",
    "    up7 = layers.Conv2DTranspose(32, 2, strides=(2, 2), padding='same', name='up7')(conv6)\n",
    "    merge7 = layers.concatenate([conv1, up7], axis=3, name='merge7')\n",
    "    conv7 = layers.Conv2D(32, 3, activation='relu', padding='same', name='conv7_1')(merge7)\n",
    "    conv7 = layers.Conv2D(32, 3, activation='relu', padding='same', name='conv7_2')(conv7)\n",
    "\n",
    "    # Output avec activation softmax\n",
    "    if mixed_precision_enabled:\n",
    "        conv7 = layers.Activation('linear', dtype='float32')(conv7)  # Cast to float32 before softmax\n",
    "\n",
    "    outputs = layers.Conv2D(NUM_CLASSES, 1, activation='softmax', name='output')(conv7)\n",
    "\n",
    "    model = models.Model(inputs, outputs, name='unet_mini_tf_2_15_compatible')\n",
    "    return model\n",
    "\n",
    "def create_vgg16_unet_tf_2_15():\n",
    "    \"\"\"\n",
    "    ‚úÖ VGG16 U-Net compatible TensorFlow 2.15+\n",
    "    Utilise input_shape au lieu de batch_shape pour compatibilit√© API\n",
    "    \"\"\"\n",
    "    # ‚úÖ INPUT_SHAPE au lieu de batch_shape\n",
    "    inputs = layers.Input(shape=INPUT_SHAPE, name='input')\n",
    "\n",
    "    # VGG16 Encoder (sans top)\n",
    "    vgg16_base = tf.keras.applications.VGG16(\n",
    "        weights='imagenet',\n",
    "        include_top=False,\n",
    "        input_tensor=inputs\n",
    "    )\n",
    "\n",
    "    # Extraire les skip connections VGG16\n",
    "    skip1 = vgg16_base.get_layer('block1_conv2').output  # 512x1024\n",
    "    skip2 = vgg16_base.get_layer('block2_conv2').output  # 256x512\n",
    "    skip3 = vgg16_base.get_layer('block3_conv3').output  # 128x256\n",
    "    skip4 = vgg16_base.get_layer('block4_conv3').output  # 64x128\n",
    "\n",
    "    # Bottleneck\n",
    "    bottleneck = vgg16_base.get_layer('block5_conv3').output  # 32x64\n",
    "\n",
    "    # Decoder U-Net\n",
    "    up6 = layers.Conv2DTranspose(512, 2, strides=2, padding='same', name='up6')(bottleneck)\n",
    "    merge6 = layers.concatenate([skip4, up6], axis=3, name='merge6')\n",
    "    conv6 = layers.Conv2D(512, 3, activation='relu', padding='same', name='conv6_1')(merge6)\n",
    "    conv6 = layers.Conv2D(512, 3, activation='relu', padding='same', name='conv6_2')(conv6)\n",
    "\n",
    "    up7 = layers.Conv2DTranspose(256, 2, strides=2, padding='same', name='up7')(conv6)\n",
    "    merge7 = layers.concatenate([skip3, up7], axis=3, name='merge7')\n",
    "    conv7 = layers.Conv2D(256, 3, activation='relu', padding='same', name='conv7_1')(merge7)\n",
    "    conv7 = layers.Conv2D(256, 3, activation='relu', padding='same', name='conv7_2')(conv7)\n",
    "\n",
    "    up8 = layers.Conv2DTranspose(128, 2, strides=2, padding='same', name='up8')(conv7)\n",
    "    merge8 = layers.concatenate([skip2, up8], axis=3, name='merge8')\n",
    "    conv8 = layers.Conv2D(128, 3, activation='relu', padding='same', name='conv8_1')(merge8)\n",
    "    conv8 = layers.Conv2D(128, 3, activation='relu', padding='same', name='conv8_2')(conv8)\n",
    "\n",
    "    up9 = layers.Conv2DTranspose(64, 2, strides=2, padding='same', name='up9')(conv8)\n",
    "    merge9 = layers.concatenate([skip1, up9], axis=3, name='merge9')\n",
    "    conv9 = layers.Conv2D(64, 3, activation='relu', padding='same', name='conv9_1')(merge9)\n",
    "    conv9 = layers.Conv2D(64, 3, activation='relu', padding='same', name='conv9_2')(conv9)\n",
    "    conv9 = layers.Conv2D(32, 3, activation='relu', padding='same', name='conv9_3')(conv9)\n",
    "\n",
    "    # Output avec activation softmax\n",
    "    if mixed_precision_enabled:\n",
    "        conv9 = layers.Activation('linear', dtype='float32')(conv9)  # Cast to float32 before softmax\n",
    "\n",
    "    outputs = layers.Conv2D(NUM_CLASSES, 1, activation='softmax', name='output')(conv9)\n",
    "\n",
    "    model = models.Model(inputs, outputs, name='vgg16_unet_tf_2_15_compatible')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a2f69d2",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "source": [
    "## üèóÔ∏è Architectures Suppl√©mentaires - Mod√®les Avanc√©s\n",
    "Impl√©mentation des mod√®les avanc√©s depuis 2.2_Model_Implementation.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17264106",
   "metadata": {
    "lines_to_next_cell": 1,
    "title": "[python]"
   },
   "outputs": [],
   "source": [
    "class SegmentationModel:\n",
    "    \"\"\"\n",
    "    Classe de base pour tous les mod√®les de segmentation.\n",
    "    Fournit une interface commune et des utilities partag√©es.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, input_shape=(512, 1024, 3), num_classes=8, name=\"BaseSegmentationModel\"):\n",
    "        self.input_shape = input_shape\n",
    "        self.num_classes = num_classes\n",
    "        self.name = name\n",
    "        self.model = None\n",
    "        \n",
    "    def build_model(self):\n",
    "        \"\"\"√Ä impl√©menter dans les classes filles\"\"\"\n",
    "        raise NotImplementedError(\"Subclasses must implement build_model\")\n",
    "    \n",
    "    def compile_model(self, optimizer='adam', loss='sparse_categorical_crossentropy', metrics=None):\n",
    "        \"\"\"Compile le mod√®le avec les param√®tres sp√©cifi√©s\"\"\"\n",
    "        if metrics is None:\n",
    "            metrics = ['accuracy']\n",
    "            \n",
    "        if self.model is None:\n",
    "            raise ValueError(\"Model must be built before compilation\")\n",
    "            \n",
    "        self.model.compile(\n",
    "            optimizer=optimizer,\n",
    "            loss=loss,\n",
    "            metrics=metrics\n",
    "        )\n",
    "        \n",
    "        print(f\"‚úÖ Mod√®le {self.name} compil√©\")\n",
    "        \n",
    "    def get_model_info(self):\n",
    "        \"\"\"Retourne les informations du mod√®le\"\"\"\n",
    "        if self.model is None:\n",
    "            return {\"error\": \"Model not built\"}\n",
    "            \n",
    "        total_params = self.model.count_params()\n",
    "        trainable_params = sum([tf.keras.backend.count_params(w) for w in self.model.trainable_weights])\n",
    "        \n",
    "        return {\n",
    "            'name': self.name,\n",
    "            'total_params': total_params,\n",
    "            'trainable_params': trainable_params,\n",
    "            'input_shape': self.input_shape,\n",
    "            'output_shape': self.model.output_shape,\n",
    "            'layers': len(self.model.layers)\n",
    "        }\n",
    "    \n",
    "    def summary(self):\n",
    "        \"\"\"Affiche le r√©sum√© du mod√®le\"\"\"\n",
    "        if self.model is not None:\n",
    "            return self.model.summary()\n",
    "        else:\n",
    "            print(\"‚ùå Mod√®le non construit\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "728cd02d",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "source": [
    "### üî• Architecture 3: U-Net + EfficientNet\n",
    "Encoder-Decoder avec skip connections et backbone efficace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8b4b0df",
   "metadata": {
    "lines_to_next_cell": 1,
    "title": "[python]"
   },
   "outputs": [],
   "source": [
    "class UNetEfficientNet(SegmentationModel):\n",
    "    \"\"\"\n",
    "    U-Net avec backbone EfficientNet pour encodage efficace\n",
    "    Compatible TensorFlow 2.18\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, backbone='B0', input_shape=(512, 1024, 3), num_classes=8, freeze_backbone=False):\n",
    "        super().__init__(input_shape, num_classes, f\"UNet_EfficientNet{backbone}\")\n",
    "        self.backbone_name = backbone\n",
    "        self.freeze_backbone = freeze_backbone\n",
    "        \n",
    "    def build_model(self):\n",
    "        \"\"\"Construit le mod√®le U-Net avec EfficientNet backbone\"\"\"\n",
    "        \n",
    "        # S√©lection du backbone\n",
    "        if self.backbone_name == 'B0':\n",
    "            backbone = tf.keras.applications.EfficientNetB0(weights='imagenet', include_top=False, input_shape=self.input_shape)\n",
    "        elif self.backbone_name == 'B1':\n",
    "            backbone = tf.keras.applications.EfficientNetB1(weights='imagenet', include_top=False, input_shape=self.input_shape)\n",
    "        elif self.backbone_name == 'B2':\n",
    "            backbone = tf.keras.applications.EfficientNetB2(weights='imagenet', include_top=False, input_shape=self.input_shape)\n",
    "        else:\n",
    "            raise ValueError(f\"Backbone {self.backbone_name} non support√©\")\n",
    "        \n",
    "        # Gel du backbone si sp√©cifi√©\n",
    "        if self.freeze_backbone:\n",
    "            backbone.trainable = False\n",
    "            \n",
    "        # Points d'extraction pour skip connections\n",
    "        skip_layer_names = {\n",
    "            'B0': ['block2a_expand_activation', 'block3a_expand_activation', \n",
    "                   'block4a_expand_activation', 'block6a_expand_activation'],\n",
    "            'B1': ['block2a_expand_activation', 'block3a_expand_activation', \n",
    "                   'block4a_expand_activation', 'block6a_expand_activation'],\n",
    "            'B2': ['block2a_expand_activation', 'block3a_expand_activation', \n",
    "                   'block4a_expand_activation', 'block6a_expand_activation']\n",
    "        }\n",
    "        \n",
    "        # Extraction des features pour skip connections\n",
    "        skip_layers = [backbone.get_layer(name).output for name in skip_layer_names[self.backbone_name]]\n",
    "        \n",
    "        # Input\n",
    "        inputs = backbone.input\n",
    "        \n",
    "        # Encoder (bottom)\n",
    "        encoder_output = backbone.output\n",
    "        \n",
    "        # Bridge\n",
    "        bridge = layers.Conv2D(512, 3, padding='same', activation='relu', \n",
    "                              kernel_regularizer=tf.keras.regularizers.l2(1e-4))(encoder_output)\n",
    "        bridge = layers.BatchNormalization()(bridge)\n",
    "        bridge = layers.Dropout(0.3)(bridge)\n",
    "        \n",
    "        # Decoder avec skip connections\n",
    "        x = bridge\n",
    "        \n",
    "        # Calcul automatique des tailles d'upsampling\n",
    "        skip_filters = [256, 128, 64, 32]\n",
    "        \n",
    "        for i, (skip_layer, filters) in enumerate(zip(reversed(skip_layers), skip_filters)):\n",
    "            # Upsampling\n",
    "            x = layers.UpSampling2D(2, interpolation='bilinear')(x)\n",
    "            \n",
    "            # Ajustement de la taille si n√©cessaire\n",
    "            skip_shape = skip_layer.shape[1:3]\n",
    "            x_shape = x.shape[1:3]\n",
    "            \n",
    "            # Redimensionnement pour correspondre au skip layer\n",
    "            if skip_shape != x_shape:\n",
    "                x = layers.Resizing(skip_shape[0], skip_shape[1])(x)\n",
    "            \n",
    "            # Concatenation avec skip connection\n",
    "            x = layers.Concatenate()([x, skip_layer])\n",
    "            \n",
    "            # Convolutions du decoder\n",
    "            x = layers.Conv2D(filters, 3, padding='same', activation='relu',\n",
    "                             kernel_regularizer=tf.keras.regularizers.l2(1e-4))(x)\n",
    "            x = layers.BatchNormalization()(x)\n",
    "            x = layers.Conv2D(filters, 3, padding='same', activation='relu',\n",
    "                             kernel_regularizer=tf.keras.regularizers.l2(1e-4))(x)\n",
    "            x = layers.BatchNormalization()(x)\n",
    "            x = layers.Dropout(0.15)(x)\n",
    "        \n",
    "        # Upsampling final pour retrouver la taille d'origine\n",
    "        x = layers.UpSampling2D(4, interpolation='bilinear')(x)\n",
    "        \n",
    "        # Ajustement final de taille\n",
    "        if x.shape[1:3] != self.input_shape[:2]:\n",
    "            x = layers.Resizing(self.input_shape[0], self.input_shape[1])(x)\n",
    "        \n",
    "        # Couche de classification finale\n",
    "        if mixed_precision_enabled:\n",
    "            x = layers.Activation('linear', dtype='float32')(x)  # Cast to float32 before softmax\n",
    "        \n",
    "        outputs = layers.Conv2D(self.num_classes, 1, activation='softmax', name='segmentation_output')(x)\n",
    "        \n",
    "        self.model = models.Model(inputs=inputs, outputs=outputs, name=self.name)\n",
    "        \n",
    "        print(f\"‚úÖ {self.name} construit avec succ√®s\")\n",
    "        return self.model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a26b3af",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "source": [
    "### üöÄ Architecture 4: DeepLabV3+ + MobileNet\n",
    "ASPP + Decoder l√©ger avec backbone mobile optimis√©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "594621f0",
   "metadata": {
    "lines_to_next_cell": 1,
    "title": "[python]"
   },
   "outputs": [],
   "source": [
    "class DeepLabV3Plus(SegmentationModel):\n",
    "    \"\"\"\n",
    "    DeepLabV3+ avec backbone MobileNetV2 pour efficacit√© embarqu√©e\n",
    "    Compatible TensorFlow 2.18\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, input_shape=(512, 1024, 3), num_classes=8, output_stride=16):\n",
    "        super().__init__(input_shape, num_classes, \"DeepLabV3Plus_MobileNetV2\")\n",
    "        self.output_stride = output_stride\n",
    "        # D√©duire statiquement les r√©solutions interm√©diaires\n",
    "        h, w, _ = input_shape\n",
    "        # MobileNetV2 reduce spatial by factor 32 by default\n",
    "        self.low_res = (h // 4, w // 4)    # bloc_1_expand_relu ‚Üí 1/4\n",
    "        self.high_res = (h // 32, w // 32) # backbone.output ‚Üí 1/32\n",
    "\n",
    "    def atrous_spatial_pyramid_pooling(self, x):\n",
    "        \"\"\"\n",
    "        ASPP statique : chaque branche est redimensionn√©e\n",
    "        en fonction de self.high_res, connu √† l'instanciation.\n",
    "        \"\"\"\n",
    "        # Branch 1: 1x1 conv\n",
    "        b1 = layers.Conv2D(256, 1, padding='same', activation='relu',\n",
    "                           kernel_regularizer=tf.keras.regularizers.l2(1e-4))(x)\n",
    "        b1 = layers.BatchNormalization()(b1)\n",
    "\n",
    "        # Branch 2-4: atrous conv\n",
    "        branches = [b1]\n",
    "        for rate in (6, 12, 18):\n",
    "            b = layers.Conv2D(256, 3, padding='same', dilation_rate=rate,\n",
    "                              activation='relu', kernel_regularizer=tf.keras.regularizers.l2(1e-4))(x)\n",
    "            b = layers.BatchNormalization()(b)\n",
    "            branches.append(b)\n",
    "\n",
    "        # Branch 5: global pooling\n",
    "        gp = layers.GlobalAveragePooling2D()(x)              # (batch, C)\n",
    "        gp = layers.Reshape((1, 1, x.shape[-1]))(gp)        # (batch,1,1,C)\n",
    "        gp = layers.Conv2D(256, 1, activation='relu',\n",
    "                           kernel_regularizer=tf.keras.regularizers.l2(1e-4))(gp)\n",
    "        gp = layers.BatchNormalization()(gp)\n",
    "        # Upsample statique vers high_res\n",
    "        gp = layers.Resizing(self.high_res[0], self.high_res[1],\n",
    "                             interpolation='bilinear')(gp)\n",
    "        branches.append(gp)\n",
    "\n",
    "        # Concat + conv final\n",
    "        concat = layers.Concatenate()(branches)\n",
    "        out = layers.Conv2D(256, 1, padding='same', activation='relu',\n",
    "                            kernel_regularizer=tf.keras.regularizers.l2(1e-4))(concat)\n",
    "        out = layers.BatchNormalization()(out)\n",
    "        out = layers.Dropout(0.3)(out)\n",
    "        return out\n",
    "\n",
    "    def build_model(self):\n",
    "        inputs = layers.Input(shape=self.input_shape)\n",
    "\n",
    "        # Backbone MobileNetV2\n",
    "        backbone = tf.keras.applications.MobileNetV2(weights='imagenet', include_top=False,\n",
    "                              input_tensor=inputs, alpha=1.0)\n",
    "\n",
    "        # Low-level (1/4) et high-level (1/32) features\n",
    "        low_feat  = backbone.get_layer('block_3_expand_relu').output\n",
    "        high_feat = backbone.output\n",
    "\n",
    "        # ASPP + upsampling direct vers low_res\n",
    "        aspp = self.atrous_spatial_pyramid_pooling(high_feat)\n",
    "        x = layers.Resizing(self.low_res[0], self.low_res[1],\n",
    "                            interpolation='bilinear')(aspp)\n",
    "\n",
    "        # R√©duction des low-level features puis concat\n",
    "        low = layers.Conv2D(48, 1, padding='same', activation='relu',\n",
    "                            kernel_regularizer=tf.keras.regularizers.l2(1e-4))(low_feat)\n",
    "        low = layers.BatchNormalization()(low)\n",
    "        concat = layers.Concatenate()([x, low])\n",
    "\n",
    "        # Decoder final\n",
    "        x = layers.Conv2D(256, 3, padding='same', activation='relu',\n",
    "                          kernel_regularizer=tf.keras.regularizers.l2(1e-4))(concat)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "        x = layers.Dropout(0.3)(x)\n",
    "\n",
    "        # Upsample final vers r√©solution d'entr√©e\n",
    "        x = layers.Resizing(self.input_shape[0], self.input_shape[1],\n",
    "                            interpolation='bilinear')(x)\n",
    "\n",
    "        # Mixed precision support\n",
    "        if mixed_precision_enabled:\n",
    "            x = layers.Activation('linear', dtype='float32')(x)\n",
    "\n",
    "        outputs = layers.Conv2D(self.num_classes, 1,\n",
    "                                activation='softmax',\n",
    "                                name='segmentation_output')(x)\n",
    "\n",
    "        self.model = models.Model(inputs=inputs, outputs=outputs, name=self.name)\n",
    "        print(f\"‚úÖ {self.name} construit avec succ√®s\")\n",
    "        return self.model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d65d751",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "source": [
    "### üåü Architecture 5: Segformer-B0 (Vision Transformer)\n",
    "Architecture Transformer adapt√©e √† la segmentation, version l√©g√®re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de283501",
   "metadata": {
    "title": "[python]"
   },
   "outputs": [],
   "source": [
    "# Couche d'attention efficace pour Segformer\n",
    "class EfficientSelfAttention(layers.Layer):\n",
    "    def __init__(self, num_heads, sr_ratio=1, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.num_heads = num_heads\n",
    "        self.sr_ratio = sr_ratio\n",
    "        self.norm = layers.LayerNormalization()\n",
    "        self.attn = None\n",
    "        self.reduce = None\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        embed_dim = input_shape[-1]\n",
    "        if self.sr_ratio > 1:\n",
    "            self.reduce = layers.Conv2D(\n",
    "                embed_dim,\n",
    "                kernel_size=self.sr_ratio,\n",
    "                strides=self.sr_ratio,\n",
    "                padding='same'\n",
    "            )\n",
    "        self.attn = layers.MultiHeadAttention(\n",
    "            num_heads=self.num_heads,\n",
    "            key_dim=embed_dim // self.num_heads,\n",
    "            attention_axes=(1, 2),\n",
    "            dropout=0.1\n",
    "        )\n",
    "        super().build(input_shape)\n",
    "\n",
    "    def call(self, x):\n",
    "        kv = x\n",
    "        if self.sr_ratio > 1:\n",
    "            kv = self.reduce(x)\n",
    "            kv = self.norm(kv)\n",
    "        return self.attn(query=x, key=kv, value=kv)\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape\n",
    "\n",
    "class SegformerB0(SegmentationModel):\n",
    "    \"\"\"\n",
    "    Segformer-B0: Vision Transformer l√©ger pour segmentation s√©mantique\n",
    "    Compatible TensorFlow 2.18\n",
    "    \"\"\"\n",
    "    def __init__(self, input_shape=(512, 1024, 3), num_classes=8, patch_size=4):\n",
    "        super().__init__(input_shape, num_classes, \"Segformer_B0\")\n",
    "        self.patch_size = patch_size\n",
    "        self.embed_dims = [32, 64, 160, 256]\n",
    "        self.num_heads = [1, 2, 5, 8]\n",
    "        self.depths = [2, 2, 2, 2]\n",
    "\n",
    "    def overlap_patch_embed(self, x, embed_dim, patch_size=7, stride=4):\n",
    "        x = layers.Conv2D(\n",
    "            embed_dim,\n",
    "            kernel_size=patch_size,\n",
    "            strides=stride,\n",
    "            padding='same',\n",
    "            kernel_regularizer=tf.keras.regularizers.l2(1e-4)\n",
    "        )(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "        return x\n",
    "\n",
    "    def mix_ffn(self, x, embed_dim, expansion_factor=4):\n",
    "        expanded_dim = embed_dim * expansion_factor\n",
    "        x = layers.Dense(expanded_dim, activation='gelu')(x)\n",
    "        x = layers.DepthwiseConv2D(3, padding='same')(x)\n",
    "        x = layers.Dense(embed_dim)(x)\n",
    "        return x\n",
    "\n",
    "    def transformer_block(self, x, embed_dim, num_heads, sr_ratio=1):\n",
    "        shortcut = x\n",
    "        x = layers.LayerNormalization()(x)\n",
    "        x = EfficientSelfAttention(num_heads=num_heads, sr_ratio=sr_ratio)(x)\n",
    "        x = layers.Add()([shortcut, x])\n",
    "        shortcut = x\n",
    "        x = layers.LayerNormalization()(x)\n",
    "        x = self.mix_ffn(x, embed_dim)\n",
    "        x = layers.Add()([shortcut, x])\n",
    "        return x\n",
    "\n",
    "    def build_model(self):\n",
    "        inputs = layers.Input(shape=self.input_shape)\n",
    "        x = inputs\n",
    "        encoder_features = []\n",
    "        patch_sizes = [7, 3, 3, 3]\n",
    "        strides = [4, 2, 2, 2]\n",
    "        sr_ratios = [8, 4, 2, 1]\n",
    "\n",
    "        for i, (embed_dim, num_heads, depth) in enumerate(zip(self.embed_dims, self.num_heads, self.depths)):\n",
    "            x = self.overlap_patch_embed(x, embed_dim, patch_sizes[i], strides[i])\n",
    "            for _ in range(depth):\n",
    "                x = self.transformer_block(x, embed_dim, num_heads, sr_ratios[i])\n",
    "            encoder_features.append(x)\n",
    "\n",
    "        # Decoder: upsample chaque feature vers 1/4 de la r√©solution d'entr√©e (128x256)\n",
    "        decoder_features = []\n",
    "        for i, features in enumerate(encoder_features):\n",
    "            projected = layers.Conv2D(256, 1, padding='same')(features)\n",
    "            upsampling_factor = 2 ** i  # i=0:1, i=1:2, i=2:4, i=3:8\n",
    "            if upsampling_factor > 1:\n",
    "                projected = layers.UpSampling2D(upsampling_factor, interpolation='bilinear')(projected)\n",
    "            decoder_features.append(projected)\n",
    "\n",
    "        fused = layers.Concatenate()(decoder_features)\n",
    "        x = layers.Conv2D(256, 1, padding='same', activation='relu')(fused)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "        x = layers.Dropout(0.3)(x)\n",
    "        x = layers.UpSampling2D(4, interpolation='bilinear')(x)\n",
    "        \n",
    "        # Mixed precision support\n",
    "        if mixed_precision_enabled:\n",
    "            x = layers.Activation('linear', dtype='float32')(x)\n",
    "            \n",
    "        outputs = layers.Conv2D(\n",
    "            self.num_classes, 1,\n",
    "            activation='softmax',\n",
    "            name='segmentation_output'\n",
    "        )(x)\n",
    "\n",
    "        self.model = models.Model(inputs=inputs, outputs=outputs, name=self.name)\n",
    "        print(f\"‚úÖ {self.name} construit avec succ√®s\")\n",
    "        return self.model\n",
    "\n",
    "print(\"‚úÖ Model architectures loaded:\")\n",
    "print(\"   - UNet Mini (TF 2.18 compatible with input_shape)\")\n",
    "print(\"   - VGG16 U-Net (TF 2.18 compatible with input_shape)\")\n",
    "print(\"   - UNet EfficientNet-B0 (TF 2.18 compatible)\")\n",
    "print(\"   - DeepLabV3+ MobileNetV2 (TF 2.18 compatible)\")\n",
    "print(\"   - Segformer-B0 (TF 2.18 compatible)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aeb93fb",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "## üéØ Setup des Donn√©es Google Colab\n",
    "Configuration automatique des donn√©es Cityscapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8159cced",
   "metadata": {
    "title": "[python]"
   },
   "outputs": [],
   "source": [
    "def setup_data_paths():\n",
    "    \"\"\"Configuration automatique des chemins de donn√©es\"\"\"\n",
    "\n",
    "    # Google Colab setup\n",
    "    try:\n",
    "        import google.colab\n",
    "        print(\"üîß Google Colab detected - Setting up data access...\")\n",
    "\n",
    "        # Authentification Google Cloud\n",
    "        from google.cloud import storage\n",
    "        import os\n",
    "\n",
    "        # Configuration des chemins GCS\n",
    "        base_path = \"gs://cityscapes_data2\"\n",
    "        train_images_path = f\"{base_path}/leftimg8bit/train\"\n",
    "        train_masks_path = f\"{base_path}/gtFine/train\"\n",
    "        val_images_path = f\"{base_path}/leftimg8bit/val\"\n",
    "        val_masks_path = f\"{base_path}/gtFine/val\"\n",
    "\n",
    "\n",
    "        # Forcer le rechargement des donn√©es Cityscapes\n",
    "        import os\n",
    "        import shutil\n",
    "                # Nettoyer l'ancien cache\n",
    "        if os.path.exists('/content/data'):\n",
    "           shutil.rmtree('/content/data')\n",
    "\n",
    "\n",
    "        # T√©l√©charger un √©chantillon pour l'entra√Ænement\n",
    "        print(\"üì• Downloading Cityscapes sample data...\")\n",
    "        os.system(\"gsutil -m cp -r gs://cityscapes_data2/leftimg8bit/train/* /tmp/train_images/ 2>/dev/null || mkdir -p /tmp/train_images\")\n",
    "        os.system(\"gsutil -m cp -r gs://cityscapes_data2/gtFine/train/* /tmp/train_masks/ 2>/dev/null || mkdir -p /tmp/train_masks\")\n",
    "        os.system(\"gsutil -m cp -r gs://cityscapes_data2/leftimg8bit/val/* /tmp/val_images/ 2>/dev/null || mkdir -p /tmp/val_images\")\n",
    "        os.system(\"gsutil -m cp -r gs://cityscapes_data2/gtFine/val/* /tmp/val_masks/ 2>/dev/null || mkdir -p /tmp/val_masks\")\n",
    "\n",
    "        train_images_path = \"/tmp/train_images\"\n",
    "        train_masks_path = \"/tmp/train_masks\"\n",
    "        val_images_path = \"/tmp/val_images\"\n",
    "        val_masks_path = \"/tmp/val_masks\"\n",
    "\n",
    "        is_colab = True\n",
    "\n",
    "    except ImportError:\n",
    "        # Local setup\n",
    "        print(\"üñ•Ô∏è Local environment detected\")\n",
    "\n",
    "        # V√©rifier si les donn√©es existent localement\n",
    "        local_data_path = Path(\"../data\")  # Chemin relatif depuis notebooks/\n",
    "\n",
    "        if local_data_path.exists():\n",
    "            train_images_path = str(local_data_path / \"leftImg8bit/train\")\n",
    "            train_masks_path = str(local_data_path / \"gtFine/train\")\n",
    "            val_images_path = str(local_data_path / \"leftImg8bit/val\")\n",
    "            val_masks_path = str(local_data_path / \"gtFine/val\")\n",
    "        else:\n",
    "            # Chemins par d√©faut pour donn√©es locales\n",
    "            train_images_path = \"/tmp/train_images\"\n",
    "            train_masks_path = \"/tmp/train_masks\"\n",
    "            val_images_path = \"/tmp/val_images\"\n",
    "            val_masks_path = \"/tmp/val_masks\"\n",
    "\n",
    "            # Cr√©er dossiers vides pour √©viter erreurs\n",
    "            for path in [train_images_path, train_masks_path, val_images_path, val_masks_path]:\n",
    "                os.makedirs(path, exist_ok=True)\n",
    "\n",
    "        is_colab = False\n",
    "\n",
    "    return {\n",
    "        'train_images': train_images_path,\n",
    "        'train_masks': train_masks_path,\n",
    "        'val_images': val_images_path,\n",
    "        'val_masks': val_masks_path,\n",
    "        'is_colab': is_colab\n",
    "    }\n",
    "\n",
    "def collect_cityscapes_files(images_dir, masks_dir):\n",
    "    \"\"\"Collecte les fichiers Cityscapes avec gestion des sous-dossiers ville\"\"\"\n",
    "    image_files = []\n",
    "    mask_files = []\n",
    "\n",
    "    if not os.path.exists(images_dir) or not os.path.exists(masks_dir):\n",
    "        print(f\"‚ö†Ô∏è Directories not found: {images_dir} or {masks_dir}\")\n",
    "        return [], []\n",
    "\n",
    "    # Explorer tous les sous-dossiers (villes)\n",
    "    for city_dir in os.listdir(images_dir):\n",
    "        city_images_path = os.path.join(images_dir, city_dir)\n",
    "        city_masks_path = os.path.join(masks_dir, city_dir)\n",
    "\n",
    "        if not os.path.isdir(city_images_path):\n",
    "            continue\n",
    "\n",
    "        # Collecter les fichiers de cette ville\n",
    "        for image_file in os.listdir(city_images_path):\n",
    "            if image_file.endswith('_leftImg8bit.png'):\n",
    "                # Construire le nom du masque correspondant\n",
    "                mask_file = image_file.replace('_leftImg8bit.png', '_gtFine_labelIds.png')\n",
    "\n",
    "                image_path = os.path.join(city_images_path, image_file)\n",
    "                mask_path = os.path.join(city_masks_path, mask_file)\n",
    "\n",
    "                # V√©rifier que les deux fichiers existent\n",
    "                if os.path.exists(image_path) and os.path.exists(mask_path):\n",
    "                    image_files.append(image_path)\n",
    "                    mask_files.append(mask_path)\n",
    "\n",
    "    return image_files, mask_files\n",
    "\n",
    "# Setup des donn√©es\n",
    "data_config = setup_data_paths()\n",
    "print(f\"üìÅ Data configuration: {data_config}\")\n",
    "\n",
    "# Collecter les fichiers d'entra√Ænement et validation\n",
    "train_images, train_masks = collect_cityscapes_files(\n",
    "    data_config['train_images'],\n",
    "    data_config['train_masks']\n",
    ")\n",
    "\n",
    "val_images, val_masks = collect_cityscapes_files(\n",
    "    data_config['val_images'],\n",
    "    data_config['val_masks']\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ Data collected:\")\n",
    "print(f\"   Train: {len(train_images)} images\")\n",
    "print(f\"   Validation: {len(val_images)} images\")\n",
    "\n",
    "# Cr√©er des g√©n√©rateurs de donn√©es\n",
    "augmentation_pipeline = get_augmentation_pipeline()\n",
    "\n",
    "train_generator = CityscapesDataGenerator(\n",
    "    train_images, train_masks,\n",
    "    batch_size=TRAINING_CONFIG['training']['batch_size'],\n",
    "    augmentation=augmentation_pipeline,\n",
    "    shuffle=True,\n",
    "    max_samples=TRAINING_CONFIG['data']['max_train_samples']\n",
    ")\n",
    "\n",
    "val_generator = CityscapesDataGenerator(\n",
    "    val_images, val_masks,\n",
    "    batch_size=TRAINING_CONFIG['training']['batch_size'],\n",
    "    augmentation=None,\n",
    "    shuffle=False,\n",
    "    max_samples=TRAINING_CONFIG['data']['max_val_samples']\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ Data generators created:\")\n",
    "print(f\"   Train batches: {len(train_generator)}\")\n",
    "print(f\"   Validation batches: {len(val_generator)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5b5a1c9",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "## üîß Infrastructure d'Entra√Ænement & Gestion des Mod√®les"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcbcc70b",
   "metadata": {
    "lines_to_next_cell": 1,
    "title": "[python]"
   },
   "outputs": [],
   "source": [
    "# ‚úÖ Sauvegarder .keras\n",
    "class KerasModelCheckpoint(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, filepath, monitor='val_loss', save_best_only=False, mode='auto', verbose=0):\n",
    "        super().__init__()\n",
    "        self.filepath = filepath\n",
    "        self.monitor = monitor\n",
    "        self.save_best_only = save_best_only\n",
    "        self.mode = mode\n",
    "        self.verbose = verbose\n",
    "        self.best = None\n",
    "\n",
    "        if mode == 'max':\n",
    "            self.monitor_op = lambda a, b: a > b\n",
    "            self.best = -float('inf')\n",
    "        elif mode == 'min':\n",
    "            self.monitor_op = lambda a, b: a < b\n",
    "            self.best = float('inf')\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        logs = logs or {}\n",
    "        current = logs.get(self.monitor)\n",
    "\n",
    "        if current is None:\n",
    "            return\n",
    "\n",
    "        if not self.save_best_only or self.monitor_op(current, self.best):\n",
    "            if self.verbose > 0:\n",
    "                print(f'\\nEpoch {epoch+1}: {self.monitor} improved from {self.best:.5f} to {current:.5f},saving model to {self.filepath}')\n",
    "\n",
    "            self.best = current\n",
    "            # Format .keras\n",
    "            self.model.save(f\"{self.filepath}.keras\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e27fb205",
   "metadata": {
    "cell_marker": "\"\"\"",
    "lines_to_next_cell": 0
   },
   "source": [
    "üèãÔ∏è TRAINING INFRASTRUCTURE\n",
    "Infrastructure d'entra√Ænement avec callbacks et sauvegarde"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "796bbf5c",
   "metadata": {
    "title": "[python]"
   },
   "outputs": [],
   "source": [
    "def create_model_callbacks(model_name, patience=8):\n",
    "      \"\"\"Cr√©e les callbacks pour l'entra√Ænement\"\"\"\n",
    "      timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "      model_callbacks = [\n",
    "          tf.keras.callbacks.EarlyStopping(\n",
    "              monitor='val_loss',\n",
    "              patience=patience,\n",
    "              restore_best_weights=True,\n",
    "              verbose=1\n",
    "          ),\n",
    "      KerasModelCheckpoint(\n",
    "          filepath=f'models/best_{model_name}_{timestamp}',\n",
    "          monitor='val_mean_iou',\n",
    "          save_best_only=True,\n",
    "          mode='max',\n",
    "          verbose=1\n",
    "          ),\n",
    "          tf.keras.callbacks.ReduceLROnPlateau(\n",
    "              monitor='val_loss',\n",
    "              factor=0.5,\n",
    "              patience=4,\n",
    "              min_lr=1e-7,\n",
    "              verbose=1\n",
    "          ),\n",
    "          tf.keras.callbacks.CSVLogger(f'training_history_{model_name}_{timestamp}.csv')\n",
    "      ]\n",
    "\n",
    "      return model_callbacks, timestamp\n",
    "\n",
    "def compile_model_tf_2_15(model, optimizer='adam'):\n",
    "    \"\"\"Compilation mod√®le pour TF 2.15+ avec m√©triques compl√®tes\"\"\"\n",
    "\n",
    "    if mixed_precision_enabled:\n",
    "        # Optimiseur avec mixed precision\n",
    "        optimizer = tf.keras.optimizers.Adam(learning_rate=TRAINING_CONFIG['training']['learning_rate'])\n",
    "        optimizer = tf.keras.mixed_precision.LossScaleOptimizer(optimizer)\n",
    "    else:\n",
    "        optimizer = tf.keras.optimizers.Adam(learning_rate=TRAINING_CONFIG['training']['learning_rate'])\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss=CombinedLoss(dice_weight=0.5, ce_weight=0.5, class_weights=CLASS_WEIGHTS),\n",
    "        metrics=[\n",
    "            MeanIoU(num_classes=NUM_CLASSES),\n",
    "            DiceCoefficient(),\n",
    "            'accuracy'\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    return model\n",
    "\n",
    "def train_model_with_monitoring(model, model_name, train_gen, val_gen):\n",
    "    \"\"\"Entra√Ænement avec monitoring complet et SavedModel\"\"\"\n",
    "\n",
    "    print(f\"\\nüöÄ Training {model_name}...\")\n",
    "    print(f\"üìä Model parameters: {model.count_params():,}\")\n",
    "\n",
    "    # Callbacks avec SavedModel\n",
    "    model_callbacks, timestamp = create_model_callbacks(model_name, patience=TRAINING_CONFIG['training']['patience'])\n",
    "\n",
    "    # Monitoring syst√®me\n",
    "    def memory_usage():\n",
    "        process = psutil.Process(os.getpid())\n",
    "        return process.memory_info().rss / 1024 / 1024  # MB\n",
    "\n",
    "    print(f\"üíæ Memory before training: {memory_usage():.1f} MB\")\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    try:\n",
    "        history = model.fit(\n",
    "            train_gen,\n",
    "            validation_data=val_gen,\n",
    "            epochs=TRAINING_CONFIG['training']['epochs'],\n",
    "            callbacks=model_callbacks,\n",
    "            verbose=1\n",
    "        )\n",
    "\n",
    "        training_time = time.time() - start_time\n",
    "        print(f\"‚è±Ô∏è Training completed in {training_time/60:.1f} minutes\")\n",
    "\n",
    "        # ‚úÖ SAUVEGARDER EN .keras (format moderne)\n",
    "        final_model_path = f\"models/{model_name}_tf_2_15_final_{timestamp}.keras\"\n",
    "        model.save(final_model_path)  # ‚úÖ Pas de save_format n√©cessaire\n",
    "        print(f\"üéØ Final Keras model saved: {final_model_path}\")\n",
    "\n",
    "        # ‚úÖ BACKUP H5 (optionnel)\n",
    "        h5_backup_path = f\"models/{model_name}_tf_2_15_backup_{timestamp}.h5\"\n",
    "        model.save(h5_backup_path)\n",
    "        print(f\"üì¶ H5 backup saved: {h5_backup_path}\")\n",
    "\n",
    "        return {\n",
    "            'model': model,\n",
    "            'history': history,\n",
    "            'training_time': training_time,\n",
    "            'timestamp': timestamp,\n",
    "            'model_path': final_model_path,  # ‚úÖ SavedModel principal\n",
    "            'h5_backup_path': h5_backup_path,  # ‚úÖ H5 backup\n",
    "            'final_metrics': {\n",
    "                'val_loss': history.history['val_loss'][-1],\n",
    "                'val_mean_iou': history.history['val_mean_iou'][-1],\n",
    "                'val_dice_coefficient': history.history['val_dice_coefficient'][-1],\n",
    "                'val_accuracy': history.history['val_accuracy'][-1]\n",
    "            }\n",
    "        }\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Training failed for {model_name}: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "# Monitoring m√©moire en temps r√©el pour Colab L4\n",
    "def monitor_memory_usage():\n",
    "    \"\"\"Monitoring en temps r√©el de l'usage m√©moire GPU et RAM\"\"\"\n",
    "    try:\n",
    "        # M√©moire RAM\n",
    "        process = psutil.Process(os.getpid())\n",
    "        ram_usage = process.memory_info().rss / 1024 / 1024 / 1024  # GB\n",
    "        \n",
    "        # M√©moire GPU si disponible\n",
    "        gpu_memory_used = 0\n",
    "        gpu_memory_total = 0\n",
    "        \n",
    "        if gpus:\n",
    "            try:\n",
    "                memory_info = tf.config.experimental.get_memory_info('GPU:0')\n",
    "                gpu_memory_used = memory_info['current'] / 1024 / 1024 / 1024  # GB\n",
    "                # Estimation bas√©e sur L4\n",
    "                gpu_memory_total = 16  # L4 a 16GB\n",
    "            except:\n",
    "                pass\n",
    "        \n",
    "        return {\n",
    "            'ram_gb': ram_usage,\n",
    "            'gpu_used_gb': gpu_memory_used,\n",
    "            'gpu_total_gb': gpu_memory_total,\n",
    "            'gpu_percent': (gpu_memory_used / gpu_memory_total * 100) if gpu_memory_total > 0 else 0\n",
    "        }\n",
    "    except:\n",
    "        return {'ram_gb': 0, 'gpu_used_gb': 0, 'gpu_total_gb': 0, 'gpu_percent': 0}\n",
    "\n",
    "def cleanup_memory(verbose=True):\n",
    "    \"\"\"Nettoyage m√©moire agressif optimis√© pour Colab L4\"\"\"\n",
    "    if verbose:\n",
    "        before = monitor_memory_usage()\n",
    "    \n",
    "    # Nettoyage TensorFlow\n",
    "    tf.keras.backend.clear_session()\n",
    "    \n",
    "    # Nettoyage Python\n",
    "    import gc\n",
    "    gc.collect()\n",
    "    \n",
    "    # Forcer le nettoyage GPU\n",
    "    if gpus:\n",
    "        try:\n",
    "            # R√©initialiser le contexte GPU\n",
    "            tf.config.experimental.reset_memory_stats('GPU:0')\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    if verbose:\n",
    "        after = monitor_memory_usage()\n",
    "        print(f\"üßπ Nettoyage m√©moire:\")\n",
    "        print(f\"   RAM: {before['ram_gb']:.1f}GB ‚Üí {after['ram_gb']:.1f}GB\")\n",
    "        print(f\"   GPU: {before['gpu_used_gb']:.1f}GB ‚Üí {after['gpu_used_gb']:.1f}GB ({after['gpu_percent']:.1f}%)\")\n",
    "\n",
    "# Cr√©er dossier models\n",
    "os.makedirs('models', exist_ok=True)\n",
    "\n",
    "print(\"‚úÖ Training infrastructure ready:\")\n",
    "print(\"   - Custom callbacks (EarlyStopping, ModelCheckpoint, ReduceLROnPlateau)\")\n",
    "print(\"   - Memory monitoring en temps r√©el\")\n",
    "print(\"   - Mixed precision support\")\n",
    "print(\"   - TF 2.18 compatible compilation\")\n",
    "print(\"   - Optimisations Google Colab L4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39a98443",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "## üéØ Ex√©cution de l'Entra√Ænement des Mod√®les\n",
    "\n",
    "### üéØ Entra√Ænement UNet Mini - TF 2.15+ Compatible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b252c63",
   "metadata": {
    "title": "[python]"
   },
   "outputs": [],
   "source": [
    "# Test de connectivit√© donn√©es avant entra√Ænement\n",
    "print(\"üîç Testing data connectivity...\")\n",
    "try:\n",
    "    test_batch = train_generator[0]\n",
    "    print(f\"‚úÖ Data test successful: {test_batch[0].shape} -> {test_batch[1].shape}\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Data test failed: {e}\")\n",
    "\n",
    "# Nettoyage m√©moire avant entra√Ænement\n",
    "cleanup_memory(verbose=True)\n",
    "\n",
    "# Cr√©er et compiler UNet Mini\n",
    "print(\"\\nüèóÔ∏è Building UNet Mini (TF 2.15+ compatible)...\")\n",
    "unet_mini_model = create_unet_mini_tf_2_15()\n",
    "unet_mini_model = compile_model_tf_2_15(unet_mini_model)\n",
    "\n",
    "print(f\"‚úÖ UNet Mini created:\")\n",
    "print(f\"   Parameters: {unet_mini_model.count_params():,}\")\n",
    "print(f\"   Input shape: {unet_mini_model.input_shape}\")\n",
    "print(f\"   Output shape: {unet_mini_model.output_shape}\")\n",
    "\n",
    "# Entra√Ænement UNet Mini\n",
    "unet_mini_results = train_model_with_monitoring(\n",
    "    unet_mini_model,\n",
    "    'unet_mini',\n",
    "    train_generator,\n",
    "    val_generator\n",
    ")\n",
    "\n",
    "if unet_mini_results:\n",
    "    print(f\"\\nüéâ UNet Mini training completed!\")\n",
    "    print(f\"   Final IoU: {unet_mini_results['final_metrics']['val_mean_iou']:.4f}\")\n",
    "    print(f\"   Final Dice: {unet_mini_results['final_metrics']['val_dice_coefficient']:.4f}\")\n",
    "    print(f\"   Final Accuracy: {unet_mini_results['final_metrics']['val_accuracy']:.4f}\")\n",
    "    print(f\"   Training time: {unet_mini_results['training_time']/60:.1f} minutes\")\n",
    "    print(f\"   Model saved: {unet_mini_results['model_path']}\")\n",
    "else:\n",
    "    print(\"‚ùå UNet Mini training failed\")\n",
    "\n",
    "# Nettoyage m√©moire apr√®s UNet Mini\n",
    "del unet_mini_model\n",
    "cleanup_memory(verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c47b64b",
   "metadata": {},
   "source": [
    "### üéØ Entra√Ænement VGG16 U-Net - TF 2.15+ Compatible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "549c47aa",
   "metadata": {
    "title": "[python]"
   },
   "outputs": [],
   "source": [
    "print(\"\\nüèóÔ∏è Building VGG16 U-Net (TF 2.15+ compatible)...\")\n",
    "vgg16_unet_model = create_vgg16_unet_tf_2_15()\n",
    "vgg16_unet_model = compile_model_tf_2_15(vgg16_unet_model)\n",
    "\n",
    "print(f\"‚úÖ VGG16 U-Net created:\")\n",
    "print(f\"   Parameters: {vgg16_unet_model.count_params():,}\")\n",
    "print(f\"   Input shape: {vgg16_unet_model.input_shape}\")\n",
    "print(f\"   Output shape: {vgg16_unet_model.output_shape}\")\n",
    "\n",
    "# Configuration batch size conservateur pour VGG16\n",
    "vgg16_batch_size = TRAINING_CONFIG['models']['vgg16_unet']['batch_size']\n",
    "\n",
    "vgg16_train_generator = CityscapesDataGenerator(\n",
    "    train_images, train_masks,\n",
    "    batch_size=vgg16_batch_size,\n",
    "    augmentation=augmentation_pipeline,\n",
    "    shuffle=True,\n",
    "    max_samples=300  # Plus conservateur pour mod√®le large\n",
    ")\n",
    "\n",
    "vgg16_val_generator = CityscapesDataGenerator(\n",
    "    val_images, val_masks,\n",
    "    batch_size=vgg16_batch_size,\n",
    "    augmentation=None,\n",
    "    shuffle=False,\n",
    "    max_samples=75\n",
    ")\n",
    "\n",
    "print(f\"üìä VGG16 Data generators:\")\n",
    "print(f\"   Train batches: {len(vgg16_train_generator)} (batch_size={vgg16_batch_size})\")\n",
    "print(f\"   Val batches: {len(vgg16_val_generator)}\")\n",
    "\n",
    "# Entra√Ænement VGG16 U-Net\n",
    "vgg16_unet_results = train_model_with_monitoring(\n",
    "    vgg16_unet_model,\n",
    "    'vgg16_unet',\n",
    "    vgg16_train_generator,\n",
    "    vgg16_val_generator\n",
    ")\n",
    "\n",
    "if vgg16_unet_results:\n",
    "    print(f\"\\nüéâ VGG16 U-Net training completed!\")\n",
    "    print(f\"   Final IoU: {vgg16_unet_results['final_metrics']['val_mean_iou']:.4f}\")\n",
    "    print(f\"   Final Dice: {vgg16_unet_results['final_metrics']['val_dice_coefficient']:.4f}\")\n",
    "    print(f\"   Final Accuracy: {vgg16_unet_results['final_metrics']['val_accuracy']:.4f}\")\n",
    "    print(f\"   Training time: {vgg16_unet_results['training_time']/60:.1f} minutes\")\n",
    "    print(f\"   Model saved: {vgg16_unet_results['model_path']}\")\n",
    "else:\n",
    "    print(\"‚ùå VGG16 U-Net training failed\")\n",
    "\n",
    "# Nettoyage m√©moire apr√®s VGG16\n",
    "del vgg16_unet_model\n",
    "cleanup_memory(verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb0612d5",
   "metadata": {},
   "source": [
    "### üî• Entra√Ænement UNet EfficientNet-B0 - Mod√®le Avanc√©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "175c0f2a",
   "metadata": {
    "title": "[python]"
   },
   "outputs": [],
   "source": [
    "print(\"\\nüèóÔ∏è Building UNet EfficientNet-B0 (TF 2.18 compatible)...\")\n",
    "unet_efficientnet_model = UNetEfficientNet(backbone='B0', freeze_backbone=True)\n",
    "unet_efficientnet_model = unet_efficientnet_model.build_model()\n",
    "unet_efficientnet_compiled = compile_model_tf_2_15(unet_efficientnet_model)\n",
    "\n",
    "print(f\"‚úÖ UNet EfficientNet-B0 created:\")\n",
    "print(f\"   Parameters: {unet_efficientnet_model.count_params():,}\")\n",
    "print(f\"   Input shape: {unet_efficientnet_model.input_shape}\")\n",
    "print(f\"   Output shape: {unet_efficientnet_model.output_shape}\")\n",
    "\n",
    "# Configuration batch size adaptatif pour EfficientNet\n",
    "efficientnet_batch_size = max(2, BATCH_SIZE // 2)  # Plus conservateur pour mod√®le complexe\n",
    "\n",
    "efficientnet_train_generator = CityscapesDataGenerator(\n",
    "    train_images, train_masks,\n",
    "    batch_size=efficientnet_batch_size,\n",
    "    augmentation=augmentation_pipeline,\n",
    "    shuffle=True,\n",
    "    max_samples=400  # Adapt√© pour mod√®le complexe\n",
    ")\n",
    "\n",
    "efficientnet_val_generator = CityscapesDataGenerator(\n",
    "    val_images, val_masks,\n",
    "    batch_size=efficientnet_batch_size,\n",
    "    augmentation=None,\n",
    "    shuffle=False,\n",
    "    max_samples=100\n",
    ")\n",
    "\n",
    "print(f\"üìä UNet EfficientNet Data generators:\")\n",
    "print(f\"   Train batches: {len(efficientnet_train_generator)} (batch_size={efficientnet_batch_size})\")\n",
    "print(f\"   Val batches: {len(efficientnet_val_generator)}\")\n",
    "\n",
    "# Entra√Ænement UNet EfficientNet\n",
    "unet_efficientnet_results = train_model_with_monitoring(\n",
    "    unet_efficientnet_model,\n",
    "    'unet_efficientnet',\n",
    "    efficientnet_train_generator,\n",
    "    efficientnet_val_generator\n",
    ")\n",
    "\n",
    "if unet_efficientnet_results:\n",
    "    print(f\"\\nüéâ UNet EfficientNet training completed!\")\n",
    "    print(f\"   Final IoU: {unet_efficientnet_results['final_metrics']['val_mean_iou']:.4f}\")\n",
    "    print(f\"   Final Dice: {unet_efficientnet_results['final_metrics']['val_dice_coefficient']:.4f}\")\n",
    "    print(f\"   Final Accuracy: {unet_efficientnet_results['final_metrics']['val_accuracy']:.4f}\")\n",
    "    print(f\"   Training time: {unet_efficientnet_results['training_time']/60:.1f} minutes\")\n",
    "    print(f\"   Model saved: {unet_efficientnet_results['model_path']}\")\n",
    "else:\n",
    "    print(\"‚ùå UNet EfficientNet training failed\")\n",
    "\n",
    "# Nettoyage m√©moire apr√®s UNet EfficientNet\n",
    "del unet_efficientnet_model\n",
    "cleanup_memory(verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4156fa46",
   "metadata": {},
   "source": [
    "### üöÄ Entra√Ænement DeepLabV3+ MobileNetV2 - Mod√®le Efficace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92b6fb4d",
   "metadata": {
    "title": "[python]"
   },
   "outputs": [],
   "source": [
    "print(\"\\nüèóÔ∏è Building DeepLabV3+ MobileNetV2 (TF 2.18 compatible)...\")\n",
    "deeplab_model = DeepLabV3Plus()\n",
    "deeplab_model = deeplab_model.build_model()\n",
    "deeplab_compiled = compile_model_tf_2_15(deeplab_model)\n",
    "\n",
    "print(f\"‚úÖ DeepLabV3+ MobileNetV2 created:\")\n",
    "print(f\"   Parameters: {deeplab_model.count_params():,}\")\n",
    "print(f\"   Input shape: {deeplab_model.input_shape}\")\n",
    "print(f\"   Output shape: {deeplab_model.output_shape}\")\n",
    "\n",
    "# Configuration batch size pour DeepLabV3+\n",
    "deeplab_batch_size = BATCH_SIZE  # Peut utiliser batch size standard\n",
    "\n",
    "deeplab_train_generator = CityscapesDataGenerator(\n",
    "    train_images, train_masks,\n",
    "    batch_size=deeplab_batch_size,\n",
    "    augmentation=augmentation_pipeline,\n",
    "    shuffle=True,\n",
    "    max_samples=500  # Plus d'√©chantillons pour mod√®le efficace\n",
    ")\n",
    "\n",
    "deeplab_val_generator = CityscapesDataGenerator(\n",
    "    val_images, val_masks,\n",
    "    batch_size=deeplab_batch_size,\n",
    "    augmentation=None,\n",
    "    shuffle=False,\n",
    "    max_samples=125\n",
    ")\n",
    "\n",
    "print(f\"üìä DeepLabV3+ Data generators:\")\n",
    "print(f\"   Train batches: {len(deeplab_train_generator)} (batch_size={deeplab_batch_size})\")\n",
    "print(f\"   Val batches: {len(deeplab_val_generator)}\")\n",
    "\n",
    "# Entra√Ænement DeepLabV3+\n",
    "deeplab_results = train_model_with_monitoring(\n",
    "    deeplab_model,\n",
    "    'deeplabv3plus',\n",
    "    deeplab_train_generator,\n",
    "    deeplab_val_generator\n",
    ")\n",
    "\n",
    "if deeplab_results:\n",
    "    print(f\"\\nüéâ DeepLabV3+ training completed!\")\n",
    "    print(f\"   Final IoU: {deeplab_results['final_metrics']['val_mean_iou']:.4f}\")\n",
    "    print(f\"   Final Dice: {deeplab_results['final_metrics']['val_dice_coefficient']:.4f}\")\n",
    "    print(f\"   Final Accuracy: {deeplab_results['final_metrics']['val_accuracy']:.4f}\")\n",
    "    print(f\"   Training time: {deeplab_results['training_time']/60:.1f} minutes\")\n",
    "    print(f\"   Model saved: {deeplab_results['model_path']}\")\n",
    "else:\n",
    "    print(\"‚ùå DeepLabV3+ training failed\")\n",
    "\n",
    "# Nettoyage m√©moire apr√®s DeepLabV3+\n",
    "del deeplab_model\n",
    "cleanup_memory(verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d481a734",
   "metadata": {},
   "source": [
    "### üåü Entra√Ænement Segformer-B0 - Vision Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66c2acfb",
   "metadata": {
    "title": "[python]"
   },
   "outputs": [],
   "source": [
    "print(\"\\nüèóÔ∏è Building Segformer-B0 (TF 2.18 compatible)...\")\n",
    "\n",
    "# Gestion d'erreur pour Segformer (mod√®le complexe)\n",
    "try:\n",
    "    segformer_model = SegformerB0()\n",
    "    segformer_model = segformer_model.build_model()\n",
    "    segformer_compiled = compile_model_tf_2_15(segformer_model)\n",
    "\n",
    "    print(f\"‚úÖ Segformer-B0 created:\")\n",
    "    print(f\"   Parameters: {segformer_model.count_params():,}\")\n",
    "    print(f\"   Input shape: {segformer_model.input_shape}\")\n",
    "    print(f\"   Output shape: {segformer_model.output_shape}\")\n",
    "\n",
    "    # Configuration batch size tr√®s conservateur pour Transformer\n",
    "    segformer_batch_size = max(1, BATCH_SIZE // 4)  # Tr√®s conservateur pour Transformer\n",
    "\n",
    "    segformer_train_generator = CityscapesDataGenerator(\n",
    "        train_images, train_masks,\n",
    "        batch_size=segformer_batch_size,\n",
    "        augmentation=augmentation_pipeline,\n",
    "        shuffle=True,\n",
    "        max_samples=200  # Limit√©e pour √©viter probl√®mes m√©moire\n",
    "    )\n",
    "\n",
    "    segformer_val_generator = CityscapesDataGenerator(\n",
    "        val_images, val_masks,\n",
    "        batch_size=segformer_batch_size,\n",
    "        augmentation=None,\n",
    "        shuffle=False,\n",
    "        max_samples=50\n",
    "    )\n",
    "\n",
    "    print(f\"üìä Segformer Data generators:\")\n",
    "    print(f\"   Train batches: {len(segformer_train_generator)} (batch_size={segformer_batch_size})\")\n",
    "    print(f\"   Val batches: {len(segformer_val_generator)}\")\n",
    "\n",
    "    # Entra√Ænement Segformer avec gestion d'erreur\n",
    "    segformer_results = train_model_with_monitoring(\n",
    "        segformer_model,\n",
    "        'segformer_b0',\n",
    "        segformer_train_generator,\n",
    "        segformer_val_generator\n",
    "    )\n",
    "\n",
    "    if segformer_results:\n",
    "        print(f\"\\nüéâ Segformer-B0 training completed!\")\n",
    "        print(f\"   Final IoU: {segformer_results['final_metrics']['val_mean_iou']:.4f}\")\n",
    "        print(f\"   Final Dice: {segformer_results['final_metrics']['val_dice_coefficient']:.4f}\")\n",
    "        print(f\"   Final Accuracy: {segformer_results['final_metrics']['val_accuracy']:.4f}\")\n",
    "        print(f\"   Training time: {segformer_results['training_time']/60:.1f} minutes\")\n",
    "        print(f\"   Model saved: {segformer_results['model_path']}\")\n",
    "    else:\n",
    "        print(\"‚ùå Segformer-B0 training failed\")\n",
    "        segformer_results = None\n",
    "\n",
    "    # Nettoyage m√©moire apr√®s Segformer\n",
    "    del segformer_model\n",
    "    cleanup_memory(verbose=True)\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è Segformer-B0 construction/training failed: {str(e)}\")\n",
    "    print(\"üí° Continuing with other models - Segformer requires more memory\")\n",
    "    segformer_results = None\n",
    "\n",
    "print(f\"\\n‚úÖ ADVANCED MODELS TRAINING COMPLETED\")\n",
    "print(f\"   Models trained: 3 additional architectures\")\n",
    "print(f\"   Memory management: Optimized for Google Colab L4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95ff51fb",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "source": [
    "## üìä Analyse des R√©sultats & Visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "638537fc",
   "metadata": {
    "title": "[python]"
   },
   "outputs": [],
   "source": [
    "def create_training_visualization(results_dict):\n",
    "    \"\"\"Cr√©e des visualisations compl√®tes des r√©sultats d'entra√Ænement\"\"\"\n",
    "\n",
    "    fig = make_subplots(\n",
    "        rows=2, cols=2,\n",
    "        subplot_titles=['Training & Validation Loss', 'IoU Score', 'Dice Coefficient', 'Accuracy'],\n",
    "        specs=[[{\"secondary_y\": False}, {\"secondary_y\": False}],\n",
    "               [{\"secondary_y\": False}, {\"secondary_y\": False}]]\n",
    "    )\n",
    "\n",
    "    colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728']\n",
    "\n",
    "    for i, (model_name, results) in enumerate(results_dict.items()):\n",
    "        if results is None:\n",
    "            continue\n",
    "\n",
    "        history = results['history'].history\n",
    "        epochs = range(1, len(history['loss']) + 1)\n",
    "        color = colors[i % len(colors)]\n",
    "\n",
    "        # Loss\n",
    "        fig.add_trace(\n",
    "            go.Scatter(x=list(epochs), y=history['loss'],\n",
    "                      name=f'{model_name} - Train Loss',\n",
    "                      line=dict(color=color, dash='solid')),\n",
    "            row=1, col=1\n",
    "        )\n",
    "        fig.add_trace(\n",
    "            go.Scatter(x=list(epochs), y=history['val_loss'],\n",
    "                      name=f'{model_name} - Val Loss',\n",
    "                      line=dict(color=color, dash='dash')),\n",
    "            row=1, col=1\n",
    "        )\n",
    "\n",
    "        # IoU\n",
    "        fig.add_trace(\n",
    "            go.Scatter(x=list(epochs), y=history['val_mean_iou'],\n",
    "                      name=f'{model_name} - IoU',\n",
    "                      line=dict(color=color)),\n",
    "            row=1, col=2\n",
    "        )\n",
    "\n",
    "        # Dice\n",
    "        fig.add_trace(\n",
    "            go.Scatter(x=list(epochs), y=history['val_dice_coefficient'],\n",
    "                      name=f'{model_name} - Dice',\n",
    "                      line=dict(color=color)),\n",
    "            row=2, col=1\n",
    "        )\n",
    "\n",
    "        # Accuracy\n",
    "        fig.add_trace(\n",
    "            go.Scatter(x=list(epochs), y=history['val_accuracy'],\n",
    "                      name=f'{model_name} - Accuracy',\n",
    "                      line=dict(color=color)),\n",
    "            row=2, col=2\n",
    "        )\n",
    "\n",
    "    fig.update_layout(\n",
    "        height=800,\n",
    "        title_text=\"üöÄ Training Results - TensorFlow 2.15+ Compatible Models\",\n",
    "        showlegend=True,\n",
    "        title_x=0.5\n",
    "    )\n",
    "\n",
    "    fig.show()\n",
    "\n",
    "def create_comparison_table(results_dict):\n",
    "    \"\"\"Cr√©e un tableau de comparaison des mod√®les\"\"\"\n",
    "\n",
    "    comparison_data = []\n",
    "\n",
    "    for model_name, results in results_dict.items():\n",
    "        if results is None:\n",
    "            continue\n",
    "\n",
    "        comparison_data.append({\n",
    "            'Model': model_name,\n",
    "            'Parameters': f\"{results['model'].count_params():,}\",\n",
    "            'Training Time (min)': f\"{results['training_time']/60:.1f}\",\n",
    "            'Final IoU': f\"{results['final_metrics']['val_mean_iou']:.4f}\",\n",
    "            'Final Dice': f\"{results['final_metrics']['val_dice_coefficient']:.4f}\",\n",
    "            'Final Accuracy': f\"{results['final_metrics']['val_accuracy']:.4f}\",\n",
    "            'Final Loss': f\"{results['final_metrics']['val_loss']:.4f}\",\n",
    "            'TF Version': \"2.15+ Compatible ‚úÖ\",\n",
    "            'API Compatible': \"‚úÖ input_shape\",\n",
    "            'Model Path': results['model_path']\n",
    "        })\n",
    "\n",
    "    df_comparison = pd.DataFrame(comparison_data)\n",
    "\n",
    "    print(\"üìä MODEL COMPARISON - TensorFlow 2.15+ Compatible\")\n",
    "    print(\"=\"*80)\n",
    "    print(df_comparison.to_string(index=False))\n",
    "\n",
    "    return df_comparison\n",
    "\n",
    "# Rassembler les r√©sultats\n",
    "training_results = {}\n",
    "if 'unet_mini_results' in locals() and unet_mini_results:\n",
    "    training_results['UNet Mini'] = unet_mini_results\n",
    "if 'vgg16_unet_results' in locals() and vgg16_unet_results:\n",
    "    training_results['VGG16 U-Net'] = vgg16_unet_results\n",
    "if 'unet_efficientnet_results' in locals() and unet_efficientnet_results:\n",
    "    training_results['UNet EfficientNet-B0'] = unet_efficientnet_results\n",
    "if 'deeplab_results' in locals() and deeplab_results:\n",
    "    training_results['DeepLabV3+ MobileNetV2'] = deeplab_results\n",
    "if 'segformer_results' in locals() and segformer_results:\n",
    "    training_results['Segformer-B0'] = segformer_results\n",
    "\n",
    "if training_results:\n",
    "    # Visualisations\n",
    "    create_training_visualization(training_results)\n",
    "\n",
    "    # Tableau de comparaison\n",
    "    comparison_df = create_comparison_table(training_results)\n",
    "\n",
    "    # Sauvegarde des r√©sultats\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    comparison_df.to_csv(f'models_comparison_tf_2_15_compatible_{timestamp}.csv', index=False)\n",
    "\n",
    "    # Champion model selection\n",
    "    best_model_name = None\n",
    "    best_iou = 0\n",
    "\n",
    "    for model_name, results in training_results.items():\n",
    "        iou = results['final_metrics']['val_mean_iou']\n",
    "        if iou > best_iou:\n",
    "            best_iou = iou\n",
    "            best_model_name = model_name\n",
    "\n",
    "    print(f\"\\nüèÜ CHAMPION MODEL: {best_model_name}\")\n",
    "    print(f\"   Best IoU: {best_iou:.4f}\")\n",
    "    print(f\"   TensorFlow 2.15+ Compatible: ‚úÖ\")\n",
    "    print(f\"   API Ready: ‚úÖ\")\n",
    "\n",
    "else:\n",
    "    print(\"‚ùå No training results available for analysis\")\n",
    "\n",
    "\"\"\"## üöÄ Test des Mod√®les & V√©rification Compatibilit√© API\"\"\"\n",
    "\n",
    "def test_model_api_compatibility(model_path, model_name):\n",
    "    \"\"\"Test la compatibilit√© d'un mod√®le avec l'API de production\"\"\"\n",
    "\n",
    "    print(f\"\\nüß™ Testing {model_name} API compatibility...\")\n",
    "\n",
    "    try:\n",
    "        # Test 1: Chargement avec custom objects (comme l'API)\n",
    "        print(\"   1. Loading with custom objects...\")\n",
    "        model = tf.keras.models.load_model(model_path, custom_objects=CUSTOM_OBJECTS, compile=False)\n",
    "        print(f\"   ‚úÖ Model loaded successfully\")\n",
    "        print(f\"      Input shape: {model.input_shape}\")\n",
    "        print(f\"      Output shape: {model.output_shape}\")\n",
    "\n",
    "        # Test 2: Recompilation (comme l'API)\n",
    "        print(\"   2. Recompiling model...\")\n",
    "        model.compile(\n",
    "            optimizer='adam',\n",
    "            loss='sparse_categorical_crossentropy',\n",
    "            metrics=['accuracy']\n",
    "        )\n",
    "        print(\"   ‚úÖ Model recompiled successfully\")\n",
    "\n",
    "        # Test 3: Inference test avec forme compatible API\n",
    "        print(\"   3. Testing inference...\")\n",
    "        dummy_input = np.random.random((1, 512, 1024, 3)).astype(np.float32)\n",
    "\n",
    "        start_time = time.time()\n",
    "        prediction = model.predict(dummy_input, verbose=0)\n",
    "        inference_time = time.time() - start_time\n",
    "\n",
    "        print(f\"   ‚úÖ Inference successful:\")\n",
    "        print(f\"      Input: {dummy_input.shape}\")\n",
    "        print(f\"      Output: {prediction.shape}\")\n",
    "        print(f\"      Time: {inference_time*1000:.1f}ms\")\n",
    "\n",
    "        # Test 4: V√©rification format de sortie\n",
    "        print(\"   4. Verifying output format...\")\n",
    "        if len(prediction.shape) == 4 and prediction.shape[-1] == NUM_CLASSES:\n",
    "            print(f\"   ‚úÖ Output format correct: {prediction.shape}\")\n",
    "\n",
    "            # Test postprocessing comme l'API\n",
    "            class_mask = np.argmax(prediction[0], axis=-1)\n",
    "            confidence_map = np.max(prediction[0], axis=-1)\n",
    "\n",
    "            print(f\"      Class mask: {class_mask.shape}, unique values: {np.unique(class_mask)}\")\n",
    "            print(f\"      Confidence: {confidence_map.shape}, range: [{confidence_map.min():.3f}, {confidence_map.max():.3f}]\")\n",
    "\n",
    "        else:\n",
    "            print(f\"   ‚ùå Output format incorrect: {prediction.shape}\")\n",
    "            return False\n",
    "\n",
    "        # Nettoyage m√©moire\n",
    "        del model\n",
    "        gc.collect()\n",
    "\n",
    "        print(f\"   üéâ {model_name} is fully API compatible!\")\n",
    "        return True\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"   ‚ùå API compatibility test failed: {str(e)}\")\n",
    "        return False\n",
    "\n",
    "def create_api_compatibility_report(training_results):\n",
    "    \"\"\"Cr√©e un rapport de compatibilit√© API\"\"\"\n",
    "\n",
    "    print(\"\\nüìã API COMPATIBILITY REPORT\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "    compatible_models = []\n",
    "\n",
    "    for model_name, results in training_results.items():\n",
    "        if results is None:\n",
    "            continue\n",
    "\n",
    "        model_path = results['model_path']\n",
    "        is_compatible = test_model_api_compatibility(model_path, model_name)\n",
    "\n",
    "        compatible_models.append({\n",
    "            'Model': model_name,\n",
    "            'API Compatible': \"‚úÖ Yes\" if is_compatible else \"‚ùå No\",\n",
    "            'Model Path': model_path,\n",
    "            'TensorFlow Version': \"2.15+ Compatible\",\n",
    "            'Input Shape Format': \"input_shape ‚úÖ\",\n",
    "            'Custom Objects': \"‚úÖ Identical to API\",\n",
    "            'Ready for Production': \"‚úÖ Ready\" if is_compatible else \"‚ùå Not Ready\"\n",
    "        })\n",
    "\n",
    "    compatibility_df = pd.DataFrame(compatible_models)\n",
    "    print(\"\\nüìä COMPATIBILITY SUMMARY:\")\n",
    "    print(compatibility_df.to_string(index=False))\n",
    "\n",
    "    # Sauvegarde du rapport\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    compatibility_df.to_csv(f'api_compatibility_report_{timestamp}.csv', index=False)\n",
    "\n",
    "    return compatibility_df\n",
    "\n",
    "# Test de compatibilit√© API pour tous les mod√®les entra√Æn√©s\n",
    "if training_results:\n",
    "    compatibility_report = create_api_compatibility_report(training_results)\n",
    "\n",
    "    # Compter les mod√®les compatibles\n",
    "    compatible_count = len([r for r in training_results.values() if r is not None])\n",
    "\n",
    "    print(f\"\\nüéØ FINAL SUMMARY:\")\n",
    "    print(f\"   Models trained: {compatible_count}\")\n",
    "    print(f\"   TensorFlow version: 2.15+ Compatible ‚úÖ\")\n",
    "    print(f\"   API compatibility: Verified ‚úÖ\")\n",
    "    print(f\"   Ready for deployment: ‚úÖ\")\n",
    "\n",
    "else:\n",
    "    print(\"‚ùå No models available for compatibility testing\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "620c8587",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "source": [
    "## üöÄ Upload Google Cloud Storage (Optionnel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd6ac00",
   "metadata": {
    "title": "[python]"
   },
   "outputs": [],
   "source": [
    "def upload_models_to_gcs(training_results, bucket_name=\"cityscapes_data2\"):\n",
    "    \"\"\"Upload des mod√®les entra√Æn√©s vers Google Cloud Storage\"\"\"\n",
    "\n",
    "    if not training_results:\n",
    "        print(\"‚ùå No models to upload\")\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        # V√©rifier si on est dans Google Colab\n",
    "        import google.colab\n",
    "\n",
    "        print(\"‚òÅÔ∏è Uploading models to Google Cloud Storage...\")\n",
    "\n",
    "        for model_name, results in training_results.items():\n",
    "            if results is None:\n",
    "                continue\n",
    "\n",
    "            model_path = results['model_path']\n",
    "\n",
    "            # Nom du fichier dans GCS\n",
    "            gcs_path = f\"gs://{bucket_name}/models/tf_2_15_compatible/{os.path.basename(model_path)}\"\n",
    "\n",
    "            print(f\"üì§ Uploading {model_name}...\")\n",
    "            print(f\"   Local: {model_path}\")\n",
    "            print(f\"   GCS: {gcs_path}\")\n",
    "\n",
    "            # Upload avec gsutil\n",
    "            upload_command = f\"gsutil cp {model_path} {gcs_path}\"\n",
    "            result = os.system(upload_command)\n",
    "\n",
    "            if result == 0:\n",
    "                print(f\"   ‚úÖ Upload successful\")\n",
    "            else:\n",
    "                print(f\"   ‚ùå Upload failed\")\n",
    "\n",
    "        print(f\"\\n‚úÖ Models uploaded to: gs://{bucket_name}/models/tf_2_15_compatible/\")\n",
    "\n",
    "    except ImportError:\n",
    "        print(\"‚ÑπÔ∏è Not in Google Colab - skipping GCS upload\")\n",
    "        print(\"   Models are saved locally and ready for manual deployment\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è GCS upload error: {str(e)}\")\n",
    "\n",
    "# Upload des mod√®les (si on est dans Colab)\n",
    "if training_results:\n",
    "    upload_models_to_gcs(training_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93c9215d",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "source": [
    "## üìä M√©triques d'√âvaluation - Analyse D√©taill√©e par Mod√®le\n",
    "Analyse fine des performances de chaque mod√®le entra√Æn√©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5d69972",
   "metadata": {
    "lines_to_next_cell": 1,
    "title": "[python]"
   },
   "outputs": [],
   "source": [
    "def calculate_detailed_metrics(training_results):\n",
    "    \"\"\"Calcule les m√©triques d√©taill√©es pour chaque mod√®le\"\"\"\n",
    "    \n",
    "    if not training_results:\n",
    "        print(\"‚ùå Aucun r√©sultat d'entra√Ænement disponible\")\n",
    "        return None\n",
    "    \n",
    "    print(\"üìä CALCUL DES M√âTRIQUES D√âTAILL√âES\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    detailed_metrics = {}\n",
    "    \n",
    "    for model_name, results in training_results.items():\n",
    "        if results is None:\n",
    "            continue\n",
    "            \n",
    "        print(f\"\\nüîç Analyse {model_name}...\")\n",
    "        \n",
    "        # M√©triques finales\n",
    "        final_metrics = results['final_metrics']\n",
    "        training_time = results['training_time']\n",
    "        model_params = results['model'].count_params()\n",
    "        \n",
    "        # Calculer les m√©triques avanc√©es\n",
    "        history = results['history'].history\n",
    "        epochs_trained = len(history['loss'])\n",
    "        \n",
    "        # Convergence analysis\n",
    "        val_loss_improvement = history['val_loss'][0] - history['val_loss'][-1]\n",
    "        val_iou_improvement = history['val_mean_iou'][-1] - history['val_mean_iou'][0]\n",
    "        \n",
    "        # Stabilit√© (variance des 5 derni√®res √©poques)\n",
    "        last_5_epochs = min(5, epochs_trained)\n",
    "        val_loss_stability = np.std(history['val_loss'][-last_5_epochs:])\n",
    "        val_iou_stability = np.std(history['val_mean_iou'][-last_5_epochs:])\n",
    "        \n",
    "        # Efficacit√© temporelle\n",
    "        time_per_epoch = training_time / epochs_trained\n",
    "        params_per_mb = model_params / (1024 * 1024)\n",
    "        \n",
    "        # Calcul du score de performance composite\n",
    "        iou_score = final_metrics['val_mean_iou']\n",
    "        dice_score = final_metrics['val_dice_coefficient']\n",
    "        accuracy_score = final_metrics['val_accuracy']\n",
    "        \n",
    "        # Score composite pond√©r√© (IoU prioritaire pour segmentation)\n",
    "        composite_score = (0.5 * iou_score + 0.3 * dice_score + 0.2 * accuracy_score)\n",
    "        \n",
    "        # Ratio efficacit√©/taille\n",
    "        efficiency_ratio = iou_score / (params_per_mb + 1e-6)  # IoU par MB de param√®tres\n",
    "        \n",
    "        detailed_metrics[model_name] = {\n",
    "            # M√©triques de base\n",
    "            'final_iou': iou_score,\n",
    "            'final_dice': dice_score,\n",
    "            'final_accuracy': accuracy_score,\n",
    "            'final_loss': final_metrics['val_loss'],\n",
    "            \n",
    "            # M√©triques de convergence\n",
    "            'loss_improvement': val_loss_improvement,\n",
    "            'iou_improvement': val_iou_improvement,\n",
    "            'epochs_trained': epochs_trained,\n",
    "            \n",
    "            # M√©triques de stabilit√©\n",
    "            'loss_stability': val_loss_stability,\n",
    "            'iou_stability': val_iou_stability,\n",
    "            \n",
    "            # M√©triques d'efficacit√©\n",
    "            'training_time_min': training_time / 60,\n",
    "            'time_per_epoch_min': time_per_epoch / 60,\n",
    "            'model_params_m': params_per_mb,\n",
    "            \n",
    "            # Scores composites\n",
    "            'composite_score': composite_score,\n",
    "            'efficiency_ratio': efficiency_ratio,\n",
    "            \n",
    "            # Classification de performance\n",
    "            'performance_class': 'Excellent' if iou_score > 0.7 else 'Bon' if iou_score > 0.5 else 'Acceptable' if iou_score > 0.3 else 'Insuffisant',\n",
    "            'efficiency_class': 'Tr√®s Efficace' if efficiency_ratio > 0.05 else 'Efficace' if efficiency_ratio > 0.02 else 'Mod√©r√©' if efficiency_ratio > 0.01 else 'Lourd'\n",
    "        }\n",
    "        \n",
    "        print(f\"   ‚úÖ M√©triques calcul√©es pour {model_name}\")\n",
    "        print(f\"      Performance: {detailed_metrics[model_name]['performance_class']}\")\n",
    "        print(f\"      Efficacit√©: {detailed_metrics[model_name]['efficiency_class']}\")\n",
    "        print(f\"      Score composite: {composite_score:.4f}\")\n",
    "    \n",
    "    return detailed_metrics\n",
    "\n",
    "def create_performance_heatmap(detailed_metrics):\n",
    "    \"\"\"Cr√©e une heatmap des performances par mod√®le et m√©trique\"\"\"\n",
    "    \n",
    "    if not detailed_metrics:\n",
    "        return\n",
    "    \n",
    "    print(\"\\nüìà HEATMAP DES PERFORMANCES\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    # Pr√©parer les donn√©es pour la heatmap\n",
    "    models = list(detailed_metrics.keys())\n",
    "    metrics = ['final_iou', 'final_dice', 'final_accuracy', 'composite_score', 'efficiency_ratio']\n",
    "    metric_labels = ['IoU Final', 'Dice Final', 'Pr√©cision', 'Score Composite', 'Ratio Efficacit√©']\n",
    "    \n",
    "    heatmap_data = []\n",
    "    for model in models:\n",
    "        row = []\n",
    "        for metric in metrics:\n",
    "            value = detailed_metrics[model][metric]\n",
    "            # Normaliser les valeurs pour la heatmap\n",
    "            if metric == 'efficiency_ratio':\n",
    "                value = min(value * 20, 1.0)  # Normaliser le ratio d'efficacit√©\n",
    "            row.append(value)\n",
    "        heatmap_data.append(row)\n",
    "    \n",
    "    heatmap_data = np.array(heatmap_data)\n",
    "    \n",
    "    # Cr√©er la heatmap avec matplotlib\n",
    "    fig, ax = plt.subplots(figsize=(12, 8))\n",
    "    im = ax.imshow(heatmap_data, cmap='RdYlGn', aspect='auto', vmin=0, vmax=1)\n",
    "    \n",
    "    # Configuration des axes\n",
    "    ax.set_xticks(np.arange(len(metric_labels)))\n",
    "    ax.set_yticks(np.arange(len(models)))\n",
    "    ax.set_xticklabels(metric_labels, rotation=45, ha=\"right\")\n",
    "    ax.set_yticklabels(models)\n",
    "    \n",
    "    # Ajouter les valeurs dans les cellules\n",
    "    for i in range(len(models)):\n",
    "        for j in range(len(metrics)):\n",
    "            value = heatmap_data[i, j]\n",
    "            text = ax.text(j, i, f'{value:.3f}', ha=\"center\", va=\"center\", \n",
    "                          color=\"white\" if value < 0.5 else \"black\", fontweight='bold')\n",
    "    \n",
    "    ax.set_title(\"üéØ Heatmap des Performances par Mod√®le\", fontsize=16, fontweight='bold', pad=20)\n",
    "    \n",
    "    # Colorbar\n",
    "    cbar = plt.colorbar(im, ax=ax)\n",
    "    cbar.set_label('Score Normalis√© (0=Faible, 1=Excellent)', rotation=270, labelpad=20)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def create_convergence_analysis(training_results):\n",
    "    \"\"\"Analyse la convergence des mod√®les\"\"\"\n",
    "    \n",
    "    if not training_results:\n",
    "        return\n",
    "    \n",
    "    print(\"\\nüìà ANALYSE DE CONVERGENCE\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "    \n",
    "    # Couleurs pour chaque mod√®le\n",
    "    colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd', '#8c564b']\n",
    "    \n",
    "    for idx, (model_name, results) in enumerate(training_results.items()):\n",
    "        if results is None:\n",
    "            continue\n",
    "            \n",
    "        history = results['history'].history\n",
    "        epochs = range(1, len(history['loss']) + 1)\n",
    "        color = colors[idx % len(colors)]\n",
    "        \n",
    "        # Loss convergence\n",
    "        axes[0, 0].plot(epochs, history['loss'], label=f'{model_name} (Train)', \n",
    "                       color=color, linestyle='-', linewidth=2)\n",
    "        axes[0, 0].plot(epochs, history['val_loss'], label=f'{model_name} (Val)', \n",
    "                       color=color, linestyle='--', linewidth=2)\n",
    "        \n",
    "        # IoU convergence\n",
    "        axes[0, 1].plot(epochs, history['val_mean_iou'], label=model_name, \n",
    "                       color=color, linewidth=2, marker='o', markersize=4)\n",
    "        \n",
    "        # Dice convergence\n",
    "        axes[1, 0].plot(epochs, history['val_dice_coefficient'], label=model_name, \n",
    "                       color=color, linewidth=2, marker='s', markersize=4)\n",
    "        \n",
    "        # Accuracy convergence\n",
    "        axes[1, 1].plot(epochs, history['val_accuracy'], label=model_name, \n",
    "                       color=color, linewidth=2, marker='^', markersize=4)\n",
    "    \n",
    "    # Configuration des graphiques\n",
    "    axes[0, 0].set_title('üìâ Convergence de la Loss', fontweight='bold')\n",
    "    axes[0, 0].set_xlabel('√âpoques')\n",
    "    axes[0, 0].set_ylabel('Loss')\n",
    "    axes[0, 0].legend()\n",
    "    axes[0, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    axes[0, 1].set_title('üìà Convergence IoU', fontweight='bold')\n",
    "    axes[0, 1].set_xlabel('√âpoques')\n",
    "    axes[0, 1].set_ylabel('IoU Score')\n",
    "    axes[0, 1].legend()\n",
    "    axes[0, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    axes[1, 0].set_title('üéØ Convergence Dice', fontweight='bold')\n",
    "    axes[1, 0].set_xlabel('√âpoques')\n",
    "    axes[1, 0].set_ylabel('Dice Coefficient')\n",
    "    axes[1, 0].legend()\n",
    "    axes[1, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    axes[1, 1].set_title('‚úÖ Convergence Pr√©cision', fontweight='bold')\n",
    "    axes[1, 1].set_xlabel('√âpoques')\n",
    "    axes[1, 1].set_ylabel('Accuracy')\n",
    "    axes[1, 1].legend()\n",
    "    axes[1, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.suptitle('üîÑ Analyse de Convergence - Tous Mod√®les', fontsize=18, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def create_metrics_comparison_table(detailed_metrics):\n",
    "    \"\"\"Cr√©e un tableau de comparaison d√©taill√© des m√©triques\"\"\"\n",
    "    \n",
    "    if not detailed_metrics:\n",
    "        return None\n",
    "    \n",
    "    print(\"\\nüìã TABLEAU COMPARATIF D√âTAILL√â\")\n",
    "    print(\"=\" * 100)\n",
    "    \n",
    "    # Pr√©parer les donn√©es pour le DataFrame\n",
    "    comparison_data = []\n",
    "    \n",
    "    for model_name, metrics in detailed_metrics.items():\n",
    "        comparison_data.append({\n",
    "            'Mod√®le': model_name,\n",
    "            'IoU Final': f\"{metrics['final_iou']:.4f}\",\n",
    "            'Dice Final': f\"{metrics['final_dice']:.4f}\",\n",
    "            'Pr√©cision': f\"{metrics['final_accuracy']:.4f}\",\n",
    "            'Score Composite': f\"{metrics['composite_score']:.4f}\",\n",
    "            'Params (M)': f\"{metrics['model_params_m']:.1f}\",\n",
    "            'Temps/√âpoque (min)': f\"{metrics['time_per_epoch_min']:.2f}\",\n",
    "            'Temps Total (min)': f\"{metrics['training_time_min']:.1f}\",\n",
    "            'Efficacit√©': f\"{metrics['efficiency_ratio']:.4f}\",\n",
    "            'Stabilit√© IoU': f\"{metrics['iou_stability']:.4f}\",\n",
    "            'Am√©lioration IoU': f\"{metrics['iou_improvement']:.4f}\",\n",
    "            'Classification': metrics['performance_class'],\n",
    "            'Efficacit√© Type': metrics['efficiency_class']\n",
    "        })\n",
    "    \n",
    "    df_detailed = pd.DataFrame(comparison_data)\n",
    "    \n",
    "    # Identifier le champion dans chaque cat√©gorie\n",
    "    champions = {\n",
    "        'IoU': df_detailed.loc[df_detailed['IoU Final'].astype(float).idxmax(), 'Mod√®le'],\n",
    "        'Dice': df_detailed.loc[df_detailed['Dice Final'].astype(float).idxmax(), 'Mod√®le'],\n",
    "        'Pr√©cision': df_detailed.loc[df_detailed['Pr√©cision'].astype(float).idxmax(), 'Mod√®le'],\n",
    "        'Composite': df_detailed.loc[df_detailed['Score Composite'].astype(float).idxmax(), 'Mod√®le'],\n",
    "        'Efficacit√©': df_detailed.loc[df_detailed['Efficacit√©'].astype(float).idxmax(), 'Mod√®le'],\n",
    "        'Vitesse': df_detailed.loc[df_detailed['Temps/√âpoque (min)'].astype(float).idxmin(), 'Mod√®le']\n",
    "    }\n",
    "    \n",
    "    print(df_detailed.to_string(index=False))\n",
    "    \n",
    "    print(f\"\\nüèÜ CHAMPIONS PAR CAT√âGORIE:\")\n",
    "    for category, champion in champions.items():\n",
    "        print(f\"   ü•á {category}: {champion}\")\n",
    "    \n",
    "    # Sauvegarde du tableau d√©taill√©\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    df_detailed.to_csv(f'detailed_metrics_analysis_{timestamp}.csv', index=False)\n",
    "    print(f\"\\nüíæ Tableau sauvegard√©: detailed_metrics_analysis_{timestamp}.csv\")\n",
    "    \n",
    "    return df_detailed, champions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43350757",
   "metadata": {},
   "source": [
    "### üîç Ex√©cution de l'Analyse des M√©triques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58c74825",
   "metadata": {
    "title": "[python]"
   },
   "outputs": [],
   "source": [
    "# Ex√©cution de l'analyse d√©taill√©e des m√©triques\n",
    "if training_results:\n",
    "    print(\"üöÄ D√âMARRAGE DE L'ANALYSE D√âTAILL√âE DES M√âTRIQUES\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # 1. Calcul des m√©triques d√©taill√©es\n",
    "    detailed_metrics = calculate_detailed_metrics(training_results)\n",
    "    \n",
    "    if detailed_metrics:\n",
    "        # 2. Cr√©ation de la heatmap des performances\n",
    "        create_performance_heatmap(detailed_metrics)\n",
    "        \n",
    "        # 3. Analyse de convergence\n",
    "        create_convergence_analysis(training_results)\n",
    "        \n",
    "        # 4. Tableau de comparaison d√©taill√©\n",
    "        detailed_df, metric_champions = create_metrics_comparison_table(detailed_metrics)\n",
    "        \n",
    "        print(f\"\\n‚úÖ ANALYSE DES M√âTRIQUES TERMIN√âE\")\n",
    "        print(f\"   Mod√®les analys√©s: {len(detailed_metrics)}\")\n",
    "        print(f\"   M√©triques calcul√©es: 13 m√©triques par mod√®le\")\n",
    "        print(f\"   Visualisations cr√©√©es: 3 graphiques + 1 tableau\")\n",
    "        \n",
    "    else:\n",
    "        print(\"‚ùå Impossible de calculer les m√©triques d√©taill√©es\")\n",
    "        detailed_metrics = {}\n",
    "        metric_champions = {}\n",
    "\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Aucun r√©sultat d'entra√Ænement disponible pour l'analyse des m√©triques\")\n",
    "    detailed_metrics = {}\n",
    "    metric_champions = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e5eb9bd",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "source": [
    "## üèÜ Comparaisons des Mod√®les - Analyse Comparative Compl√®te\n",
    "Analyse co√ªt/b√©n√©fice et recommandations de d√©ploiement pour syst√®mes embarqu√©s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a93efe19",
   "metadata": {
    "lines_to_next_cell": 1,
    "title": "[python]"
   },
   "outputs": [],
   "source": [
    "def create_performance_radar_chart(detailed_metrics):\n",
    "    \"\"\"Cr√©e des graphiques radar pour comparer les mod√®les sur multiple crit√®res\"\"\"\n",
    "    \n",
    "    if not detailed_metrics:\n",
    "        return\n",
    "    \n",
    "    print(\"üéØ GRAPHIQUES RADAR MULTI-CRIT√àRES\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    # Crit√®res d'√©valuation (normalis√©s 0-1)\n",
    "    criteria = ['Performance', 'Efficacit√©', 'Vitesse', 'Stabilit√©', 'Am√©lioration']\n",
    "    \n",
    "    # Pr√©parer les donn√©es radar\n",
    "    radar_data = {}\n",
    "    for model_name, metrics in detailed_metrics.items():\n",
    "        # Normaliser les valeurs pour le radar\n",
    "        radar_data[model_name] = {\n",
    "            'Performance': metrics['composite_score'],\n",
    "            'Efficacit√©': min(metrics['efficiency_ratio'] * 20, 1.0),  # Normaliser\n",
    "            'Vitesse': max(0, 1 - (metrics['time_per_epoch_min'] / 10)),  # Inverser (plus rapide = mieux)\n",
    "            'Stabilit√©': max(0, 1 - metrics['iou_stability'] * 10),  # Inverser (moins de variance = mieux)\n",
    "            'Am√©lioration': min(metrics['iou_improvement'] * 2, 1.0)  # Normaliser\n",
    "        }\n",
    "    \n",
    "    # Cr√©er le graphique radar\n",
    "    angles = np.linspace(0, 2 * np.pi, len(criteria), endpoint=False).tolist()\n",
    "    angles += angles[:1]  # Fermer le cercle\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(12, 10), subplot_kw=dict(projection='polar'))\n",
    "    \n",
    "    colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd']\n",
    "    \n",
    "    for idx, (model_name, values) in enumerate(radar_data.items()):\n",
    "        values_list = [values[criterion] for criterion in criteria]\n",
    "        values_list += values_list[:1]  # Fermer le cercle\n",
    "        \n",
    "        color = colors[idx % len(colors)]\n",
    "        ax.plot(angles, values_list, 'o-', linewidth=2, label=model_name, color=color)\n",
    "        ax.fill(angles, values_list, alpha=0.1, color=color)\n",
    "    \n",
    "    # Configuration du radar\n",
    "    ax.set_xticks(angles[:-1])\n",
    "    ax.set_xticklabels(criteria, fontsize=12)\n",
    "    ax.set_ylim(0, 1)\n",
    "    ax.set_yticks([0.2, 0.4, 0.6, 0.8, 1.0])\n",
    "    ax.set_yticklabels(['0.2', '0.4', '0.6', '0.8', '1.0'], fontsize=10)\n",
    "    ax.grid(True)\n",
    "    \n",
    "    ax.set_title('üéØ Comparaison Multi-Crit√®res des Mod√®les\\n(Plus proche du centre = Meilleur)', \n",
    "                 size=16, fontweight='bold', pad=20)\n",
    "    ax.legend(loc='upper right', bbox_to_anchor=(1.3, 1.0))\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def create_cost_benefit_analysis(detailed_metrics):\n",
    "    \"\"\"Analyse co√ªt/b√©n√©fice pour d√©ploiement embarqu√©\"\"\"\n",
    "    \n",
    "    if not detailed_metrics:\n",
    "        return\n",
    "    \n",
    "    print(\"\\nüí∞ ANALYSE CO√õT/B√âN√âFICE POUR SYST√àMES EMBARQU√âS\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    # Crit√®res pour syst√®me embarqu√©\n",
    "    embedded_criteria = {\n",
    "        'performance_weight': 0.4,    # Performance IoU\n",
    "        'efficiency_weight': 0.3,     # Efficacit√© param√®tres/performance\n",
    "        'speed_weight': 0.2,          # Vitesse d'inf√©rence\n",
    "        'memory_weight': 0.1          # Utilisation m√©moire\n",
    "    }\n",
    "    \n",
    "    # Calculer le score embarqu√© pour chaque mod√®le\n",
    "    embedded_scores = {}\n",
    "    \n",
    "    for model_name, metrics in detailed_metrics.items():\n",
    "        # Normaliser les crit√®res\n",
    "        performance_score = metrics['composite_score']\n",
    "        efficiency_score = min(metrics['efficiency_ratio'] * 20, 1.0)\n",
    "        speed_score = max(0, 1 - (metrics['time_per_epoch_min'] / 10))\n",
    "        memory_score = max(0, 1 - (metrics['model_params_m'] / 50))  # P√©naliser gros mod√®les\n",
    "        \n",
    "        # Score pond√©r√© pour embarqu√©\n",
    "        embedded_score = (\n",
    "            performance_score * embedded_criteria['performance_weight'] +\n",
    "            efficiency_score * embedded_criteria['efficiency_weight'] +\n",
    "            speed_score * embedded_criteria['speed_weight'] +\n",
    "            memory_score * embedded_criteria['memory_weight']\n",
    "        )\n",
    "        \n",
    "        embedded_scores[model_name] = {\n",
    "            'embedded_score': embedded_score,\n",
    "            'performance_score': performance_score,\n",
    "            'efficiency_score': efficiency_score,\n",
    "            'speed_score': speed_score,\n",
    "            'memory_score': memory_score,\n",
    "            'deployment_recommendation': ''\n",
    "        }\n",
    "    \n",
    "    # Cr√©er les recommandations de d√©ploiement\n",
    "    for model_name, scores in embedded_scores.items():\n",
    "        score = scores['embedded_score']\n",
    "        params = detailed_metrics[model_name]['model_params_m']\n",
    "        \n",
    "        if score > 0.7 and params < 10:\n",
    "            recommendation = \"ü•á EXCELLENT pour embarqu√© - D√©ploiement prioritaire\"\n",
    "        elif score > 0.6 and params < 25:\n",
    "            recommendation = \"ü•à BON pour embarqu√© - D√©ploiement recommand√©\"\n",
    "        elif score > 0.5:\n",
    "            recommendation = \"ü•â ACCEPTABLE - D√©ploiement conditionnel\"\n",
    "        else:\n",
    "            recommendation = \"‚ùå NON RECOMMAND√â pour embarqu√© - Trop lourd/lent\"\n",
    "        \n",
    "        embedded_scores[model_name]['deployment_recommendation'] = recommendation\n",
    "    \n",
    "    # Cr√©er le graphique scatter co√ªt/b√©n√©fice\n",
    "    fig, ax = plt.subplots(figsize=(14, 10))\n",
    "    \n",
    "    models = list(embedded_scores.keys())\n",
    "    x_values = [embedded_scores[model]['embedded_score'] for model in models]\n",
    "    y_values = [detailed_metrics[model]['model_params_m'] for model in models]\n",
    "    colors = ['#2ca02c' if score > 0.7 else '#ff7f0e' if score > 0.6 else '#d62728' \n",
    "              for score in x_values]\n",
    "    \n",
    "    scatter = ax.scatter(x_values, y_values, c=colors, s=200, alpha=0.7, edgecolors='black')\n",
    "    \n",
    "    # Ajouter les labels des mod√®les\n",
    "    for i, model in enumerate(models):\n",
    "        ax.annotate(model, (x_values[i], y_values[i]), \n",
    "                   xytext=(5, 5), textcoords='offset points', fontsize=10, fontweight='bold')\n",
    "    \n",
    "    # Zones de recommandation\n",
    "    ax.axvline(x=0.7, color='green', linestyle='--', alpha=0.5, label='Excellent (>0.7)')\n",
    "    ax.axvline(x=0.6, color='orange', linestyle='--', alpha=0.5, label='Bon (>0.6)')\n",
    "    ax.axhline(y=10, color='blue', linestyle='--', alpha=0.5, label='Limite Embarqu√© (10M params)')\n",
    "    \n",
    "    ax.set_xlabel('Score Embarqu√© (Performance + Efficacit√© + Vitesse + M√©moire)', fontsize=12)\n",
    "    ax.set_ylabel('Taille Mod√®le (Millions de Param√®tres)', fontsize=12)\n",
    "    ax.set_title('üí∞ Analyse Co√ªt/B√©n√©fice pour D√©ploiement Embarqu√©\\n' + \n",
    "                 'üü¢ Excellent  üü† Bon  üî¥ Non Recommand√©', fontsize=14, fontweight='bold')\n",
    "    \n",
    "    ax.grid(True, alpha=0.3)\n",
    "    ax.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Tableau des recommandations\n",
    "    print(\"\\nüìã RECOMMANDATIONS DE D√âPLOIEMENT:\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # Trier par score embarqu√©\n",
    "    sorted_models = sorted(embedded_scores.items(), key=lambda x: x[1]['embedded_score'], reverse=True)\n",
    "    \n",
    "    for model_name, scores in sorted_models:\n",
    "        params = detailed_metrics[model_name]['model_params_m']\n",
    "        iou = detailed_metrics[model_name]['final_iou']\n",
    "        \n",
    "        print(f\"\\nü§ñ {model_name}:\")\n",
    "        print(f\"   Score Embarqu√©: {scores['embedded_score']:.3f}\")\n",
    "        print(f\"   Param√®tres: {params:.1f}M\")\n",
    "        print(f\"   IoU Final: {iou:.4f}\")\n",
    "        print(f\"   üìã {scores['deployment_recommendation']}\")\n",
    "    \n",
    "    return embedded_scores\n",
    "\n",
    "def create_deployment_strategy_table(detailed_metrics, embedded_scores):\n",
    "    \"\"\"Cr√©e un tableau de strat√©gies de d√©ploiement par sc√©nario d'usage\"\"\"\n",
    "    \n",
    "    if not detailed_metrics or not embedded_scores:\n",
    "        return\n",
    "    \n",
    "    print(\"\\nüöÄ STRAT√âGIES DE D√âPLOIEMENT PAR SC√âNARIO\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    scenarios = {\n",
    "        'Temps R√©el Critique': {\n",
    "            'description': 'Conduite autonome niveau 4-5, latence <50ms',\n",
    "            'priority': ['speed_score', 'performance_score', 'memory_score'],\n",
    "            'weights': [0.5, 0.3, 0.2]\n",
    "        },\n",
    "        'Efficacit√© √ânerg√©tique': {\n",
    "            'description': 'V√©hicule √©lectrique, autonomie optimis√©e',\n",
    "            'priority': ['efficiency_score', 'memory_score', 'performance_score'],\n",
    "            'weights': [0.4, 0.4, 0.2]\n",
    "        },\n",
    "        'Haute Pr√©cision': {\n",
    "            'description': 'Applications critiques s√©curit√©, pr√©cision maximale',\n",
    "            'priority': ['performance_score', 'embedded_score', 'speed_score'],\n",
    "            'weights': [0.6, 0.3, 0.1]\n",
    "        },\n",
    "        'D√©ploiement Massif': {\n",
    "            'description': 'Production s√©rie, co√ªt minimum',\n",
    "            'priority': ['memory_score', 'efficiency_score', 'performance_score'],\n",
    "            'weights': [0.5, 0.3, 0.2]\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    strategy_results = {}\n",
    "    \n",
    "    for scenario_name, scenario_config in scenarios.items():\n",
    "        scenario_scores = {}\n",
    "        \n",
    "        for model_name in embedded_scores.keys():\n",
    "            # Calculer le score pour ce sc√©nario\n",
    "            total_score = 0\n",
    "            for i, criterion in enumerate(scenario_config['priority']):\n",
    "                score = embedded_scores[model_name][criterion]\n",
    "                weight = scenario_config['weights'][i]\n",
    "                total_score += score * weight\n",
    "            \n",
    "            scenario_scores[model_name] = total_score\n",
    "        \n",
    "        # Identifier le meilleur mod√®le pour ce sc√©nario\n",
    "        best_model = max(scenario_scores, key=scenario_scores.get)\n",
    "        strategy_results[scenario_name] = {\n",
    "            'best_model': best_model,\n",
    "            'best_score': scenario_scores[best_model],\n",
    "            'all_scores': scenario_scores,\n",
    "            'description': scenario_config['description']\n",
    "        }\n",
    "    \n",
    "    # Cr√©er le tableau de strat√©gies\n",
    "    strategy_data = []\n",
    "    \n",
    "    for scenario_name, results in strategy_results.items():\n",
    "        best_model = results['best_model']\n",
    "        best_metrics = detailed_metrics[best_model]\n",
    "        \n",
    "        strategy_data.append({\n",
    "            'Sc√©nario': scenario_name,\n",
    "            'Description': results['description'],\n",
    "            'Mod√®le Recommand√©': best_model,\n",
    "            'Score Sc√©nario': f\"{results['best_score']:.3f}\",\n",
    "            'IoU': f\"{best_metrics['final_iou']:.4f}\",\n",
    "            'Params (M)': f\"{best_metrics['model_params_m']:.1f}\",\n",
    "            'Temps/√âpoque (min)': f\"{best_metrics['time_per_epoch_min']:.2f}\",\n",
    "            'Justification': f\"Optimis√© pour {scenario_name.lower()}\"\n",
    "        })\n",
    "    \n",
    "    strategy_df = pd.DataFrame(strategy_data)\n",
    "    print(strategy_df.to_string(index=False))\n",
    "    \n",
    "    # Sauvegarde\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    strategy_df.to_csv(f'deployment_strategies_{timestamp}.csv', index=False)\n",
    "    print(f\"\\nüíæ Strat√©gies sauvegard√©es: deployment_strategies_{timestamp}.csv\")\n",
    "    \n",
    "    return strategy_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20e5aea7",
   "metadata": {},
   "source": [
    "### üéØ Ex√©cution de l'Analyse Comparative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b351b3e",
   "metadata": {
    "title": "[python]"
   },
   "outputs": [],
   "source": [
    "# Ex√©cution de l'analyse comparative compl√®te\n",
    "if detailed_metrics:\n",
    "    print(\"üöÄ D√âMARRAGE DE L'ANALYSE COMPARATIVE COMPL√àTE\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # 1. Graphiques radar multi-crit√®res\n",
    "    create_performance_radar_chart(detailed_metrics)\n",
    "    \n",
    "    # 2. Analyse co√ªt/b√©n√©fice pour embarqu√©\n",
    "    embedded_analysis = create_cost_benefit_analysis(detailed_metrics)\n",
    "    \n",
    "    # 3. Strat√©gies de d√©ploiement par sc√©nario\n",
    "    if embedded_analysis:\n",
    "        deployment_strategies = create_deployment_strategy_table(detailed_metrics, embedded_analysis)\n",
    "        \n",
    "        print(f\"\\n‚úÖ ANALYSE COMPARATIVE TERMIN√âE\")\n",
    "        print(f\"   Crit√®res analys√©s: 5 crit√®res multi-dimensionnels\")\n",
    "        print(f\"   Sc√©narios √©valu√©s: 4 cas d'usage embarqu√©\")\n",
    "        print(f\"   Recommandations: D√©ploiement par contexte d'usage\")\n",
    "        \n",
    "        # R√©sum√© ex√©cutif des recommandations\n",
    "        print(f\"\\nüéØ R√âSUM√â EX√âCUTIF - RECOMMANDATIONS D√âPLOIEMENT:\")\n",
    "        print(f\"=\" * 60)\n",
    "        \n",
    "        if embedded_analysis:\n",
    "            # Mod√®le champion global\n",
    "            global_champion = max(embedded_analysis.items(), key=lambda x: x[1]['embedded_score'])\n",
    "            print(f\"üèÜ CHAMPION GLOBAL EMBARQU√â: {global_champion[0]}\")\n",
    "            print(f\"   Score: {global_champion[1]['embedded_score']:.3f}\")\n",
    "            print(f\"   Recommandation: {global_champion[1]['deployment_recommendation']}\")\n",
    "            \n",
    "            # Top 3 pour d√©ploiement\n",
    "            top_3 = sorted(embedded_analysis.items(), key=lambda x: x[1]['embedded_score'], reverse=True)[:3]\n",
    "            print(f\"\\nü•á TOP 3 POUR D√âPLOIEMENT EMBARQU√â:\")\n",
    "            for i, (model, scores) in enumerate(top_3, 1):\n",
    "                print(f\"   {i}. {model} (Score: {scores['embedded_score']:.3f})\")\n",
    "    \n",
    "    else:\n",
    "        print(\"‚ùå Impossible de cr√©er l'analyse co√ªt/b√©n√©fice\")\n",
    "\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Aucune m√©trique d√©taill√©e disponible pour l'analyse comparative\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44ebba1f",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "source": [
    "## üìù R√©sum√© de l'Entra√Ænement & Prochaines √âtapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "836201cb",
   "metadata": {
    "title": "[python]"
   },
   "outputs": [],
   "source": [
    "def generate_training_summary(training_results):\n",
    "    \"\"\"G√©n√®re un r√©sum√© complet de l'entra√Ænement\"\"\"\n",
    "\n",
    "    timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"üéØ FUTURE VISION TRANSPORT - TRAINING SUMMARY\")\n",
    "    print(\"üöÄ TensorFlow 2.15+ Compatible Training Pipeline\")\n",
    "    print(\"=\"*80)\n",
    "\n",
    "    print(f\"üìÖ Training completed: {timestamp}\")\n",
    "    print(f\"üîß TensorFlow version: {tf.__version__}\")\n",
    "    print(f\"üéØ Target: 8-class Cityscapes segmentation\")\n",
    "    print(f\"üìê Input format: {INPUT_SHAPE} (input_shape compatible)\")\n",
    "\n",
    "    if training_results:\n",
    "        print(f\"\\nüèÜ TRAINED MODELS ({len(training_results)}):\")\n",
    "\n",
    "        for model_name, results in training_results.items():\n",
    "            if results is None:\n",
    "                continue\n",
    "\n",
    "            print(f\"\\n   üìä {model_name}:\")\n",
    "            print(f\"      Parameters: {results['model'].count_params():,}\")\n",
    "            print(f\"      Training time: {results['training_time']/60:.1f} minutes\")\n",
    "            print(f\"      Final IoU: {results['final_metrics']['val_mean_iou']:.4f}\")\n",
    "            print(f\"      Final Dice: {results['final_metrics']['val_dice_coefficient']:.4f}\")\n",
    "            print(f\"      Final Accuracy: {results['final_metrics']['val_accuracy']:.4f}\")\n",
    "            print(f\"      Model file: {results['model_path']}\")\n",
    "            print(f\"      API Compatible: ‚úÖ TF 2.15+ with input_shape\")\n",
    "\n",
    "        # Champion model\n",
    "        best_model = max(training_results.items(),\n",
    "                        key=lambda x: x[1]['final_metrics']['val_mean_iou'] if x[1] else 0)\n",
    "\n",
    "        print(f\"\\nü•á CHAMPION MODEL: {best_model[0]}\")\n",
    "        print(f\"   IoU Score: {best_model[1]['final_metrics']['val_mean_iou']:.4f}\")\n",
    "        print(f\"   Ready for API deployment: ‚úÖ\")\n",
    "\n",
    "    else:\n",
    "        print(\"\\n‚ùå No models were successfully trained\")\n",
    "\n",
    "    print(f\"\\n‚úÖ COMPATIBILITY STATUS:\")\n",
    "    print(f\"   TensorFlow 2.15+: ‚úÖ Compatible\")\n",
    "    print(f\"   API main_keras_compatible.py: ‚úÖ Compatible\")\n",
    "    print(f\"   Custom objects: ‚úÖ Identical\")\n",
    "    print(f\"   Input shape format: ‚úÖ input_shape (not batch_shape)\")\n",
    "    print(f\"   Production ready: ‚úÖ Ready\")\n",
    "\n",
    "    print(f\"\\nüéØ NEXT STEPS:\")\n",
    "    print(f\"   1. ‚úÖ Models trained with TF 2.15+ compatibility\")\n",
    "    print(f\"   2. ‚úÖ Custom loss/metrics identical to API\")\n",
    "    print(f\"   3. ‚úÖ Input shape format corrected\")\n",
    "    print(f\"   4. üìã Ready for Milestone 4: FastAPI deployment\")\n",
    "    print(f\"   5. üìã Ready for Milestone 5: Next.js application\")\n",
    "\n",
    "    print(f\"\\nüîó INTEGRATION:\")\n",
    "    print(f\"   - Load models in main_keras_compatible.py\")\n",
    "    print(f\"   - No conversion needed - direct compatibility\")\n",
    "    print(f\"   - Same preprocessing pipeline\")\n",
    "    print(f\"   - Same class mapping and colors\")\n",
    "\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"üéâ TENSORFLOW 2.15+ COMPATIBLE TRAINING COMPLETED!\")\n",
    "    print(\"=\"*80)\n",
    "\n",
    "# G√©n√©rer le r√©sum√© final\n",
    "if 'training_results' in locals():\n",
    "    generate_training_summary(training_results)\n",
    "else:\n",
    "    generate_training_summary({})\n",
    "\n",
    "# Cleanup final\n",
    "cleanup_memory(verbose=True)\n",
    "\n",
    "print(f\"\\nüíæ All training artifacts saved in:\")\n",
    "print(f\"   Models: ./models/\")\n",
    "print(f\"   History: ./training_history_*.csv\")\n",
    "print(f\"   Comparison: ./models_comparison_tf_2_15_compatible_*.csv\")\n",
    "print(f\"   Compatibility: ./api_compatibility_report_*.csv\")\n",
    "\n",
    "print(f\"\\nüöÄ Training pipeline completed successfully!\")\n",
    "print(f\"   Ready for production deployment with TensorFlow 2.18 ‚úÖ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8e23db9",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "## üéâ Validation et R√©sum√© Final du Pipeline\n",
    "\n",
    "### ‚úÖ Pipeline Compl√©t√© avec Succ√®s\n",
    "\n",
    "**5 Mod√®les Entra√Æn√©s** :\n",
    "1. **UNet Mini** - Mod√®le simple non pr√©-entra√Æn√© (~1.9M param√®tres)\n",
    "2. **VGG16 U-Net** - Mod√®le pr√©-entra√Æn√© classique (~25M param√®tres)  \n",
    "3. **UNet EfficientNet-B0** - Mod√®le avanc√© avec backbone efficace (~5M param√®tres)\n",
    "4. **DeepLabV3+ MobileNetV2** - Architecture ASPP optimis√©e (~2.5M param√®tres)\n",
    "5. **Segformer-B0** - Vision Transformer l√©ger (~3.8M param√®tres)\n",
    "\n",
    "### üìä Analyses Compl√®tes Impl√©ment√©es\n",
    "\n",
    "**M√©triques d'√âvaluation** :\n",
    "- 13 m√©triques d√©taill√©es par mod√®le\n",
    "- Heatmap des performances\n",
    "- Analyse de convergence (4 graphiques)\n",
    "- Tableau comparatif avec champions par cat√©gorie\n",
    "\n",
    "**Comparaisons des Mod√®les** :\n",
    "- Graphiques radar multi-crit√®res\n",
    "- Analyse co√ªt/b√©n√©fice pour syst√®mes embarqu√©s\n",
    "- Strat√©gies de d√©ploiement par sc√©nario d'usage\n",
    "- Recommandations par contexte (4 sc√©narios)\n",
    "\n",
    "### üõ†Ô∏è Optimisations Google Colab L4\n",
    "\n",
    "**Gestion M√©moire** :\n",
    "- Limite GPU : 14GB/16GB\n",
    "- Nettoyage automatique entre mod√®les\n",
    "- Monitoring en temps r√©el\n",
    "- Garbage collection optimis√©\n",
    "\n",
    "**Performance** :\n",
    "- Mixed precision activ√©e\n",
    "- XLA JIT compilation\n",
    "- Allocation GPU asynchrone\n",
    "- Batch sizes adaptatifs par mod√®le\n",
    "\n",
    "### üöÄ Pr√™t pour Milestone 4\n",
    "\n",
    "**Compatibilit√© API** :\n",
    "- TensorFlow 2.18 compatible\n",
    "- Format input_shape (non batch_shape)\n",
    "- Custom objects identiques √† l'API\n",
    "- Sauvegarde .keras moderne\n",
    "\n",
    "**Fichiers G√©n√©r√©s** :\n",
    "- Mod√®les entra√Æn√©s (.keras + .h5 backup)\n",
    "- Historiques d'entra√Ænement (.csv)\n",
    "- Analyses d√©taill√©es (.csv)\n",
    "- Strat√©gies de d√©ploiement (.csv)\n",
    "\n",
    "### üìà R√©sultats Attendus\n",
    "\n",
    "Selon la configuration, vous devriez obtenir :\n",
    "- **IoU** : 15-45% (selon mod√®le et donn√©es d'entra√Ænement)\n",
    "- **Temps d'entra√Ænement** : 5-25 minutes par mod√®le\n",
    "- **Taille des mod√®les** : 1.9M √† 25M param√®tres\n",
    "- **Vitesse d'inf√©rence** : 50-200ms par image\n",
    "\n",
    "### üéØ Prochaines √âtapes\n",
    "\n",
    "1. ‚úÖ **Milestone 3 Compl√©t√©** - Pipeline d'entra√Ænement avec 5 mod√®les\n",
    "2. üìã **Milestone 4** - D√©veloppement API FastAPI avec d√©ploiement mod√®les\n",
    "3. üìã **Milestone 5** - Interface Next.js pour visualisation r√©sultats\n",
    "\n",
    "---\n",
    "**üéâ Pipeline d'Entra√Ænement Future Vision Transport - Termin√© avec Succ√®s !**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35283e50",
   "metadata": {
    "title": "[python]"
   },
   "outputs": [],
   "source": [
    "print(\"üéØ VALIDATION FINALE DU PIPELINE\")\n",
    "print(\"=\" * 80)\n",
    "print(\"‚úÖ 5 architectures de mod√®les impl√©ment√©es\")\n",
    "print(\"‚úÖ Entra√Ænement s√©quentiel avec nettoyage m√©moire\")\n",
    "print(\"‚úÖ 2 sections d'analyse compl√®tes ajout√©es\")\n",
    "print(\"‚úÖ Balises Jupytext pour conversion notebook\")\n",
    "print(\"‚úÖ Optimisations Google Colab L4\")\n",
    "print(\"‚úÖ Compatible TensorFlow 2.18\")\n",
    "print(\"‚úÖ Pr√™t pour Milestone 4 (FastAPI)\")\n",
    "print(\"=\" * 80)\n",
    "print(\"üöÄ PIPELINE VALID√â ET COMPLET !\")\n",
    "\n",
    "# Affichage des statistiques finales\n",
    "try:\n",
    "    memory_stats = monitor_memory_usage()\n",
    "    print(f\"\\nüìä Statistiques finales:\")\n",
    "    print(f\"   RAM utilis√©e: {memory_stats['ram_gb']:.1f} GB\")\n",
    "    print(f\"   GPU utilis√©: {memory_stats['gpu_used_gb']:.1f} GB ({memory_stats['gpu_percent']:.1f}%)\")\n",
    "except:\n",
    "    print(\"\\nüìä Monitoring m√©moire non disponible\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4f0a4c5",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "## üéØ V√©rification Compl√®te du Pipeline & Simulation API\n",
    "V√©rification compl√®te du pipeline avec visualisations comme attendues pour l'API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eacac6e4",
   "metadata": {
    "lines_to_next_cell": 1,
    "title": "[python]"
   },
   "outputs": [],
   "source": [
    "import matplotlib.patches as patches\n",
    "from matplotlib.gridspec import GridSpec\n",
    "import matplotlib.colors as colors\n",
    "\n",
    "def create_cityscapes_colormap():\n",
    "    \"\"\"Cr√©e la colormap Cityscapes pour visualisation des masques\"\"\"\n",
    "    # Couleurs exactes des 8 classes Cityscapes\n",
    "    class_colors = np.array([\n",
    "        [139, 69, 19],    # road (brown)\n",
    "        [128, 128, 128],  # building (gray)\n",
    "        [255, 215, 0],    # object (gold)\n",
    "        [34, 139, 34],    # nature (green)\n",
    "        [135, 206, 235],  # sky (sky blue)\n",
    "        [255, 105, 180],  # person (pink)\n",
    "        [220, 20, 60],    # vehicle (red)\n",
    "        [0, 0, 0]         # void (black)\n",
    "    ]) / 255.0\n",
    "\n",
    "    return colors.ListedColormap(class_colors)\n",
    "\n",
    "def visualize_data_samples(generator, num_samples=4):\n",
    "    \"\"\"Visualise des √©chantillons de donn√©es avec images et masques\"\"\"\n",
    "\n",
    "    print(\"\\nüìä VISUALISATION DES DONN√âES D'ENTR√âE\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "    # R√©cup√©rer un batch\n",
    "    batch_images, batch_masks = generator[0]\n",
    "\n",
    "    # Cr√©er la colormap\n",
    "    cityscapes_cmap = create_cityscapes_colormap()\n",
    "\n",
    "    fig = plt.figure(figsize=(20, 12))\n",
    "    gs = GridSpec(3, num_samples, figure=fig, hspace=0.3, wspace=0.2)\n",
    "\n",
    "    for i in range(min(num_samples, len(batch_images))):\n",
    "        # Image originale\n",
    "        ax1 = fig.add_subplot(gs[0, i])\n",
    "        ax1.imshow(batch_images[i])\n",
    "        ax1.set_title(f'Image {i+1}\\n{batch_images[i].shape}', fontsize=10)\n",
    "        ax1.axis('off')\n",
    "\n",
    "        # Masque ground truth (one-hot vers classe)\n",
    "        ax2 = fig.add_subplot(gs[1, i])\n",
    "        mask_classes = np.argmax(batch_masks[i], axis=-1)\n",
    "        im2 = ax2.imshow(mask_classes, cmap=cityscapes_cmap, vmin=0, vmax=7)\n",
    "        ax2.set_title(f'Masque GT\\n{mask_classes.shape}', fontsize=10)\n",
    "        ax2.axis('off')\n",
    "\n",
    "        # Statistiques des classes\n",
    "        ax3 = fig.add_subplot(gs[2, i])\n",
    "        unique, counts = np.unique(mask_classes, return_counts=True)\n",
    "        class_names = ['road', 'building', 'object', 'nature', 'sky', 'person', 'vehicle', 'void']\n",
    "        bars = ax3.bar(range(len(unique)), counts, color=[cityscapes_cmap.colors[u] for u in unique])\n",
    "        ax3.set_title('Distribution classes', fontsize=9)\n",
    "        ax3.set_xticks(range(len(unique)))\n",
    "        ax3.set_xticklabels([class_names[u] for u in unique], rotation=45, fontsize=8)\n",
    "        ax3.tick_params(axis='y', labelsize=8)\n",
    "\n",
    "    # Colorbar pour les masques\n",
    "    cbar_ax = fig.add_axes([0.92, 0.4, 0.02, 0.2])\n",
    "    cbar = fig.colorbar(im2, cax=cbar_ax)\n",
    "    cbar.set_ticks(range(8))\n",
    "    cbar.set_ticklabels(['road', 'building', 'object', 'nature', 'sky', 'person', 'vehicle', 'void'], fontsize=8)\n",
    "\n",
    "    plt.suptitle('üéØ √âCHANTILLONS DE DONN√âES CITYSCAPES (8 CLASSES)', fontsize=16, y=0.95)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    print(f\"‚úÖ Batch shape: Images {batch_images.shape}, Masques {batch_masks.shape}\")\n",
    "    print(f\"‚úÖ Format compatible API: input_shape {INPUT_SHAPE}\")\n",
    "\n",
    "def visualize_augmentation_pipeline(generator_with_aug, generator_without_aug, num_samples=3):\n",
    "    \"\"\"Visualise l'effet des augmentations de donn√©es\"\"\"\n",
    "\n",
    "    print(\"\\nüé® VISUALISATION DES AUGMENTATIONS DE DONN√âES\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "    # R√©cup√©rer des √©chantillons avec et sans augmentation\n",
    "    aug_batch = generator_with_aug[0]\n",
    "    no_aug_batch = generator_without_aug[0]\n",
    "\n",
    "    cityscapes_cmap = create_cityscapes_colormap()\n",
    "\n",
    "    fig, axes = plt.subplots(4, num_samples, figsize=(15, 12))\n",
    "\n",
    "    for i in range(num_samples):\n",
    "        # Images sans augmentation\n",
    "        axes[0, i].imshow(no_aug_batch[0][i])\n",
    "        axes[0, i].set_title(f'Image Originale {i+1}', fontsize=10)\n",
    "        axes[0, i].axis('off')\n",
    "\n",
    "        # Masques sans augmentation\n",
    "        mask_orig = np.argmax(no_aug_batch[1][i], axis=-1)\n",
    "        axes[1, i].imshow(mask_orig, cmap=cityscapes_cmap, vmin=0, vmax=7)\n",
    "        axes[1, i].set_title(f'Masque Original {i+1}', fontsize=10)\n",
    "        axes[1, i].axis('off')\n",
    "\n",
    "        # Images avec augmentation\n",
    "        axes[2, i].imshow(aug_batch[0][i])\n",
    "        axes[2, i].set_title(f'Image Augment√©e {i+1}', fontsize=10)\n",
    "        axes[2, i].axis('off')\n",
    "\n",
    "        # Masques avec augmentation\n",
    "        mask_aug = np.argmax(aug_batch[1][i], axis=-1)\n",
    "        axes[3, i].imshow(mask_aug, cmap=cityscapes_cmap, vmin=0, vmax=7)\n",
    "        axes[3, i].set_title(f'Masque Augment√© {i+1}', fontsize=10)\n",
    "        axes[3, i].axis('off')\n",
    "\n",
    "    plt.suptitle('üé® PIPELINE AUGMENTATION ALBUMENTATIONS (>1000 FPS)', fontsize=14)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    print(\"‚úÖ Augmentations appliqu√©es:\")\n",
    "    print(\"   ‚Ä¢ RandomBrightnessContrast\")\n",
    "    print(\"   ‚Ä¢ HueSaturationValue\")\n",
    "    print(\"   ‚Ä¢ RandomGamma\")\n",
    "    print(\"   ‚Ä¢ GaussianBlur\")\n",
    "    print(\"   ‚Ä¢ HorizontalFlip\")\n",
    "    print(\"   ‚Ä¢ ShiftScaleRotate\")\n",
    "    print(\"‚úÖ Augmentation coordonn√©e image+masque avec Albumentations\")\n",
    "\n",
    "def load_and_test_trained_models():\n",
    "    \"\"\"Charge et teste les mod√®les entra√Æn√©s\"\"\"\n",
    "\n",
    "    print(\"\\nü§ñ TEST DES MOD√àLES ENTRA√éN√âS\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "    trained_models = {}\n",
    "\n",
    "    # Chercher les mod√®les dans le dossier models/\n",
    "    import glob\n",
    "    model_files = glob.glob('models/*.keras') + glob.glob('models/*.h5')\n",
    "\n",
    "    if not model_files:\n",
    "        print(\"‚ö†Ô∏è Aucun mod√®le trouv√© - utilisation des r√©sultats d'entra√Ænement en m√©moire\")\n",
    "        if 'training_results' in locals() and training_results:\n",
    "            for model_name, results in training_results.items():\n",
    "                if results and 'model' in results:\n",
    "                    trained_models[model_name] = results['model']\n",
    "        return trained_models\n",
    "\n",
    "    print(f\"üìÅ Mod√®les trouv√©s: {len(model_files)}\")\n",
    "\n",
    "    for model_file in model_files[:2]:  # Charger max 2 mod√®les\n",
    "        try:\n",
    "            print(f\"üîÑ Chargement: {model_file}\")\n",
    "\n",
    "            # Charger avec custom objects\n",
    "            model = tf.keras.models.load_model(model_file, custom_objects=CUSTOM_OBJECTS, compile=False)\n",
    "\n",
    "            # Recompiler pour test\n",
    "            model.compile(\n",
    "                optimizer='adam',\n",
    "                loss='sparse_categorical_crossentropy',\n",
    "                metrics=['accuracy']\n",
    "            )\n",
    "\n",
    "            model_name = os.path.basename(model_file).split('_')[0]\n",
    "            trained_models[model_name] = model\n",
    "\n",
    "            print(f\"‚úÖ {model_name}: {model.count_params():,} param√®tres\")\n",
    "            print(f\"   Input: {model.input_shape}\")\n",
    "            print(f\"   Output: {model.output_shape}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Erreur chargement {model_file}: {e}\")\n",
    "\n",
    "    return trained_models\n",
    "\n",
    "def simulate_api_request_with_predictions(models, test_generator, num_samples=2):\n",
    "    \"\"\"Simule une requ√™te API compl√®te avec pr√©dictions visuelles\"\"\"\n",
    "\n",
    "    print(\"\\nüöÄ SIMULATION REQU√äTE API - PR√âDICTIONS VISUELLES\")\n",
    "    print(\"=\"*80)\n",
    "\n",
    "    if not models:\n",
    "        print(\"‚ùå Aucun mod√®le disponible pour les pr√©dictions\")\n",
    "        return\n",
    "\n",
    "    # R√©cup√©rer √©chantillons de test\n",
    "    test_images, test_masks_gt = test_generator[0]\n",
    "\n",
    "    cityscapes_cmap = create_cityscapes_colormap()\n",
    "    class_names = ['road', 'building', 'object', 'nature', 'sky', 'person', 'vehicle', 'void']\n",
    "\n",
    "    for sample_idx in range(min(num_samples, len(test_images))):\n",
    "\n",
    "        print(f\"\\nüì∏ √âCHANTILLON {sample_idx + 1}\")\n",
    "        print(\"-\" * 40)\n",
    "\n",
    "        input_image = test_images[sample_idx:sample_idx+1]  # Batch de 1\n",
    "        gt_mask = np.argmax(test_masks_gt[sample_idx], axis=-1)\n",
    "\n",
    "        # Cr√©er figure pour cet √©chantillon\n",
    "        fig = plt.figure(figsize=(20, 6))\n",
    "        gs = GridSpec(2, len(models) + 2, figure=fig, hspace=0.3, wspace=0.2)\n",
    "\n",
    "        # Image originale\n",
    "        ax_img = fig.add_subplot(gs[:, 0])\n",
    "        ax_img.imshow(test_images[sample_idx])\n",
    "        ax_img.set_title(f\"Image d\\'entr√©e\\n{input_image.shape[1:]}\", fontsize=12, fontweight='bold')\n",
    "        ax_img.axis('off')\n",
    "\n",
    "        # Masque ground truth\n",
    "        ax_gt = fig.add_subplot(gs[:, 1])\n",
    "        ax_gt.imshow(gt_mask, cmap=cityscapes_cmap, vmin=0, vmax=7)\n",
    "        ax_gt.set_title('Masque Ground Truth', fontsize=12, fontweight='bold')\n",
    "        ax_gt.axis('off')\n",
    "\n",
    "        # Pr√©dictions pour chaque mod√®le\n",
    "        predictions_data = []\n",
    "\n",
    "        for idx, (model_name, model) in enumerate(models.items()):\n",
    "\n",
    "            print(f\"üîÆ Pr√©diction avec {model_name}...\")\n",
    "\n",
    "            # Mesurer temps d'inf√©rence\n",
    "            start_time = time.time()\n",
    "            prediction = model.predict(input_image, verbose=0)\n",
    "            inference_time = time.time() - start_time\n",
    "\n",
    "            # Convertir en masque de classes\n",
    "            pred_mask = np.argmax(prediction[0], axis=-1)\n",
    "            confidence_map = np.max(prediction[0], axis=-1)\n",
    "\n",
    "            # Calculer m√©triques rapides\n",
    "            intersection = np.logical_and(gt_mask == pred_mask, gt_mask != 7)  # Exclude void\n",
    "            union = np.logical_or(gt_mask != 7, pred_mask != 7)\n",
    "            iou_sample = np.sum(intersection) / np.sum(union) if np.sum(union) > 0 else 0\n",
    "\n",
    "            predictions_data.append({\n",
    "                'model_name': model_name,\n",
    "                'pred_mask': pred_mask,\n",
    "                'confidence': confidence_map,\n",
    "                'iou': iou_sample,\n",
    "                'inference_time': inference_time\n",
    "            })\n",
    "\n",
    "            # Visualiser pr√©diction\n",
    "            ax_pred = fig.add_subplot(gs[0, idx + 2])\n",
    "            ax_pred.imshow(pred_mask, cmap=cityscapes_cmap, vmin=0, vmax=7)\n",
    "            ax_pred.set_title(f'{model_name}\\\\nIoU: {iou_sample:.3f}', fontsize=10, fontweight='bold')\n",
    "            ax_pred.axis('off')\n",
    "\n",
    "            # Visualiser confiance\n",
    "            ax_conf = fig.add_subplot(gs[1, idx + 2])\n",
    "            im_conf = ax_conf.imshow(confidence_map, cmap='viridis', vmin=0, vmax=1)\n",
    "            ax_conf.set_title(f'Confiance\\\\n{inference_time*1000:.1f}ms', fontsize=10)\n",
    "            ax_conf.axis('off')\n",
    "\n",
    "            # Colorbar confiance\n",
    "            if idx == len(models) - 1:\n",
    "                cbar_ax = fig.add_axes([0.92, 0.1, 0.02, 0.35])\n",
    "                cbar = fig.colorbar(im_conf, cax=cbar_ax)\n",
    "                cbar.set_label('Confiance', fontsize=10)\n",
    "\n",
    "        plt.suptitle(f'üöÄ SIMULATION API - SEGMENTATION AUTOMATIQUE (√âchantillon {sample_idx + 1})',\n",
    "                    fontsize=16, y=0.95)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "        # Rapport d√©taill√© pour cet √©chantillon\n",
    "        print(\"üìä RAPPORT DE PR√âDICTION:\")\n",
    "        for pred_data in predictions_data:\n",
    "            print(f\"   ü§ñ {pred_data['model_name']}:\")\n",
    "            print(f\"      IoU: {pred_data['iou']:.4f}\")\n",
    "            print(f\"      Temps inf√©rence: {pred_data['inference_time']*1000:.1f}ms\")\n",
    "            print(f\"      Confiance moyenne: {pred_data['confidence'].mean():.3f}\")\n",
    "            print(f\"      Classes pr√©dites: {len(np.unique(pred_data['pred_mask']))}\")\n",
    "\n",
    "def create_final_performance_summary(models, test_generator, num_test_samples=10):\n",
    "    \"\"\"Cr√©e un r√©sum√© final des performances avec m√©triques compl√®tes\"\"\"\n",
    "\n",
    "    print(\"\\nüìà R√âSUM√â FINAL DES PERFORMANCES\")\n",
    "    print(\"=\"*80)\n",
    "\n",
    "    if not models:\n",
    "        print(\"‚ùå Aucun mod√®le disponible pour l'√©valuation\")\n",
    "        return\n",
    "\n",
    "    performance_data = []\n",
    "\n",
    "    for model_name, model in models.items():\n",
    "\n",
    "        print(f\"\\nüîç √âvaluation {model_name}...\")\n",
    "\n",
    "        # M√©triques sur plusieurs √©chantillons\n",
    "        total_iou = 0\n",
    "        total_dice = 0\n",
    "        total_accuracy = 0\n",
    "        total_time = 0\n",
    "\n",
    "        for i in range(min(num_test_samples, len(test_generator))):\n",
    "            batch_images, batch_masks = test_generator[i]\n",
    "\n",
    "            # Pr√©diction avec mesure du temps\n",
    "            start_time = time.time()\n",
    "            predictions = model.predict(batch_images, verbose=0)\n",
    "            batch_time = time.time() - start_time\n",
    "\n",
    "            # Calcul m√©triques par √©chantillon du batch\n",
    "            for j in range(len(batch_images)):\n",
    "                gt_mask = np.argmax(batch_masks[j], axis=-1)\n",
    "                pred_mask = np.argmax(predictions[j], axis=-1)\n",
    "\n",
    "                # IoU\n",
    "                intersection = np.logical_and(gt_mask == pred_mask, gt_mask != 7)\n",
    "                union = np.logical_or(gt_mask != 7, pred_mask != 7)\n",
    "                iou = np.sum(intersection) / np.sum(union) if np.sum(union) > 0 else 0\n",
    "                total_iou += iou\n",
    "\n",
    "                # Dice\n",
    "                intersection_dice = np.sum(intersection)\n",
    "                total_pixels = np.sum(gt_mask != 7) + np.sum(pred_mask != 7)\n",
    "                dice = 2 * intersection_dice / total_pixels if total_pixels > 0 else 0\n",
    "                total_dice += dice\n",
    "\n",
    "                # Accuracy\n",
    "                accuracy = np.mean(gt_mask == pred_mask)\n",
    "                total_accuracy += accuracy\n",
    "\n",
    "            total_time += batch_time\n",
    "\n",
    "        # Moyennes\n",
    "        num_samples = min(num_test_samples * BATCH_SIZE, len(test_generator) * BATCH_SIZE)\n",
    "        avg_iou = total_iou / num_samples\n",
    "        avg_dice = total_dice / num_samples\n",
    "        avg_accuracy = total_accuracy / num_samples\n",
    "        avg_time_per_image = (total_time / num_samples) * 1000  # ms\n",
    "\n",
    "        performance_data.append({\n",
    "            'Mod√®le': model_name.upper(),\n",
    "            'Param√®tres': f\"{model.count_params():,}\",\n",
    "            'IoU Moyen': f\"{avg_iou:.4f}\",\n",
    "            'Dice Moyen': f\"{avg_dice:.4f}\",\n",
    "            'Pr√©cision': f\"{avg_accuracy:.4f}\",\n",
    "            'Temps/Image (ms)': f\"{avg_time_per_image:.1f}\",\n",
    "            'Compatible API': \"‚úÖ TF 2.15+\",\n",
    "            'Pr√™t Production': \"‚úÖ Oui\"\n",
    "        })\n",
    "\n",
    "        print(f\"   IoU: {avg_iou:.4f}\")\n",
    "        print(f\"   Dice: {avg_dice:.4f}\")\n",
    "        print(f\"   Pr√©cision: {avg_accuracy:.4f}\")\n",
    "        print(f\"   Temps/image: {avg_time_per_image:.1f}ms\")\n",
    "\n",
    "    # Tableau final\n",
    "    df_performance = pd.DataFrame(performance_data)\n",
    "\n",
    "    print(\"\\nüèÜ TABLEAU FINAL DES PERFORMANCES:\")\n",
    "    print(df_performance.to_string(index=False))\n",
    "\n",
    "    # Champion model\n",
    "    best_model = max(performance_data, key=lambda x: float(x['IoU Moyen']))\n",
    "\n",
    "    print(f\"\\nü•á MOD√àLE CHAMPION: {best_model['Mod√®le']}\")\n",
    "    print(f\"   Meilleur IoU: {best_model['IoU Moyen']}\")\n",
    "    print(f\"   Temps d'inf√©rence: {best_model['Temps/Image (ms)']}ms\")\n",
    "    print(f\"   Param√®tres: {best_model['Param√®tres']}\")\n",
    "    print(f\"   Compatible API FastAPI: ‚úÖ\")\n",
    "    print(f\"   Pr√™t pour d√©ploiement: ‚úÖ\")\n",
    "\n",
    "    # Sauvegarder le rapport\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    df_performance.to_csv(f'pipeline_verification_report_{timestamp}.csv', index=False)\n",
    "\n",
    "    return df_performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbcff7d8",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "### üöÄ Ex√©cution de la V√©rification Compl√®te"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0db3845f",
   "metadata": {
    "title": "[python]"
   },
   "outputs": [],
   "source": [
    "# Ex√©cution de la v√©rification compl√®te du pipeline\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    print(\"\\n\" + \"üéØ\" * 80)\n",
    "    print(\"üöÄ V√âRIFICATION COMPL√àTE DU PIPELINE - SIMULATION API COMPLETE\")\n",
    "    print(\"üéØ\" * 80)\n",
    "\n",
    "    # 1. Visualisation des donn√©es d'entr√©e\n",
    "    if 'val_generator' in locals():\n",
    "        visualize_data_samples(val_generator, num_samples=4)\n",
    "\n",
    "    # 2. Visualisation des augmentations\n",
    "    if 'train_generator' in locals() and 'val_generator' in locals():\n",
    "        print(\"\\nüîÑ Cr√©ation g√©n√©rateur sans augmentation pour comparaison...\")\n",
    "        no_aug_generator = CityscapesDataGenerator(\n",
    "            val_images[:4], val_masks[:4],\n",
    "            batch_size=4,\n",
    "            augmentation=None,\n",
    "            shuffle=False\n",
    "        )\n",
    "        visualize_augmentation_pipeline(train_generator, no_aug_generator, num_samples=3)\n",
    "\n",
    "    # 3. Chargement et test des mod√®les\n",
    "    trained_models = load_and_test_trained_models()\n",
    "\n",
    "    # 4. Simulation requ√™te API avec pr√©dictions\n",
    "    if trained_models and 'val_generator' in locals():\n",
    "        simulate_api_request_with_predictions(trained_models, val_generator, num_samples=2)\n",
    "\n",
    "    # 5. R√©sum√© final des performances\n",
    "    if trained_models and 'val_generator' in locals():\n",
    "        final_report = create_final_performance_summary(trained_models, val_generator, num_test_samples=5)\n",
    "\n",
    "    print(\"üéâ V√âRIFICATION PIPELINE TERMIN√âE\")"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "encoding": "# -*- coding: utf-8 -*-"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
