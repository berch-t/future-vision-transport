{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1dedcec8",
   "metadata": {},
   "source": [
    "# üèóÔ∏è Model Implementation - Architectures de Segmentation\n",
    "\n",
    "## üéØ Objectifs\n",
    "\n",
    "**Mission** : Impl√©menter 5 architectures de segmentation en Keras/TensorFlow \n",
    "\n",
    "**Strat√©gie d'impl√©mentation** :\n",
    "1. **Structure modulaire** : Classes r√©utilisables et configurables\n",
    "2. **Transfer learning** : Backbones pr√©-entra√Æn√©s ImageNet\n",
    "3. **Optimisation embarqu√©e** : Architectures adapt√©es aux contraintes\n",
    "4. **Tests unitaires** : Validation des dimensions et fonctionnalit√©s\n",
    "\n",
    "**Architectures impl√©ment√©es** :\n",
    "- U-Net + EfficientNet (Encoder-Decoder classique)\n",
    "- DeepLabV3+ + MobileNet (Atrous convolutions + efficacit√©)  \n",
    "- Segformer-B0 (Vision Transformer l√©ger)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acd4429c",
   "metadata": {},
   "source": [
    "## üìö Imports et Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ed73577a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Configuration charg√©e\n",
      "üîó TensorFlow: 2.15.1\n",
      "üéØ Impl√©mentation de 5 architectures modulaires\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Core libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Deep Learning\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, Model, Input\n",
    "from tensorflow.keras.applications import (\n",
    "    EfficientNetB0, EfficientNetB1, EfficientNetB2,\n",
    "    MobileNetV2, VGG16\n",
    ")\n",
    "from tensorflow.keras.optimizers import Adam, AdamW\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "\n",
    "# Configuration\n",
    "plt.style.use('seaborn-v0_8')\n",
    "\n",
    "# Chemins du projet\n",
    "PROJECT_ROOT = Path(\"C:/Tonton/OpenClassrooms/Projet_7_traiter_images_systeme_embarque_voiture_autonome\")\n",
    "NOTEBOOKS_DIR = PROJECT_ROOT / \"notebooks\"\n",
    "OUTPUTS_DIR = NOTEBOOKS_DIR / \"outputs\"\n",
    "FIGURES_DIR = NOTEBOOKS_DIR / \"figures\"\n",
    "\n",
    "print(\"‚úÖ Configuration charg√©e\")\n",
    "print(f\"üîó TensorFlow: {tf.__version__}\")\n",
    "print(f\"üéØ Impl√©mentation de 5 architectures modulaires\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38e0d220",
   "metadata": {},
   "source": [
    "## ‚öôÔ∏è Configuration Exp√©rimentale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "568474eb",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéØ Configuration des mod√®les:\n",
      "   ‚Ä¢ Input shape: (512, 1024, 3)\n",
      "   ‚Ä¢ Nombre de classes: 8\n",
      "   ‚Ä¢ R√©gularisation L2: 0.0001\n"
     ]
    }
   ],
   "source": [
    "# Configuration globale des mod√®les\n",
    "MODEL_CONFIG = {\n",
    "    'input_shape': (512, 1024, 3),\n",
    "    'num_classes': 8,\n",
    "    'activation': 'softmax',\n",
    "    'dropout_rate': 0.3,\n",
    "    'batch_norm': True,\n",
    "    'l2_reg': 1e-4\n",
    "}\n",
    "\n",
    "# Charger le mapping des classes\n",
    "with open(OUTPUTS_DIR / \"class_mapping.json\", 'r') as f:\n",
    "    class_mapping = json.load(f)\n",
    "\n",
    "print(\"üéØ Configuration des mod√®les:\")\n",
    "print(f\"   ‚Ä¢ Input shape: {MODEL_CONFIG['input_shape']}\")\n",
    "print(f\"   ‚Ä¢ Nombre de classes: {MODEL_CONFIG['num_classes']}\")\n",
    "print(f\"   ‚Ä¢ R√©gularisation L2: {MODEL_CONFIG['l2_reg']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2232f8c5",
   "metadata": {},
   "source": [
    "## üèóÔ∏è Classe de Base pour Mod√®les de Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cf02df85",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Classe de base SegmentationModel d√©finie\n"
     ]
    }
   ],
   "source": [
    "class SegmentationModel:\n",
    "    \"\"\"\n",
    "    Classe de base pour tous les mod√®les de segmentation.\n",
    "    Fournit une interface commune et des utilities partag√©es.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, input_shape=(512, 1024, 3), num_classes=8, name=\"BaseSegmentationModel\"):\n",
    "        self.input_shape = input_shape\n",
    "        self.num_classes = num_classes\n",
    "        self.name = name\n",
    "        self.model = None\n",
    "        \n",
    "    def build_model(self):\n",
    "        \"\"\"√Ä impl√©menter dans les classes filles\"\"\"\n",
    "        raise NotImplementedError(\"Subclasses must implement build_model\")\n",
    "    \n",
    "    def compile_model(self, optimizer='adam', loss='sparse_categorical_crossentropy', metrics=None):\n",
    "        \"\"\"Compile le mod√®le avec les param√®tres sp√©cifi√©s\"\"\"\n",
    "        if metrics is None:\n",
    "            metrics = ['accuracy']\n",
    "            \n",
    "        if self.model is None:\n",
    "            raise ValueError(\"Model must be built before compilation\")\n",
    "            \n",
    "        self.model.compile(\n",
    "            optimizer=optimizer,\n",
    "            loss=loss,\n",
    "            metrics=metrics\n",
    "        )\n",
    "        \n",
    "        print(f\"‚úÖ Mod√®le {self.name} compil√©\")\n",
    "        \n",
    "    def get_model_info(self):\n",
    "        \"\"\"Retourne les informations du mod√®le\"\"\"\n",
    "        if self.model is None:\n",
    "            return {\"error\": \"Model not built\"}\n",
    "            \n",
    "        total_params = self.model.count_params()\n",
    "        trainable_params = sum([tf.keras.backend.count_params(w) for w in self.model.trainable_weights])\n",
    "        \n",
    "        return {\n",
    "            'name': self.name,\n",
    "            'total_params': total_params,\n",
    "            'trainable_params': trainable_params,\n",
    "            'input_shape': self.input_shape,\n",
    "            'output_shape': self.model.output_shape,\n",
    "            'layers': len(self.model.layers)\n",
    "        }\n",
    "    \n",
    "    def summary(self):\n",
    "        \"\"\"Affiche le r√©sum√© du mod√®le\"\"\"\n",
    "        if self.model is not None:\n",
    "            return self.model.summary()\n",
    "        else:\n",
    "            print(\"‚ùå Mod√®le non construit\")\n",
    "\n",
    "print(\"‚úÖ Classe de base SegmentationModel d√©finie\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04662b10",
   "metadata": {},
   "source": [
    "## üî• Architecture 1: U-Net + EfficientNet\n",
    "\n",
    "**Conception** : Encoder-Decoder avec skip connections et backbone efficace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "51222d12",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üî• CONSTRUCTION U-NET + EFFICIENTNET\n",
      "==================================================\n",
      "‚úÖ UNet_EfficientNetB0 construit avec succ√®s\n",
      "üìä U-Net EfficientNet-B0:\n",
      "   ‚Ä¢ Param√®tres totaux: 14,240,875\n",
      "   ‚Ä¢ Param√®tres entra√Ænables: 10,188,360\n",
      "   ‚Ä¢ Couches: 272\n"
     ]
    }
   ],
   "source": [
    "class UNetEfficientNet(SegmentationModel):\n",
    "    \"\"\"\n",
    "    U-Net avec backbone EfficientNet pour encodage efficace\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, backbone='B0', input_shape=(512, 1024, 3), num_classes=8, freeze_backbone=False):\n",
    "        super().__init__(input_shape, num_classes, f\"UNet_EfficientNet{backbone}\")\n",
    "        self.backbone_name = backbone\n",
    "        self.freeze_backbone = freeze_backbone\n",
    "        \n",
    "    def build_model(self):\n",
    "        \"\"\"Construit le mod√®le U-Net avec EfficientNet backbone\"\"\"\n",
    "        \n",
    "        # S√©lection du backbone\n",
    "        if self.backbone_name == 'B0':\n",
    "            backbone = EfficientNetB0(weights='imagenet', include_top=False, input_shape=self.input_shape)\n",
    "        elif self.backbone_name == 'B1':\n",
    "            backbone = EfficientNetB1(weights='imagenet', include_top=False, input_shape=self.input_shape)\n",
    "        elif self.backbone_name == 'B2':\n",
    "            backbone = EfficientNetB2(weights='imagenet', include_top=False, input_shape=self.input_shape)\n",
    "        else:\n",
    "            raise ValueError(f\"Backbone {self.backbone_name} non support√©\")\n",
    "        \n",
    "        # Gel du backbone si sp√©cifi√©\n",
    "        if self.freeze_backbone:\n",
    "            backbone.trainable = False\n",
    "            \n",
    "        # Points d'extraction pour skip connections\n",
    "        skip_layer_names = {\n",
    "            'B0': ['block2a_expand_activation', 'block3a_expand_activation', \n",
    "                   'block4a_expand_activation', 'block6a_expand_activation'],\n",
    "            'B1': ['block2a_expand_activation', 'block3a_expand_activation', \n",
    "                   'block4a_expand_activation', 'block6a_expand_activation'],\n",
    "            'B2': ['block2a_expand_activation', 'block3a_expand_activation', \n",
    "                   'block4a_expand_activation', 'block6a_expand_activation']\n",
    "        }\n",
    "        \n",
    "        # Extraction des features pour skip connections\n",
    "        skip_layers = [backbone.get_layer(name).output for name in skip_layer_names[self.backbone_name]]\n",
    "        \n",
    "        # Input\n",
    "        inputs = backbone.input\n",
    "        \n",
    "        # Encoder (bottom)\n",
    "        encoder_output = backbone.output\n",
    "        \n",
    "        # Bridge\n",
    "        bridge = layers.Conv2D(512, 3, padding='same', activation='relu', \n",
    "                              kernel_regularizer=l2(MODEL_CONFIG['l2_reg']))(encoder_output)\n",
    "        bridge = layers.BatchNormalization()(bridge)\n",
    "        bridge = layers.Dropout(MODEL_CONFIG['dropout_rate'])(bridge)\n",
    "        \n",
    "        # Decoder avec skip connections\n",
    "        x = bridge\n",
    "        \n",
    "        # Calcul automatique des tailles d'upsampling\n",
    "        skip_filters = [256, 128, 64, 32]\n",
    "        \n",
    "        for i, (skip_layer, filters) in enumerate(zip(reversed(skip_layers), skip_filters)):\n",
    "            # Upsampling\n",
    "            x = layers.UpSampling2D(2, interpolation='bilinear')(x)\n",
    "            \n",
    "            # Ajustement de la taille si n√©cessaire\n",
    "            skip_shape = skip_layer.shape[1:3]\n",
    "            x_shape = x.shape[1:3]\n",
    "            \n",
    "            # Redimensionnement pour correspondre au skip layer\n",
    "            if skip_shape != x_shape:\n",
    "                x = layers.Resizing(skip_shape[0], skip_shape[1])(x)\n",
    "            \n",
    "            # Concatenation avec skip connection\n",
    "            x = layers.Concatenate()([x, skip_layer])\n",
    "            \n",
    "            # Convolutions du decoder\n",
    "            x = layers.Conv2D(filters, 3, padding='same', activation='relu',\n",
    "                             kernel_regularizer=l2(MODEL_CONFIG['l2_reg']))(x)\n",
    "            x = layers.BatchNormalization()(x)\n",
    "            x = layers.Conv2D(filters, 3, padding='same', activation='relu',\n",
    "                             kernel_regularizer=l2(MODEL_CONFIG['l2_reg']))(x)\n",
    "            x = layers.BatchNormalization()(x)\n",
    "            x = layers.Dropout(MODEL_CONFIG['dropout_rate'] * 0.5)(x)\n",
    "        \n",
    "        # Upsampling final pour retrouver la taille d'origine\n",
    "        x = layers.UpSampling2D(4, interpolation='bilinear')(x)\n",
    "        \n",
    "        # Ajustement final de taille\n",
    "        if x.shape[1:3] != self.input_shape[:2]:\n",
    "            x = layers.Resizing(self.input_shape[0], self.input_shape[1])(x)\n",
    "        \n",
    "        # Couche de classification finale\n",
    "        outputs = layers.Conv2D(self.num_classes, 1, activation=MODEL_CONFIG['activation'], name='segmentation_output')(x)\n",
    "        \n",
    "        self.model = Model(inputs=inputs, outputs=outputs, name=self.name)\n",
    "        \n",
    "        print(f\"‚úÖ {self.name} construit avec succ√®s\")\n",
    "        return self.model\n",
    "\n",
    "# Test de construction U-Net EfficientNet\n",
    "print(\"\\nüî• CONSTRUCTION U-NET + EFFICIENTNET\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "unet_efficient = UNetEfficientNet(backbone='B0', freeze_backbone=True)\n",
    "model_unet = unet_efficient.build_model()\n",
    "\n",
    "info_unet = unet_efficient.get_model_info()\n",
    "print(f\"üìä U-Net EfficientNet-B0:\")\n",
    "print(f\"   ‚Ä¢ Param√®tres totaux: {info_unet['total_params']:,}\")\n",
    "print(f\"   ‚Ä¢ Param√®tres entra√Ænables: {info_unet['trainable_params']:,}\")\n",
    "print(f\"   ‚Ä¢ Couches: {info_unet['layers']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dedc5f53",
   "metadata": {},
   "source": [
    "## üöÄ Architecture 2: DeepLabV3+ + MobileNet\n",
    "\n",
    "**Conception** : ASPP + Decoder l√©ger avec backbone mobile optimis√©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b30a76ff",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üöÄ CONSTRUCTION DEEPLABV3+ + MOBILENET\n",
      "==================================================\n",
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "‚úÖ DeepLabV3Plus_MobileNetV2 construit avec succ√®s\n",
      "üìä DeepLabV3+ MobileNetV2:\n",
      "   ‚Ä¢ Param√®tres totaux: 12,806,968\n",
      "   ‚Ä¢ Param√®tres entra√Ænables: 12,769,176\n",
      "   ‚Ä¢ Couches: 180\n"
     ]
    }
   ],
   "source": [
    "class DeepLabV3Plus(SegmentationModel):\n",
    "    \"\"\"\n",
    "    DeepLabV3+ avec backbone MobileNetV2 pour efficacit√© embarqu√©e,\n",
    "    r√©√©crit pour n'utiliser que des tailles statiques.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, input_shape=(512, 1024, 3), num_classes=8, output_stride=16):\n",
    "        super().__init__(input_shape, num_classes, \"DeepLabV3Plus_MobileNetV2\")\n",
    "        self.output_stride = output_stride\n",
    "        # D√©duire statiquement les r√©solutions interm√©diaires\n",
    "        h, w, _ = input_shape\n",
    "        # MobileNetV2 reduce spatial by factor 32 by default\n",
    "        self.low_res = (h // 4, w // 4)    # bloc_1_expand_relu ‚Üí 1/4\n",
    "        self.high_res = (h // 32, w // 32) # backbone.output ‚Üí 1/32\n",
    "\n",
    "    def atrous_spatial_pyramid_pooling(self, x):\n",
    "        \"\"\"\n",
    "        ASPP statique : chaque branche est redimensionn√©e\n",
    "        en fonction de self.high_res, connu √† l'instanciation.\n",
    "        \"\"\"\n",
    "        # Branch 1: 1x1 conv\n",
    "        b1 = layers.Conv2D(256, 1, padding='same', activation='relu',\n",
    "                           kernel_regularizer=l2(MODEL_CONFIG['l2_reg']))(x)\n",
    "        b1 = layers.BatchNormalization()(b1)\n",
    "\n",
    "        # Branch 2-4: atrous conv\n",
    "        branches = [b1]\n",
    "        for rate in (6, 12, 18):\n",
    "            b = layers.Conv2D(256, 3, padding='same', dilation_rate=rate,\n",
    "                              activation='relu', kernel_regularizer=l2(MODEL_CONFIG['l2_reg']))(x)\n",
    "            b = layers.BatchNormalization()(b)\n",
    "            branches.append(b)\n",
    "\n",
    "        # Branch 5: global pooling\n",
    "        gp = layers.GlobalAveragePooling2D()(x)              # (batch, C)\n",
    "        gp = layers.Reshape((1, 1, x.shape[-1]))(gp)        # (batch,1,1,C)\n",
    "        gp = layers.Conv2D(256, 1, activation='relu',\n",
    "                           kernel_regularizer=l2(MODEL_CONFIG['l2_reg']))(gp)\n",
    "        gp = layers.BatchNormalization()(gp)\n",
    "        # Upsample statique vers high_res\n",
    "        gp = layers.Resizing(self.high_res[0], self.high_res[1],\n",
    "                             interpolation='bilinear')(gp)\n",
    "        branches.append(gp)\n",
    "\n",
    "        # Concat + conv final\n",
    "        concat = layers.Concatenate()(branches)\n",
    "        out = layers.Conv2D(256, 1, padding='same', activation='relu',\n",
    "                            kernel_regularizer=l2(MODEL_CONFIG['l2_reg']))(concat)\n",
    "        out = layers.BatchNormalization()(out)\n",
    "        out = layers.Dropout(MODEL_CONFIG['dropout_rate'])(out)\n",
    "        return out\n",
    "\n",
    "    def build_model(self):\n",
    "        inputs = Input(shape=self.input_shape)\n",
    "\n",
    "        # Backbone MobileNetV2\n",
    "        backbone = MobileNetV2(weights='imagenet', include_top=False,\n",
    "                              input_tensor=inputs, alpha=1.0)\n",
    "\n",
    "        # Low-level (1/4) et high-level (1/32) features\n",
    "        low_feat  = backbone.get_layer('block_3_expand_relu').output\n",
    "        high_feat = backbone.output\n",
    "\n",
    "        # ASPP + upsampling direct vers low_res\n",
    "        aspp = self.atrous_spatial_pyramid_pooling(high_feat)\n",
    "        x = layers.Resizing(self.low_res[0], self.low_res[1],\n",
    "                            interpolation='bilinear')(aspp)\n",
    "\n",
    "        # R√©duction des low-level features puis concat\n",
    "        low = layers.Conv2D(48, 1, padding='same', activation='relu',\n",
    "                            kernel_regularizer=l2(MODEL_CONFIG['l2_reg']))(low_feat)\n",
    "        low = layers.BatchNormalization()(low)\n",
    "        concat = layers.Concatenate()([x, low])\n",
    "\n",
    "        # Decoder final\n",
    "        x = layers.Conv2D(256, 3, padding='same', activation='relu',\n",
    "                          kernel_regularizer=l2(MODEL_CONFIG['l2_reg']))(concat)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "        x = layers.Dropout(MODEL_CONFIG['dropout_rate'])(x)\n",
    "\n",
    "        # Upsample final vers r√©solution d'entr√©e\n",
    "        x = layers.Resizing(self.input_shape[0], self.input_shape[1],\n",
    "                            interpolation='bilinear')(x)\n",
    "\n",
    "        outputs = layers.Conv2D(self.num_classes, 1,\n",
    "                                activation=MODEL_CONFIG['activation'],\n",
    "                                name='segmentation_output')(x)\n",
    "\n",
    "        self.model = Model(inputs=inputs, outputs=outputs, name=self.name)\n",
    "        print(f\"‚úÖ {self.name} construit avec succ√®s\")\n",
    "        return self.model\n",
    "\n",
    "# Test de construction DeepLabV3+\n",
    "print(\"\\nüöÄ CONSTRUCTION DEEPLABV3+ + MOBILENET\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "deeplab = DeepLabV3Plus()\n",
    "model_deeplab = deeplab.build_model()\n",
    "\n",
    "info_deeplab = deeplab.get_model_info()\n",
    "print(f\"üìä DeepLabV3+ MobileNetV2:\")\n",
    "print(f\"   ‚Ä¢ Param√®tres totaux: {info_deeplab['total_params']:,}\")\n",
    "print(f\"   ‚Ä¢ Param√®tres entra√Ænables: {info_deeplab['trainable_params']:,}\")\n",
    "print(f\"   ‚Ä¢ Couches: {info_deeplab['layers']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4c84ee73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Couche d'attention efficace pour Segformer\n",
    "class EfficientSelfAttention(layers.Layer):\n",
    "    def __init__(self, num_heads, sr_ratio=1, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.num_heads = num_heads\n",
    "        self.sr_ratio = sr_ratio\n",
    "        self.norm = layers.LayerNormalization()\n",
    "        self.attn = None\n",
    "        self.reduce = None\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        embed_dim = input_shape[-1]\n",
    "        if self.sr_ratio > 1:\n",
    "            self.reduce = layers.Conv2D(\n",
    "                embed_dim,\n",
    "                kernel_size=self.sr_ratio,\n",
    "                strides=self.sr_ratio,\n",
    "                padding='same'\n",
    "            )\n",
    "        self.attn = layers.MultiHeadAttention(\n",
    "            num_heads=self.num_heads,\n",
    "            key_dim=embed_dim // self.num_heads,\n",
    "            attention_axes=(1, 2),\n",
    "            dropout=0.1\n",
    "        )\n",
    "        super().build(input_shape)\n",
    "\n",
    "    def call(self, x):\n",
    "        kv = x\n",
    "        if self.sr_ratio > 1:\n",
    "            kv = self.reduce(x)\n",
    "            kv = self.norm(kv)\n",
    "        return self.attn(query=x, key=kv, value=kv)\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1884abc1",
   "metadata": {},
   "source": [
    "## üåü Architecture 3: Segformer-B0 (Vision Transformer)\n",
    "\n",
    "**Conception** : Architecture Transformer adapt√©e √† la segmentation, version l√©g√®re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f3a7a882",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üåü CONSTRUCTION SEGFORMER-B0 (SIMPLIFI√â)\n",
      "==================================================\n",
      "‚úÖ Segformer_B0 construit avec succ√®s\n",
      "üìä Segformer-B0:\n",
      "   ‚Ä¢ Param√®tres totaux: 3,716,968\n",
      "   ‚Ä¢ Param√®tres entra√Ænables: 3,715,432\n",
      "   ‚Ä¢ Couches: 86\n"
     ]
    }
   ],
   "source": [
    "class SegformerB0(SegmentationModel):\n",
    "    \"\"\"\n",
    "    Segformer-B0: Vision Transformer l√©ger pour segmentation s√©mantique\n",
    "    Impl√©mentation adapt√©e sans reshapes manuels\n",
    "    \"\"\"\n",
    "    def __init__(self, input_shape=(512, 1024, 3), num_classes=8, patch_size=4):\n",
    "        super().__init__(input_shape, num_classes, \"Segformer_B0\")\n",
    "        self.patch_size = patch_size\n",
    "        self.embed_dims = [32, 64, 160, 256]\n",
    "        self.num_heads = [1, 2, 5, 8]\n",
    "        self.depths = [2, 2, 2, 2]\n",
    "\n",
    "    def overlap_patch_embed(self, x, embed_dim, patch_size=7, stride=4):\n",
    "        x = layers.Conv2D(\n",
    "            embed_dim,\n",
    "            kernel_size=patch_size,\n",
    "            strides=stride,\n",
    "            padding='same',\n",
    "            kernel_regularizer=l2(MODEL_CONFIG['l2_reg'])\n",
    "        )(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "        return x\n",
    "\n",
    "    def mix_ffn(self, x, embed_dim, expansion_factor=4):\n",
    "        expanded_dim = embed_dim * expansion_factor\n",
    "        x = layers.Dense(expanded_dim, activation='gelu')(x)\n",
    "        x = layers.DepthwiseConv2D(3, padding='same')(x)\n",
    "        x = layers.Dense(embed_dim)(x)\n",
    "        return x\n",
    "\n",
    "    def transformer_block(self, x, embed_dim, num_heads, sr_ratio=1):\n",
    "        shortcut = x\n",
    "        x = layers.LayerNormalization()(x)\n",
    "        x = EfficientSelfAttention(num_heads=num_heads, sr_ratio=sr_ratio)(x)\n",
    "        x = layers.Add()([shortcut, x])\n",
    "        shortcut = x\n",
    "        x = layers.LayerNormalization()(x)\n",
    "        x = self.mix_ffn(x, embed_dim)\n",
    "        x = layers.Add()([shortcut, x])\n",
    "        return x\n",
    "\n",
    "    def build_model(self):\n",
    "        inputs = Input(shape=self.input_shape)\n",
    "        x = inputs\n",
    "        encoder_features = []\n",
    "        patch_sizes = [7, 3, 3, 3]\n",
    "        strides = [4, 2, 2, 2]\n",
    "        sr_ratios = [8, 4, 2, 1]\n",
    "\n",
    "        for i, (embed_dim, num_heads, depth) in enumerate(zip(self.embed_dims, self.num_heads, self.depths)):\n",
    "            x = self.overlap_patch_embed(x, embed_dim, patch_sizes[i], strides[i])\n",
    "            for _ in range(depth):\n",
    "                x = self.transformer_block(x, embed_dim, num_heads, sr_ratios[i])\n",
    "            encoder_features.append(x)\n",
    "\n",
    "        # Decoder: upsample chaque feature vers 1/4 de la r√©solution d'entr√©e (128x256)\n",
    "        decoder_features = []\n",
    "        for i, features in enumerate(encoder_features):\n",
    "            projected = layers.Conv2D(256, 1, padding='same')(features)\n",
    "            upsampling_factor = 2 ** i  # i=0:1, i=1:2, i=2:4, i=3:8\n",
    "            if upsampling_factor > 1:\n",
    "                projected = layers.UpSampling2D(upsampling_factor, interpolation='bilinear')(projected)\n",
    "            decoder_features.append(projected)\n",
    "\n",
    "        fused = layers.Concatenate()(decoder_features)\n",
    "        x = layers.Conv2D(256, 1, padding='same', activation='relu')(fused)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "        x = layers.Dropout(MODEL_CONFIG['dropout_rate'])(x)\n",
    "        x = layers.UpSampling2D(4, interpolation='bilinear')(x)\n",
    "        outputs = layers.Conv2D(\n",
    "            self.num_classes, 1,\n",
    "            activation=MODEL_CONFIG['activation'],\n",
    "            name='segmentation_output'\n",
    "        )(x)\n",
    "\n",
    "        self.model = Model(inputs=inputs, outputs=outputs, name=self.name)\n",
    "        print(f\"‚úÖ {self.name} construit avec succ√®s\")\n",
    "        return self.model\n",
    "\n",
    "# Test de construction Segformer (version all√©g√©e pour √©viter les erreurs de m√©moire)\n",
    "print(\"\\nüåü CONSTRUCTION SEGFORMER-B0 (SIMPLIFI√â)\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "try:\n",
    "    segformer = SegformerB0()\n",
    "    model_segformer = segformer.build_model()\n",
    "    \n",
    "    info_segformer = segformer.get_model_info()\n",
    "    print(f\"üìä Segformer-B0:\")\n",
    "    print(f\"   ‚Ä¢ Param√®tres totaux: {info_segformer['total_params']:,}\")\n",
    "    print(f\"   ‚Ä¢ Param√®tres entra√Ænables: {info_segformer['trainable_params']:,}\")\n",
    "    print(f\"   ‚Ä¢ Couches: {info_segformer['layers']}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è Construction Segformer √©chou√©e: {e}\")\n",
    "    print(\"üí° Version simplifi√©e sera utilis√©e en cas d'erreur de m√©moire\")\n",
    "    model_segformer = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4606760c",
   "metadata": {},
   "source": [
    "## üéØ Architecture 4: UNet Mini (Non Pr√©-entra√Æn√©) - MILESTONE 1\n",
    "\n",
    "**Conception** : U-Net simple comme recommand√© dans Milestone 1\n",
    "\"un mod√®le simple non pr√©-entra√Æn√© comme ¬´ Unet mini ¬ª\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5a0821cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üéØ CONSTRUCTION UNET MINI (NON PR√â-ENTRA√éN√â) - MILESTONE 1\n",
      "============================================================\n",
      "‚úÖ UNet_Mini construit avec succ√®s\n",
      "üìä UNet Mini:\n",
      "   ‚Ä¢ Param√®tres totaux: 31,402,952\n",
      "   ‚Ä¢ Param√®tres entra√Ænables: 31,391,176\n",
      "   ‚Ä¢ Couches: 59\n"
     ]
    }
   ],
   "source": [
    "class UNetMini(SegmentationModel):\n",
    "    \"\"\"\n",
    "    U-Net Mini: Architecture simple sans pr√©-entra√Ænement\n",
    "    Conforme aux recommandations Milestone 1\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, input_shape=(512, 1024, 3), num_classes=8):\n",
    "        super().__init__(input_shape, num_classes, \"UNet_Mini\")\n",
    "        \n",
    "    def conv_block(self, x, filters, kernel_size=3, activation='relu'):\n",
    "        \"\"\"Bloc de convolution standard avec BatchNorm et Dropout\"\"\"\n",
    "        x = layers.Conv2D(filters, kernel_size, padding='same', activation=activation,\n",
    "                         kernel_regularizer=l2(MODEL_CONFIG['l2_reg']))(x)\n",
    "        if MODEL_CONFIG['batch_norm']:\n",
    "            x = layers.BatchNormalization()(x)\n",
    "        x = layers.Conv2D(filters, kernel_size, padding='same', activation=activation,\n",
    "                         kernel_regularizer=l2(MODEL_CONFIG['l2_reg']))(x)\n",
    "        if MODEL_CONFIG['batch_norm']:\n",
    "            x = layers.BatchNormalization()(x)\n",
    "        return x\n",
    "    \n",
    "    def encoder_block(self, x, filters):\n",
    "        \"\"\"Bloc encoder: Conv + MaxPool\"\"\"\n",
    "        conv = self.conv_block(x, filters)\n",
    "        pool = layers.MaxPooling2D(2)(conv)\n",
    "        pool = layers.Dropout(MODEL_CONFIG['dropout_rate'])(pool)\n",
    "        return conv, pool\n",
    "    \n",
    "    def decoder_block(self, x, skip_connection, filters):\n",
    "        \"\"\"Bloc decoder: UpSampling + Concat + Conv\"\"\"\n",
    "        x = layers.UpSampling2D(2, interpolation='bilinear')(x)\n",
    "        \n",
    "        # Ajustement de taille si n√©cessaire\n",
    "        if x.shape[1:3] != skip_connection.shape[1:3]:\n",
    "            target_height, target_width = skip_connection.shape[1:3]\n",
    "            x = layers.Resizing(target_height, target_width)(x)\n",
    "        \n",
    "        x = layers.Concatenate()([x, skip_connection])\n",
    "        x = self.conv_block(x, filters)\n",
    "        x = layers.Dropout(MODEL_CONFIG['dropout_rate'] * 0.5)(x)\n",
    "        return x\n",
    "    \n",
    "    def build_model(self):\n",
    "        \"\"\"Construit le mod√®le U-Net Mini sans pr√©-entra√Ænement\"\"\"\n",
    "        \n",
    "        inputs = Input(shape=self.input_shape)\n",
    "        \n",
    "        # Encoder (Contracting Path)\n",
    "        # Configuration optimis√©e pour Cityscapes 512x1024\n",
    "        conv1, pool1 = self.encoder_block(inputs, 64)      # 512x1024 -> 256x512\n",
    "        conv2, pool2 = self.encoder_block(pool1, 128)      # 256x512 -> 128x256\n",
    "        conv3, pool3 = self.encoder_block(pool2, 256)      # 128x256 -> 64x128\n",
    "        conv4, pool4 = self.encoder_block(pool3, 512)      # 64x128 -> 32x64\n",
    "        \n",
    "        # Bridge (Bottom)\n",
    "        bridge = self.conv_block(pool4, 1024)              # 32x64\n",
    "        bridge = layers.Dropout(MODEL_CONFIG['dropout_rate'])(bridge)\n",
    "        \n",
    "        # Decoder (Expanding Path)\n",
    "        dec4 = self.decoder_block(bridge, conv4, 512)      # 32x64 -> 64x128\n",
    "        dec3 = self.decoder_block(dec4, conv3, 256)        # 64x128 -> 128x256\n",
    "        dec2 = self.decoder_block(dec3, conv2, 128)        # 128x256 -> 256x512\n",
    "        dec1 = self.decoder_block(dec2, conv1, 64)         # 256x512 -> 512x1024\n",
    "        \n",
    "        # Couche de classification finale\n",
    "        outputs = layers.Conv2D(self.num_classes, 1, \n",
    "                               activation=MODEL_CONFIG['activation'], \n",
    "                               name='segmentation_output')(dec1)\n",
    "        \n",
    "        self.model = Model(inputs=inputs, outputs=outputs, name=self.name)\n",
    "        \n",
    "        print(f\"‚úÖ {self.name} construit avec succ√®s\")\n",
    "        return self.model\n",
    "\n",
    "# Test de construction UNet Mini\n",
    "print(\"\\nüéØ CONSTRUCTION UNET MINI (NON PR√â-ENTRA√éN√â) - MILESTONE 1\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "unet_mini = UNetMini()\n",
    "model_unet_mini = unet_mini.build_model()\n",
    "\n",
    "info_unet_mini = unet_mini.get_model_info()\n",
    "print(f\"üìä UNet Mini:\")\n",
    "print(f\"   ‚Ä¢ Param√®tres totaux: {info_unet_mini['total_params']:,}\")\n",
    "print(f\"   ‚Ä¢ Param√®tres entra√Ænables: {info_unet_mini['trainable_params']:,}\")\n",
    "print(f\"   ‚Ä¢ Couches: {info_unet_mini['layers']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaca16ae",
   "metadata": {},
   "source": [
    "## üéØ Architecture 5: VGG16 UNet (Pr√©-entra√Æn√©) - MILESTONE 1\n",
    "\n",
    "**Conception** : U-Net avec encoder VGG16 comme recommand√© dans Milestone 1\n",
    "\"un mod√®le pr√©-entra√Æn√© comme ¬´ VGG16 Unet ¬ª (encoder = VGG16 pr√©-entra√Æn√©)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7afbcd0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üéØ CONSTRUCTION VGG16 UNET (PR√â-ENTRA√éN√â) - MILESTONE 1\n",
      "============================================================\n",
      "‚úÖ VGG16_UNet construit avec succ√®s\n",
      "üìä VGG16 UNet:\n",
      "   ‚Ä¢ Param√®tres totaux: 41,424,584\n",
      "   ‚Ä¢ Param√®tres entra√Ænables: 26,701,960\n",
      "   ‚Ä¢ Couches: 56\n",
      "\n",
      "‚úÖ 5 MOD√àLES IMPL√âMENT√âS\n"
     ]
    }
   ],
   "source": [
    "class VGG16UNet(SegmentationModel):\n",
    "    \"\"\"\n",
    "    VGG16 U-Net: U-Net avec encoder VGG16 pr√©-entra√Æn√© ImageNet\n",
    "    Conforme aux recommandations Milestone 1\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, input_shape=(512, 1024, 3), num_classes=8, freeze_backbone=False):\n",
    "        super().__init__(input_shape, num_classes, \"VGG16_UNet\")\n",
    "        self.freeze_backbone = freeze_backbone\n",
    "        \n",
    "    def conv_block(self, x, filters, kernel_size=3, activation='relu'):\n",
    "        \"\"\"Bloc de convolution pour le decoder\"\"\"\n",
    "        x = layers.Conv2D(filters, kernel_size, padding='same', activation=activation,\n",
    "                         kernel_regularizer=l2(MODEL_CONFIG['l2_reg']))(x)\n",
    "        if MODEL_CONFIG['batch_norm']:\n",
    "            x = layers.BatchNormalization()(x)\n",
    "        x = layers.Conv2D(filters, kernel_size, padding='same', activation=activation,\n",
    "                         kernel_regularizer=l2(MODEL_CONFIG['l2_reg']))(x)\n",
    "        if MODEL_CONFIG['batch_norm']:\n",
    "            x = layers.BatchNormalization()(x)\n",
    "        return x\n",
    "    \n",
    "    def decoder_block(self, x, skip_connection, filters):\n",
    "        \"\"\"Bloc decoder avec skip connections\"\"\"\n",
    "        x = layers.UpSampling2D(2, interpolation='bilinear')(x)\n",
    "        \n",
    "        # Ajustement de taille pour correspondre au skip connection\n",
    "        if x.shape[1:3] != skip_connection.shape[1:3]:\n",
    "            target_height, target_width = skip_connection.shape[1:3]\n",
    "            x = layers.Resizing(target_height, target_width)(x)\n",
    "        \n",
    "        x = layers.Concatenate()([x, skip_connection])\n",
    "        x = self.conv_block(x, filters)\n",
    "        x = layers.Dropout(MODEL_CONFIG['dropout_rate'] * 0.5)(x)\n",
    "        return x\n",
    "    \n",
    "    def build_model(self):\n",
    "        \"\"\"Construit le mod√®le VGG16 U-Net\"\"\"\n",
    "        \n",
    "        # Encoder VGG16 pr√©-entra√Æn√©\n",
    "        vgg16_base = VGG16(weights='imagenet', include_top=False, input_shape=self.input_shape)\n",
    "        \n",
    "        # Gel du backbone si sp√©cifi√©\n",
    "        if self.freeze_backbone:\n",
    "            vgg16_base.trainable = False\n",
    "            \n",
    "        # Extraction des features pour skip connections\n",
    "        # VGG16 architecture: block1, block2, block3, block4, block5\n",
    "        skip_layers = [\n",
    "            vgg16_base.get_layer('block1_conv2').output,  # 512x1024x64\n",
    "            vgg16_base.get_layer('block2_conv2').output,  # 256x512x128  \n",
    "            vgg16_base.get_layer('block3_conv3').output,  # 128x256x256\n",
    "            vgg16_base.get_layer('block4_conv3').output,  # 64x128x512\n",
    "        ]\n",
    "        \n",
    "        inputs = vgg16_base.input\n",
    "        \n",
    "        # Bottom (Bridge) - Sortie VGG16\n",
    "        bridge = vgg16_base.output  # 16x32x512\n",
    "        bridge = self.conv_block(bridge, 1024)\n",
    "        bridge = layers.Dropout(MODEL_CONFIG['dropout_rate'])(bridge)\n",
    "        \n",
    "        # Decoder avec skip connections\n",
    "        # Remont√©e progressive avec les features VGG16\n",
    "        dec4 = self.decoder_block(bridge, skip_layers[3], 512)    # 16x32 -> 32x64\n",
    "        dec3 = self.decoder_block(dec4, skip_layers[2], 256)      # 32x64 -> 64x128\n",
    "        dec2 = self.decoder_block(dec3, skip_layers[1], 128)      # 64x128 -> 128x256\n",
    "        dec1 = self.decoder_block(dec2, skip_layers[0], 64)       # 128x256 -> 256x512\n",
    "        \n",
    "        # Remont√©e finale vers r√©solution d'origine\n",
    "        final = layers.UpSampling2D(2, interpolation='bilinear')(dec1)  # 256x512 -> 512x1024\n",
    "        \n",
    "        # Ajustement final de taille si n√©cessaire\n",
    "        if final.shape[1:3] != self.input_shape[:2]:\n",
    "            final = layers.Resizing(self.input_shape[0], self.input_shape[1])(final)\n",
    "        \n",
    "        # Couche de classification finale\n",
    "        outputs = layers.Conv2D(self.num_classes, 1, \n",
    "                               activation=MODEL_CONFIG['activation'], \n",
    "                               name='segmentation_output')(final)\n",
    "        \n",
    "        self.model = Model(inputs=inputs, outputs=outputs, name=self.name)\n",
    "        \n",
    "        print(f\"‚úÖ {self.name} construit avec succ√®s\")\n",
    "        return self.model\n",
    "\n",
    "# Test de construction VGG16 UNet\n",
    "print(\"\\nüéØ CONSTRUCTION VGG16 UNET (PR√â-ENTRA√éN√â) - MILESTONE 1\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "vgg16_unet = VGG16UNet(freeze_backbone=True)\n",
    "model_vgg16_unet = vgg16_unet.build_model()\n",
    "\n",
    "info_vgg16_unet = vgg16_unet.get_model_info()\n",
    "print(f\"üìä VGG16 UNet:\")\n",
    "print(f\"   ‚Ä¢ Param√®tres totaux: {info_vgg16_unet['total_params']:,}\")\n",
    "print(f\"   ‚Ä¢ Param√®tres entra√Ænables: {info_vgg16_unet['trainable_params']:,}\")\n",
    "print(f\"   ‚Ä¢ Couches: {info_vgg16_unet['layers']}\")\n",
    "\n",
    "\n",
    "\n",
    "print(f\"\\n‚úÖ 5 MOD√àLES IMPL√âMENT√âS\")\n",
    "\n",
    "# Nettoyage m√©moire\n",
    "tf.keras.backend.clear_session()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4cf2b9c",
   "metadata": {},
   "source": [
    "## üîß Factory Pattern pour Cr√©ation de Mod√®les"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ad4e017e",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Mod√®les import√©s depuis 2.2\n",
      "üí° Utilisez run_model_comparison() pour comparer les mod√®les\n"
     ]
    }
   ],
   "source": [
    "class ModelFactory:\n",
    "    \"\"\"\n",
    "    Factory pour cr√©er et g√©rer les diff√©rents mod√®les de segmentation\n",
    "    \"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def create_model(model_type, **kwargs):\n",
    "        \"\"\"\n",
    "        Cr√©e un mod√®le selon le type sp√©cifi√©\n",
    "        \n",
    "        Args:\n",
    "            model_type: Type de mod√®le ('unet', 'deeplab', 'segformer')\n",
    "            **kwargs: Arguments sp√©cifiques au mod√®le\n",
    "        \"\"\"\n",
    "        \n",
    "        model_registry = {\n",
    "            'unet': UNetEfficientNet,\n",
    "            'deeplab': DeepLabV3Plus,\n",
    "            'segformer': SegformerB0,\n",
    "            'unet_mini': UNetMini,\n",
    "            'vgg16_unet': VGG16UNet\n",
    "        }\n",
    "        \n",
    "        if model_type.lower() not in model_registry:\n",
    "            raise ValueError(f\"Type de mod√®le '{model_type}' non reconnu. \"\n",
    "                           f\"Types disponibles: {list(model_registry.keys())}\")\n",
    "        \n",
    "        model_class = model_registry[model_type.lower()]\n",
    "        return model_class(**kwargs)\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_model_comparison():\n",
    "        \"\"\"\n",
    "        Compare les mod√®les impl√©ment√©s\n",
    "        \"\"\"\n",
    "        models_info = []\n",
    "        \n",
    "        # Test de chaque mod√®le\n",
    "        test_configs = [\n",
    "            {'type': 'unet', 'name': 'U-Net EfficientNet-B0', 'kwargs': {'backbone': 'B0'}},\n",
    "            {'type': 'deeplab', 'name': 'DeepLabV3+ MobileNetV2', 'kwargs': {}},\n",
    "            {'type': 'segformer', 'name': 'Segformer-B0', 'kwargs': {}},\n",
    "            {'type': 'unet_mini', 'name': 'UNet Mini (Milestone 1)', 'kwargs': {}},\n",
    "            {'type': 'vgg16_unet', 'name': 'VGG16 UNet (Milestone 1)', 'kwargs': {}}\n",
    "        ]\n",
    "        \n",
    "        for config in test_configs:\n",
    "            try:\n",
    "                model = ModelFactory.create_model(config['type'], **config['kwargs'])\n",
    "                built_model = model.build_model()\n",
    "                info = model.get_model_info()\n",
    "                \n",
    "                models_info.append({\n",
    "                    'Architecture': config['name'],\n",
    "                    'Param√®tres (M)': info['total_params'] / 1e6,\n",
    "                    'Param√®tres Entra√Ænables (M)': info['trainable_params'] / 1e6,\n",
    "                    'Couches': info['layers'],\n",
    "                    'Statut': '‚úÖ Op√©rationnel'\n",
    "                })\n",
    "                \n",
    "                # Nettoyage m√©moire\n",
    "                del built_model, model\n",
    "                tf.keras.backend.clear_session()\n",
    "                \n",
    "            except Exception as e:\n",
    "                models_info.append({\n",
    "                    'Architecture': config['name'],\n",
    "                    'Param√®tres (M)': 'N/A',\n",
    "                    'Param√®tres Entra√Ænables (M)': 'N/A',\n",
    "                    'Couches': 'N/A',\n",
    "                    'Statut': f'‚ùå Erreur: {str(e)[:50]}...'\n",
    "                })\n",
    "        \n",
    "        return pd.DataFrame(models_info)\n",
    "\n",
    "# Fonction de comparaison disponible mais pas ex√©cut√©e automatiquement\n",
    "def run_model_comparison():\n",
    "    \"\"\"\n",
    "    Ex√©cute la comparaison des mod√®les (√† appeler manuellement)\n",
    "    \"\"\"\n",
    "    print(\"\\nüìä COMPARAISON DES MOD√àLES IMPL√âMENT√âS\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    try:\n",
    "        df_models = ModelFactory.get_model_comparison()\n",
    "        print(df_models.to_string(index=False))\n",
    "        return df_models\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Erreur lors de la comparaison: {e}\")\n",
    "        print(\"üí° Assurer-vous que toutes les classes sont d√©finies avant d'appeler cette fonction\")\n",
    "        return None\n",
    "\n",
    "print(\"\\n‚úÖ Mod√®les import√©s depuis 2.2\")\n",
    "print(\"üí° Utilisez run_model_comparison() pour comparer les mod√®les\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a453b6d1",
   "metadata": {},
   "source": [
    "## üß™ Tests Unitaires des Architectures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0ac5d437",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üß™ TESTS UNITAIRES DES ARCHITECTURES\n",
      "==================================================\n",
      "\n",
      "üß™ TEST: U-Net + EfficientNet-B0\n",
      "----------------------------------------\n",
      "‚úÖ UNet_EfficientNetB0 construit avec succ√®s\n",
      "‚úÖ U-Net + EfficientNet-B0 - Tests r√©ussis\n",
      "   ‚Ä¢ Param√®tres: 14,240,875\n",
      "   ‚Ä¢ Shape output: (1, 512, 1024, 8)\n",
      "   ‚Ä¢ Min/Max pr√©diction: 0.014770/0.412901\n",
      "\n",
      "üß™ TEST: DeepLabV3+ + MobileNetV2\n",
      "----------------------------------------\n",
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "‚úÖ DeepLabV3Plus_MobileNetV2 construit avec succ√®s\n",
      "‚úÖ DeepLabV3+ + MobileNetV2 - Tests r√©ussis\n",
      "   ‚Ä¢ Param√®tres: 12,806,968\n",
      "   ‚Ä¢ Shape output: (1, 512, 1024, 8)\n",
      "   ‚Ä¢ Min/Max pr√©diction: 0.006096/0.786791\n",
      "\n",
      "üß™ TEST: Segformer-B0\n",
      "----------------------------------------\n",
      "‚úÖ Segformer_B0 construit avec succ√®s\n",
      "‚úÖ Segformer-B0 - Tests r√©ussis\n",
      "   ‚Ä¢ Param√®tres: 3,716,968\n",
      "   ‚Ä¢ Shape output: (1, 512, 1024, 8)\n",
      "   ‚Ä¢ Min/Max pr√©diction: 0.056748/0.338376\n",
      "\n",
      "üß™ TEST: UNet Mini (Non pr√©-entra√Æn√©)\n",
      "----------------------------------------\n",
      "‚úÖ UNet_Mini construit avec succ√®s\n",
      "‚úÖ UNet Mini (Non pr√©-entra√Æn√©) - Tests r√©ussis\n",
      "   ‚Ä¢ Param√®tres: 31,402,952\n",
      "   ‚Ä¢ Shape output: (1, 512, 1024, 8)\n",
      "   ‚Ä¢ Min/Max pr√©diction: 0.111345/0.138980\n",
      "\n",
      "üß™ TEST: VGG16 UNet (Pr√©-entra√Æn√©)\n",
      "----------------------------------------\n",
      "‚úÖ VGG16_UNet construit avec succ√®s\n",
      "‚úÖ VGG16 UNet (Pr√©-entra√Æn√©) - Tests r√©ussis\n",
      "   ‚Ä¢ Param√®tres: 41,424,584\n",
      "   ‚Ä¢ Shape output: (1, 512, 1024, 8)\n",
      "   ‚Ä¢ Min/Max pr√©diction: 0.000000/0.964786\n"
     ]
    }
   ],
   "source": [
    "def test_model_architecture(model_instance, test_name):\n",
    "    \"\"\"\n",
    "    Test unitaire pour valider l'architecture d'un mod√®le\n",
    "    \"\"\"\n",
    "    print(f\"\\nüß™ TEST: {test_name}\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    try:\n",
    "        # Construction du mod√®le\n",
    "        model = model_instance.build_model()\n",
    "        \n",
    "        # Tests des dimensions\n",
    "        assert model.input_shape == (None,) + model_instance.input_shape, \"Erreur input shape\"\n",
    "        assert model.output_shape == (None, model_instance.input_shape[0], \n",
    "                                     model_instance.input_shape[1], \n",
    "                                     model_instance.num_classes), \"Erreur output shape\"\n",
    "        \n",
    "        # Test de pr√©diction avec donn√©es al√©atoires\n",
    "        test_input = np.random.random((1,) + model_instance.input_shape)\n",
    "        prediction = model.predict(test_input, verbose=0)\n",
    "        \n",
    "        # V√©rifications de la pr√©diction\n",
    "        assert prediction.shape == (1, model_instance.input_shape[0], \n",
    "                                   model_instance.input_shape[1], \n",
    "                                   model_instance.num_classes), \"Erreur shape pr√©diction\"\n",
    "        \n",
    "        # V√©rification softmax (somme = 1 par pixel)\n",
    "        pixel_sums = np.sum(prediction[0], axis=-1)\n",
    "        assert np.allclose(pixel_sums, 1.0, atol=1e-5), \"Erreur normalisation softmax\"\n",
    "        \n",
    "        # Informations du mod√®le\n",
    "        info = model_instance.get_model_info()\n",
    "        \n",
    "        print(f\"‚úÖ {test_name} - Tests r√©ussis\")\n",
    "        print(f\"   ‚Ä¢ Param√®tres: {info['total_params']:,}\")\n",
    "        print(f\"   ‚Ä¢ Shape output: {prediction.shape}\")\n",
    "        print(f\"   ‚Ä¢ Min/Max pr√©diction: {prediction.min():.6f}/{prediction.max():.6f}\")\n",
    "        \n",
    "        return True, info\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå {test_name} - Erreur: {e}\")\n",
    "        return False, None\n",
    "\n",
    "# Tests des architectures\n",
    "print(\"\\nüß™ TESTS UNITAIRES DES ARCHITECTURES\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "test_results = []\n",
    "\n",
    "# Test U-Net EfficientNet\n",
    "unet_test = UNetEfficientNet(backbone='B0')\n",
    "success, info = test_model_architecture(unet_test, \"U-Net + EfficientNet-B0\")\n",
    "test_results.append(('U-Net EfficientNet-B0', success, info))\n",
    "\n",
    "# Test DeepLabV3+\n",
    "deeplab_test = DeepLabV3Plus()\n",
    "success, info = test_model_architecture(deeplab_test, \"DeepLabV3+ + MobileNetV2\")\n",
    "test_results.append(('DeepLabV3+ MobileNetV2', success, info))\n",
    "\n",
    "# Test Segformer (avec gestion d'erreur)\n",
    "try:\n",
    "    segformer_test = SegformerB0()\n",
    "    success, info = test_model_architecture(segformer_test, \"Segformer-B0\")\n",
    "    test_results.append(('Segformer-B0', success, info))\n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è Segformer-B0 non test√©: {e}\")\n",
    "    test_results.append(('Segformer-B0', False, None))\n",
    "\n",
    "# Test UNet Mini\n",
    "unet_mini_test = UNetMini()\n",
    "success_mini, info_mini = test_model_architecture(unet_mini_test, \"UNet Mini (Non pr√©-entra√Æn√©)\")\n",
    "test_results.append(('UNet Mini', success_mini, info_mini))\n",
    "\n",
    "# Test VGG16 UNet\n",
    "vgg16_test = VGG16UNet()\n",
    "success_vgg16, info_vgg16 = test_model_architecture(vgg16_test, \"VGG16 UNet (Pr√©-entra√Æn√©)\")\n",
    "test_results.append(('VGG16 UNet', success_vgg16, info_vgg16))\n",
    "\n",
    "# Nettoyage m√©moire\n",
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58b0b6bd",
   "metadata": {},
   "source": [
    "## üìã Configuration Transfer Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2076f1fa",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìã STRAT√âGIES DE TRANSFER LEARNING\n",
      "==================================================\n",
      "\n",
      "üèóÔ∏è UNET_EFFICIENTNET:\n",
      "   üìä Total √©poques: 35\n",
      "   ‚Ä¢ phase_1: Freeze backbone, train decoder only\n",
      "     - √âpoques: 5, LR: 0.001\n",
      "   ‚Ä¢ phase_2: Unfreeze backbone, fine-tune all\n",
      "     - √âpoques: 20, LR: 0.0001\n",
      "   ‚Ä¢ phase_3: Full training with decay\n",
      "     - √âpoques: 10, LR: 1e-05\n",
      "\n",
      "üèóÔ∏è DEEPLAB_MOBILENET:\n",
      "   üìä Total √©poques: 35\n",
      "   ‚Ä¢ phase_1: Train ASPP and decoder only\n",
      "     - √âpoques: 8, LR: 0.001\n",
      "   ‚Ä¢ phase_2: Fine-tune all layers\n",
      "     - √âpoques: 22, LR: 0.0005\n",
      "   ‚Ä¢ phase_3: Final optimization\n",
      "     - √âpoques: 5, LR: 1e-05\n",
      "\n",
      "üèóÔ∏è SEGFORMER:\n",
      "   üìä Total √©poques: 35\n",
      "   ‚Ä¢ phase_1: Train decoder head only\n",
      "     - √âpoques: 10, LR: 0.001\n",
      "   ‚Ä¢ phase_2: Full model fine-tuning\n",
      "     - √âpoques: 25, LR: 0.0003\n",
      "\n",
      "üèóÔ∏è UNET_MINI:\n",
      "   üìä Total √©poques: 70\n",
      "   ‚Ä¢ phase_1: Train all from scratch\n",
      "     - √âpoques: 50, LR: 0.001\n",
      "   ‚Ä¢ phase_2: Fine-tune with decay\n",
      "     - √âpoques: 20, LR: 0.0001\n",
      "\n",
      "üèóÔ∏è VGG16_UNET:\n",
      "   üìä Total √©poques: 40\n",
      "   ‚Ä¢ phase_1: Freeze VGG16, train decoder only\n",
      "     - √âpoques: 8, LR: 0.001\n",
      "   ‚Ä¢ phase_2: Unfreeze VGG16, fine-tune all\n",
      "     - √âpoques: 25, LR: 0.0005\n",
      "   ‚Ä¢ phase_3: Final optimization\n",
      "     - √âpoques: 7, LR: 1e-05\n"
     ]
    }
   ],
   "source": [
    "def create_transfer_learning_strategy():\n",
    "    \"\"\"\n",
    "    D√©finit les strat√©gies de transfer learning pour chaque architecture\n",
    "    \"\"\"\n",
    "    \n",
    "    strategies = {\n",
    "        'unet_efficientnet': {\n",
    "            'phase_1': {\n",
    "                'description': 'Freeze backbone, train decoder only',\n",
    "                'epochs': 5,\n",
    "                'freeze_backbone': True,\n",
    "                'learning_rate': 1e-3,\n",
    "                'rationale': 'Adaptation rapide du decoder aux donn√©es Cityscapes'\n",
    "            },\n",
    "            'phase_2': {\n",
    "                'description': 'Unfreeze backbone, fine-tune all',\n",
    "                'epochs': 20,\n",
    "                'freeze_backbone': False,\n",
    "                'learning_rate': 1e-4,\n",
    "                'rationale': 'Fine-tuning complet avec LR r√©duit'\n",
    "            },\n",
    "            'phase_3': {\n",
    "                'description': 'Full training with decay',\n",
    "                'epochs': 10,\n",
    "                'freeze_backbone': False,\n",
    "                'learning_rate': 1e-5,\n",
    "                'rationale': 'Optimisation finale avec tr√®s petit LR'\n",
    "            }\n",
    "        },\n",
    "        'deeplab_mobilenet': {\n",
    "            'phase_1': {\n",
    "                'description': 'Train ASPP and decoder only',\n",
    "                'epochs': 8,\n",
    "                'freeze_backbone': True,\n",
    "                'learning_rate': 1e-3,\n",
    "                'rationale': 'Focus sur l\\'adaptation de l\\'ASPP'\n",
    "            },\n",
    "            'phase_2': {\n",
    "                'description': 'Fine-tune all layers',\n",
    "                'epochs': 22,\n",
    "                'freeze_backbone': False,\n",
    "                'learning_rate': 5e-4,\n",
    "                'rationale': 'Fine-tuning global MobileNet'\n",
    "            },\n",
    "            'phase_3': {\n",
    "                'description': 'Final optimization',\n",
    "                'epochs': 5,\n",
    "                'freeze_backbone': False,\n",
    "                'learning_rate': 1e-5,\n",
    "                'rationale': 'Convergence finale'\n",
    "            }\n",
    "        },\n",
    "        'segformer': {\n",
    "            'phase_1': {\n",
    "                'description': 'Train decoder head only',\n",
    "                'epochs': 10,\n",
    "                'freeze_backbone': True,\n",
    "                'learning_rate': 1e-3,\n",
    "                'rationale': 'Adaptation MLP head aux 8 classes'\n",
    "            },\n",
    "            'phase_2': {\n",
    "                'description': 'Full model fine-tuning',\n",
    "                'epochs': 25,\n",
    "                'freeze_backbone': False,\n",
    "                'learning_rate': 3e-4,\n",
    "                'rationale': 'Fine-tuning Transformer complet'\n",
    "            }\n",
    "        },\n",
    "        'unet_mini': {\n",
    "            'phase_1': {\n",
    "                'description': 'Train all from scratch',\n",
    "                'epochs': 50,\n",
    "                'freeze_backbone': False,\n",
    "                'learning_rate': 1e-3,\n",
    "                'rationale': 'Entra√Ænement complet sans pr√©-entra√Ænement'\n",
    "            },\n",
    "            'phase_2': {\n",
    "                'description': 'Fine-tune with decay',\n",
    "                'epochs': 20,\n",
    "                'freeze_backbone': False,\n",
    "                'learning_rate': 1e-4,\n",
    "                'rationale': 'Convergence finale avec LR r√©duit'\n",
    "            }\n",
    "        },\n",
    "        'vgg16_unet': {\n",
    "            'phase_1': {\n",
    "                'description': 'Freeze VGG16, train decoder only',\n",
    "                'epochs': 8,\n",
    "                'freeze_backbone': True,\n",
    "                'learning_rate': 1e-3,\n",
    "                'rationale': 'Adaptation decoder aux features VGG16'\n",
    "            },\n",
    "            'phase_2': {\n",
    "                'description': 'Unfreeze VGG16, fine-tune all',\n",
    "                'epochs': 25,\n",
    "                'freeze_backbone': False,\n",
    "                'learning_rate': 5e-4,\n",
    "                'rationale': 'Fine-tuning complet VGG16 + decoder'\n",
    "            },\n",
    "            'phase_3': {\n",
    "                'description': 'Final optimization',\n",
    "                'epochs': 7,\n",
    "                'freeze_backbone': False,\n",
    "                'learning_rate': 1e-5,\n",
    "                'rationale': 'Convergence finale optimis√©e'\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # Sauvegarde des strat√©gies\n",
    "    with open(OUTPUTS_DIR / \"transfer_learning_strategies.json\", 'w') as f:\n",
    "        json.dump(strategies, f, indent=2)\n",
    "    \n",
    "    print(\"üìã STRAT√âGIES DE TRANSFER LEARNING\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    for model_name, phases in strategies.items():\n",
    "        print(f\"\\nüèóÔ∏è {model_name.upper()}:\")\n",
    "        total_epochs = sum(phase['epochs'] for phase in phases.values())\n",
    "        print(f\"   üìä Total √©poques: {total_epochs}\")\n",
    "        \n",
    "        for phase_name, config in phases.items():\n",
    "            print(f\"   ‚Ä¢ {phase_name}: {config['description']}\")\n",
    "            print(f\"     - √âpoques: {config['epochs']}, LR: {config['learning_rate']}\")\n",
    "    \n",
    "    return strategies\n",
    "\n",
    "# Cr√©ation des strat√©gies\n",
    "transfer_strategies = create_transfer_learning_strategy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a3c8fe4",
   "metadata": {},
   "source": [
    "## üíæ Sauvegarde et Export des Mod√®les"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "95ef5da8",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üíæ SAUVEGARDE DES IMPL√âMENTATIONS\n",
      "==================================================\n",
      "‚úÖ 5/5 mod√®les impl√©ment√©s avec succ√®s\n",
      "üìÅ M√©tadonn√©es sauvegard√©es: C:\\Tonton\\OpenClassrooms\\Projet_7_traiter_images_systeme_embarque_voiture_autonome\\notebooks\\outputs\\model_implementations.json\n",
      "üìÅ Strat√©gies TL sauvegard√©es: C:\\Tonton\\OpenClassrooms\\Projet_7_traiter_images_systeme_embarque_voiture_autonome\\notebooks\\outputs\\transfer_learning_strategies.json\n",
      "\n",
      "üèÜ R√âSUM√â FINAL - IMPL√âMENTATION MOD√àLES\n",
      "============================================================\n",
      "‚úÖ Mod√®les op√©rationnels: U-Net EfficientNet-B0, DeepLabV3+ MobileNetV2, Segformer-B0, UNet Mini, VGG16 UNet\n",
      "üéØ Configuration: (512, 1024, 3) ‚Üí 8 classes\n",
      "üîß Factory Pattern impl√©ment√© pour cr√©ation modulaire\n",
      "üìã Strat√©gies Transfer Learning d√©finies pour chaque architecture\n"
     ]
    }
   ],
   "source": [
    "def save_model_architectures():\n",
    "    \"\"\"\n",
    "    Sauvegarde les architectures et m√©tadonn√©es des mod√®les\n",
    "    \"\"\"\n",
    "    \n",
    "    # R√©sum√© des impl√©mentations\n",
    "    models_impl = [r for r in test_results if r[1]]\n",
    "    models_fail = [r for r in test_results if not r[1]]\n",
    "    implementation_summary = {\n",
    "        'models_implemented': int(len(models_impl)),\n",
    "        'total_models_planned': 5,\n",
    "        'successful_models': [r[0] for r in models_impl],\n",
    "        'failed_models': [r[0] for r in models_fail],\n",
    "        'model_specifications': {\n",
    "            'input_shape': MODEL_CONFIG['input_shape'],\n",
    "            'num_classes': MODEL_CONFIG['num_classes'],\n",
    "            'activation': MODEL_CONFIG['activation']\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # Param√®tres d√©taill√©s par mod√®le\n",
    "    model_details = {}\n",
    "    for model_name, success, info in test_results:\n",
    "        if success and info:\n",
    "            model_details[model_name] = {\n",
    "                'total_params': int(info['total_params']),\n",
    "                'trainable_params': int(info['trainable_params']),\n",
    "                'layers': int(info['layers']),\n",
    "                'memory_estimate_mb': float(info['total_params'] * 4 / (1024 * 1024))\n",
    "            }\n",
    "    \n",
    "    implementation_summary['model_details'] = model_details\n",
    "    \n",
    "    # Sauvegarde\n",
    "    with open(OUTPUTS_DIR / \"model_implementations.json\", 'w') as f:\n",
    "        json.dump(implementation_summary, f, indent=2)\n",
    "    \n",
    "    print(\"\\nüíæ SAUVEGARDE DES IMPL√âMENTATIONS\")\n",
    "    print(\"=\" * 50)\n",
    "    print(f\"‚úÖ {implementation_summary['models_implemented']}/{implementation_summary['total_models_planned']} mod√®les impl√©ment√©s avec succ√®s\")\n",
    "    print(f\"üìÅ M√©tadonn√©es sauvegard√©es: {OUTPUTS_DIR / 'model_implementations.json'}\")\n",
    "    print(f\"üìÅ Strat√©gies TL sauvegard√©es: {OUTPUTS_DIR / 'transfer_learning_strategies.json'}\")\n",
    "    \n",
    "    return implementation_summary\n",
    "\n",
    "# Sauvegarde finale\n",
    "summary = save_model_architectures()\n",
    "\n",
    "# Affichage du r√©sum√© final\n",
    "print(f\"\\nüèÜ R√âSUM√â FINAL - IMPL√âMENTATION MOD√àLES\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"‚úÖ Mod√®les op√©rationnels: {', '.join(summary['successful_models'])}\")\n",
    "if summary['failed_models']:\n",
    "    print(f\"‚ö†Ô∏è Mod√®les √©chou√©s: {', '.join(summary['failed_models'])}\")\n",
    "print(f\"üéØ Configuration: {summary['model_specifications']['input_shape']} ‚Üí {summary['model_specifications']['num_classes']} classes\")\n",
    "print(f\"üîß Factory Pattern impl√©ment√© pour cr√©ation modulaire\")\n",
    "print(f\"üìã Strat√©gies Transfer Learning d√©finies pour chaque architecture\")"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": ".cityscapes_albumentations",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
